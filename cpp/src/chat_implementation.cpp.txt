// Implementation of Real-Time Conversation API
// Add to NPCInference.cpp after Learn() method

std::string NPCInferenceEngine::StartConversation(const std::string& npc_name, const std::string& player_name) {
    if (!conversation_manager_) {
        conversation_manager_ = std::make_unique<ConversationManager>();
    }
    
    return conversation_manager_->CreateSession(npc_name, player_name);
}

std::string NPCInferenceEngine::Chat(const std::string& session_id, const std::string& user_message) {
    if (!conversation_manager_) {
        return "Error: No conversation manager initialized";
    }
    
    // Get conversation context
    auto* ctx = conversation_manager_->GetSession(session_id);
    if (!ctx) {
        return "Error: Invalid session ID";
    }
    
    // Add user message to history
    conversation_manager_->AddMessage(session_id, "user", user_message);
    
    // === Build Context for Generation ===
    
    // 1. Retrieve relevant memories from VectorStore (RAG)
    std::string rag_context = "";
    if (config_.enable_rag && vector_store_ && embedding_model_ && embedding_model_->IsLoaded()) {
        try {
            auto embedding = embedding_model_->Embed(user_message);
            if (!embedding.empty()) {
                auto results = vector_store_->Search(embedding, 5);
                
                if (!results.empty()) {
                    rag_context += "Relevant Memories:\n";
                    for (const auto& result : results) {
                        if (result.similarity > config_.rag_threshold) {
                            rag_context += "- " + result.text + "\n";
                        }
                    }
                }
            }
        } catch (const std::exception& e) {
            std::cerr << "RAG retrieval error: " << e.what() << std::endl;
        }
    }
    
    // 2. Query knowledge graph for relevant facts
    std::string graph_context = "";
    if (config_.enable_graph && knowledge_graph_) {
        try {
            // Simple entity extraction: look for capitalized words
            std::istringstream iss(user_message);
            std::string word;
            std::vector<std::string> potential_entities;
            
            while (iss >> word) {
                if (!word.empty() && std::isupper(word[0])) {
                    potential_entities.push_back(word);
                }
            }
            
            // Query graph for each entity
            for (const auto& entity : potential_entities) {
                auto edges = knowledge_graph_->GetRelations(entity);
                if (!edges.empty()) {
                    if (graph_context.empty()) {
                        graph_context += "Known Facts:\n";
                    }
                    for (const auto& edge : edges) {
                        graph_context += "- " + edge.source + " " + edge.relation + " " + edge.target + "\n";
                    }
                }
            }
        } catch (const std::exception& e) {
            std::cerr << "Graph query error: " << e.what() << std::endl;
        }
    }
    
    // 3. Build conversation history
    std::string conversation_history = "";
    auto history = conversation_manager_->GetHistory(session_id, 6); // Last 3 turns
    for (const auto& msg : history) {
        if (msg.role == "user") {
            conversation_history += ctx->player_name + ": " + msg.content + "\n";
        } else {
            conversation_history += ctx->npc_name + ": " + msg.content + "\n";
        }
    }
    
    // 4. Build full context
    std::string full_context = "";
    if (!rag_context.empty()) {
        full_context += rag_context + "\n";
    }
    if (!graph_context.empty()) {
        full_context += graph_context + "\n";
    }
    if (!conversation_history.empty()) {
        full_context += "Conversation History:\n" + conversation_history;
    }
    
    // 5. Generate response using existing GenerateFromContext
    std::string persona = "You are " + ctx->npc_name + ", a character in a fantasy world.";
    std::string response = GenerateFromContext(persona, ctx->npc_name, full_context, user_message);
    
    // 6. Add assistant response to history
    conversation_manager_->AddMessage(session_id, "assistant", response);
    
    // 7. Remember this interaction
    if (config_.enable_rag) {
        std::string memory_text = "Conversation with " + ctx->player_name + ": " + 
                                 user_message + " -> " + response;
        Remember(memory_text, {
            {"type", "conversation"},
            {"npc", ctx->npc_name},
            {"player", ctx->player_name},
            {"session", session_id}
        });
    }
    
    return response;
}

void NPCInferenceEngine::EndConversation(const std::string& session_id) {
    if (!conversation_manager_) return;
    
    // Trigger reflection/consolidation if enabled
    if (config_.enable_reflection) {
        std::cout << "Ending conversation. Triggering memory consolidation..." << std::endl;
        PerformSleepCycle();
    }
    
    conversation_manager_->CloseSession(session_id);
}
