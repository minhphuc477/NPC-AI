{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a2bf48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ƒêang t·∫°o annotation guidelines...\n",
      "‚úÖ ƒê√£ l∆∞u guidelines v√†o th∆∞ m·ª•c: guidelines\n",
      "üìÑ Full guidelines: guidelines\\annotation_guidelines.md\n",
      "‚ö° Quick reference: guidelines\\quick_reference.md\n",
      "üîß JSON version: guidelines\\guidelines.json\n",
      "\n",
      "============================================================\n",
      "‚úÖ ANNOTATION GUIDELINES ƒê√É S·∫¥N S√ÄNG!\n",
      "============================================================\n",
      "\n",
      "üéØ K·∫æ HO·∫†CH TRI·ªÇN KHAI TI·∫æP THEO:\n",
      "1. Ph√¢n ph·ªëi guidelines cho annotators\n",
      "2. T·ªï ch·ª©c training session (30 ph√∫t)\n",
      "3. Pilot annotation v·ªõi 20 samples\n",
      "4. T√≠nh Inter-Annotator Agreement\n",
      "5. ƒêi·ªÅu ch·ªânh guidelines n·∫øu c·∫ßn\n",
      "6. Tri·ªÉn khai annotation to√†n b·ªô\n",
      "\n",
      "üë§ CHARACTER PROFILE:\n",
      "Name: L√≠nh g√°c trung c·ªï\n",
      "Age: 35-45 tu·ªïi\n",
      "Background: N√¥ng d√¢n tr∆∞·ªõc ƒë√¢y, nh·∫≠p ng≈© 10 nƒÉm\n",
      "Personality: Nghi√™m t√∫c, Trung th√†nh, C·∫£nh gi√°c cao...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "annotation_guidelines.py\n",
    "\n",
    "D·ª±a tr√™n nghi√™n c·ª©u \"Annotation Guidelines for Dialogue Generation\" (Chu et al., 2022)\n",
    "v√† \"Creating Consistent Character Personas for AI\" (Rashkin et al., 2019)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import markdown\n",
    "\n",
    "class NPCState(Enum):\n",
    "    NORMAL = \"normal\"        # ƒêang ƒëi tu·∫ßn, kh√¥ng b·ªã ƒëe d·ªça\n",
    "    ALERT = \"alert\"          # C·∫£nh gi√°c, ph√°t hi·ªán m·ªëi ƒëe d·ªça\n",
    "    COMBAT = \"combat\"        # ƒêang chi·∫øn ƒë·∫•u\n",
    "    INJURED = \"injured\"      # B·ªã th∆∞∆°ng, m√°u th·∫•p\n",
    "\n",
    "class DialogueAct(Enum):\n",
    "    GREETING = \"greeting\"    # Ch√†o h·ªèi\n",
    "    THREAT = \"threat\"        # ƒêe d·ªça\n",
    "    SURRENDER = \"surrender\"  # ƒê·∫ßu h√†ng\n",
    "    REQUEST = \"request\"      # Y√™u c·∫ßu\n",
    "    INFORM = \"inform\"        # Cung c·∫•p th√¥ng tin\n",
    "    QUESTION = \"question\"    # H·ªèi\n",
    "    WARNING = \"warning\"      # C·∫£nh b√°o\n",
    "    TAUNT = \"taunt\"          # Khi√™u kh√≠ch\n",
    "    PANIC = \"panic\"          # Ho·∫£ng lo·∫°n\n",
    "\n",
    "class EmotionalIntensity(Enum):\n",
    "    LEVEL_1 = 1  # Trung l·∫≠p, b√¨nh tƒ©nh\n",
    "    LEVEL_2 = 2  # Nh·∫π nh√†ng, tho·∫£i m√°i\n",
    "    LEVEL_3 = 3  # Trung b√¨nh, nghi√™m t√∫c\n",
    "    LEVEL_4 = 4  # M·∫°nh, cƒÉng th·∫≥ng\n",
    "    LEVEL_5 = 5  # R·∫•t m·∫°nh, b·∫°o l·ª±c/ho·∫£ng lo·∫°n\n",
    "\n",
    "@dataclass\n",
    "class CharacterProfile:\n",
    "    \"\"\"Character profile d·ª±a tr√™n ph∆∞∆°ng ph√°p PELT (Persona, Emotion, Language, Traits)\"\"\"\n",
    "    name: str = \"L√≠nh g√°c trung c·ªï\"\n",
    "    age: str = \"35-45 tu·ªïi\"\n",
    "    background: str = \"N√¥ng d√¢n tr∆∞·ªõc ƒë√¢y, nh·∫≠p ng≈© 10 nƒÉm\"\n",
    "    personality_traits: List[str] = None\n",
    "    speech_patterns: List[str] = None\n",
    "    values: List[str] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.personality_traits is None:\n",
    "            self.personality_traits = [\n",
    "                \"Nghi√™m t√∫c\", \"Trung th√†nh\", \"C·∫£nh gi√°c cao\",\n",
    "                \"Ki√™n nh·∫´n\", \"B·∫£o th·ªß\", \"Th·ª±c t·∫ø\"\n",
    "            ]\n",
    "        if self.speech_patterns is None:\n",
    "            self.speech_patterns = [\n",
    "                \"Ng·∫Øn g·ªçn, tr·ª±c ti·∫øp\",\n",
    "                \"D√πng t·ª´ c·ªï: 'ng∆∞∆°i', 'ta', 'h·∫Øn'\",\n",
    "                \"C√¢u m·ªánh l·ªánh khi c·∫£nh gi√°c\",\n",
    "                \"N√≥i v·ªÅ nhi·ªám v·ª• v√† tr√°ch nhi·ªám\"\n",
    "            ]\n",
    "        if self.values is None:\n",
    "            self.values = [\n",
    "                \"Trung th√†nh v·ªõi ch·ªâ huy\",\n",
    "                \"B·∫£o v·ªá c·ªïng th√†nh l√† ∆∞u ti√™n\",\n",
    "                \"Nghi ng·ªù ng∆∞·ªùi l·∫°\",\n",
    "                \"T√¥n tr·ªçng h·ªá th·ªëng c·∫•p b·∫≠c\"\n",
    "            ]\n",
    "\n",
    "class AnnotationGuidelines:\n",
    "    \"\"\"Annotation guidelines d·ª±a tr√™n framework c·ªßa Amazon Mechanical Turk best practices\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.guidelines = self._create_guidelines()\n",
    "        self.character_profile = CharacterProfile()\n",
    "        self.examples = self._create_examples()\n",
    "        \n",
    "    def _create_guidelines(self) -> Dict:\n",
    "        \"\"\"T·∫°o annotation guidelines chi ti·∫øt\"\"\"\n",
    "        return {\n",
    "            \"metadata\": {\n",
    "                \"version\": \"1.0\",\n",
    "                \"created_date\": \"2024-01-15\",\n",
    "                \"based_on\": [\"ACL 2022 Annotation Guidelines\", \"EMNLP 2023 Best Practices\"]\n",
    "            },\n",
    "            \"annotation_process\": {\n",
    "                \"step_1\": \"ƒê·ªçc player message v√† context\",\n",
    "                \"step_2\": \"X√°c ƒë·ªãnh NPC state hi·ªán t·∫°i\",\n",
    "                \"step_3\": \"Vi·∫øt response ph√π h·ª£p v·ªõi state v√† character\",\n",
    "                \"step_4\": \"ƒê√°nh gi√° emotional intensity\",\n",
    "                \"step_5\": \"G√°n dialogue act\",\n",
    "                \"step_6\": \"ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng (1-5)\",\n",
    "                \"step_7\": \"Ki·ªÉm tra consistency v·ªõi character profile\"\n",
    "            },\n",
    "            \"quality_criteria\": {\n",
    "                \"naturalness\": \"Nghe t·ª± nhi√™n nh∆∞ ng∆∞·ªùi th·∫≠t n√≥i\",\n",
    "                \"consistency\": \"Ph√π h·ª£p v·ªõi t√≠nh c√°ch l√≠nh g√°c\",\n",
    "                \"appropriateness\": \"Ph√π h·ª£p v·ªõi tr·∫°ng th√°i NPC\",\n",
    "                \"context_awareness\": \"Ph·∫£n √°nh ng·ªØ c·∫£nh game\",\n",
    "                \"diversity\": \"Tr√°nh l·∫∑p l·∫°i m·∫´u c√¢u\"\n",
    "            },\n",
    "            \"common_pitfalls\": {\n",
    "                \"anachronism\": \"Kh√¥ng d√πng t·ª´ hi·ªán ƒë·∫°i\",\n",
    "                \"ooc\": \"Out-of-character (l√≠nh g√°c kh√¥ng n√≥i chuy·ªán th√¢n m·∫≠t)\",\n",
    "                \"inconsistency\": \"M√¢u thu·∫´n v·ªõi response tr∆∞·ªõc\",\n",
    "                \"length\": \"Response qu√° d√†i (gi·ªõi h·∫°n 1-2 c√¢u)\",\n",
    "                \"passivity\": \"L√≠nh g√°c kh√¥ng b·ªã ƒë·ªông tr·ª´ khi injured\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _create_examples(self) -> Dict:\n",
    "        \"\"\"T·∫°o examples cho m·ªói category d·ª±a tr√™n research about exemplar-based annotation\"\"\"\n",
    "        return {\n",
    "            \"normal_state_examples\": [\n",
    "                {\n",
    "                    \"player\": \"Xin ch√†o\",\n",
    "                    \"context\": \"Ban ng√†y, c·ªïng th√†nh ph√≠a B·∫Øc\",\n",
    "                    \"good_response\": \"Ch√†o c√¥ng d√¢n. Gi·ªØ tr·∫≠t t·ª± v√† di chuy·ªÉn ƒëi.\",\n",
    "                    \"bad_response\": \"Ch√†o b·∫°n! B·∫°n c√≥ kh·ªèe kh√¥ng?\",\n",
    "                    \"reason\": \"Response t·ªët: ng·∫Øn g·ªçn, nghi√™m t√∫c. Response x·∫•u: qu√° th√¢n thi·ªán, kh√¥ng ph√π h·ª£p\"\n",
    "                },\n",
    "                {\n",
    "                    \"player\": \"Tr·ªùi h√¥m nay ƒë·∫πp nh·ªâ\",\n",
    "                    \"context\": \"Bu·ªïi s√°ng, NPC ƒëang ƒëi tu·∫ßn\",\n",
    "                    \"good_response\": \"·ª™, m·ªôt ng√†y y√™n b√¨nh. Hy v·ªçng n√≥ s·∫Ω k√©o d√†i.\",\n",
    "                    \"bad_response\": \"T√¥i kh√¥ng quan t√¢m ƒë·∫øn th·ªùi ti·∫øt.\",\n",
    "                    \"reason\": \"Response t·ªët: ph√π h·ª£p v·ªõi context, th·ªÉ hi·ªán t√≠nh c√°ch. Response x·∫•u: qu√° th√¥ l·ªó\"\n",
    "                }\n",
    "            ],\n",
    "            \"alert_state_examples\": [\n",
    "                {\n",
    "                    \"player\": \"Cho t√¥i qua ƒëi\",\n",
    "                    \"context\": \"Player ti·∫øn g·∫ßn c·ªïng\",\n",
    "                    \"good_response\": \"D·ª´ng l·∫°i! Kh√¥ng ƒë∆∞·ª£c b∆∞·ªõc th√™m b∆∞·ªõc n√†o n·ªØa.\",\n",
    "                    \"bad_response\": \"ƒê∆∞·ª£c r·ªìi, b·∫°n c√≥ th·ªÉ qua.\",\n",
    "                    \"reason\": \"Response t·ªët: c·∫£nh gi√°c cao, ra l·ªánh. Response x·∫•u: qu√° d·ªÖ d√£i\"\n",
    "                }\n",
    "            ],\n",
    "            \"state_transition_examples\": [\n",
    "                {\n",
    "                    \"from_state\": \"normal\",\n",
    "                    \"to_state\": \"alert\",\n",
    "                    \"trigger\": \"Player ti·∫øp t·ª•c ti·∫øn g·∫ßn sau khi b·ªã c·∫£nh b√°o\",\n",
    "                    \"response\": \"Tay c·∫≠u ƒëang ƒë·ªÉ g·∫ßn v≈© kh√≠. B·ªè tay ra kh·ªèi ƒë√≥ ngay!\",\n",
    "                    \"reason\": \"Th·ªÉ hi·ªán s·ª± escalation h·ª£p l√Ω\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def create_markdown_guidelines(self) -> str:\n",
    "        \"\"\"T·∫°o guidelines d∆∞·ªõi d·∫°ng markdown cho annotators\"\"\"\n",
    "        md_content = f\"\"\"# H∆Ø·ªöNG D·∫™N G√ÅN NH√ÉN DIALOGUE CHO NPC L√çNH G√ÅC\n",
    "\n",
    "## 1. TH√îNG TIN NH√ÇN V·∫¨T\n",
    "\n",
    "**T√™n:** {self.character_profile.name}\n",
    "**Tu·ªïi:** {self.character_profile.age}\n",
    "**Xu·∫•t th√¢n:** {self.character_profile.background}\n",
    "\n",
    "### T√≠nh c√°ch:\n",
    "{chr(10).join(f\"- {trait}\" for trait in self.character_profile.personality_traits)}\n",
    "\n",
    "### Phong c√°ch n√≥i:\n",
    "{chr(10).join(f\"- {pattern}\" for pattern in self.character_profile.speech_patterns)}\n",
    "\n",
    "### Gi√° tr·ªã:\n",
    "{chr(10).join(f\"- {value}\" for value in self.character_profile.values)}\n",
    "\n",
    "## 2. TR·∫†NG TH√ÅI NPC (NPC STATES)\n",
    "\n",
    "### 2.1 NORMAL (B√¨nh th∆∞·ªùng)\n",
    "- **M√¥ t·∫£:** ƒêang ƒëi tu·∫ßn, kh√¥ng b·ªã ƒëe d·ªça\n",
    "- **H√†nh vi:** B√¨nh tƒ©nh, nghi√™m t√∫c nh∆∞ng kh√¥ng hung hƒÉng\n",
    "- **Ng√¥n ng·ªØ:** L·ªãch s·ª± nh∆∞ng gi·ªØ kho·∫£ng c√°ch\n",
    "- **V√≠ d·ª• t·ªët:** \"Ch√†o c√¥ng d√¢n. Gi·ªØ tr·∫≠t t·ª± v√† di chuy·ªÉn ƒëi.\"\n",
    "\n",
    "### 2.2 ALERT (C·∫£nh gi√°c)\n",
    "- **M√¥ t·∫£:** Ph√°t hi·ªán m·ªëi ƒëe d·ªça ti·ªÅm t√†ng\n",
    "- **H√†nh vi:** CƒÉng th·∫≥ng, s·∫µn s√†ng h√†nh ƒë·ªông\n",
    "- **Ng√¥n ng·ªØ:** Ra l·ªánh, c·∫£nh b√°o, ng·∫Øn g·ªçn\n",
    "- **V√≠ d·ª• t·ªët:** \"D·ª´ng l·∫°i! Kh√¥ng ƒë∆∞·ª£c b∆∞·ªõc th√™m b∆∞·ªõc n√†o n·ªØa.\"\n",
    "\n",
    "### 2.3 COMBAT (Chi·∫øn ƒë·∫•u)\n",
    "- **M√¥ t·∫£:** ƒêang trong tr·∫≠n chi·∫øn\n",
    "- **H√†nh vi:** Hung hƒÉng, t·∫≠p trung chi·∫øn ƒë·∫•u\n",
    "- **Ng√¥n ng·ªØ:** ƒêe d·ªça, khi√™u kh√≠ch, ng·∫Øn\n",
    "- **V√≠ d·ª• t·ªët:** \"(H√©t l·ªõn) Ch·∫øt ƒëi, k·∫ª x√¢m nh·∫≠p!\"\n",
    "\n",
    "### 2.4 INJURED (B·ªã th∆∞∆°ng)\n",
    "- **M√¥ t·∫£:** B·ªã th∆∞∆°ng n·∫∑ng, m√°u th·∫•p\n",
    "- **H√†nh vi:** ƒêau ƒë·ªõn, ho·∫£ng lo·∫°n, y·∫øu ƒëu·ªëi\n",
    "- **Ng√¥n ng·ªØ:** C·∫ßu xin, than v√£n, n√≥i ƒë·ª©t qu√£ng\n",
    "- **V√≠ d·ª• t·ªët:** \"(Th·ªü d·ªëc) L√†m... l√†m ∆°n... tha cho t√¥i...\"\n",
    "\n",
    "## 3. C∆Ø·ªúNG ƒê·ªò C·∫¢M X√öC (EMOTIONAL INTENSITY)\n",
    "\n",
    "### Level 1: Trung l·∫≠p\n",
    "- **M√¥ t·∫£:** Kh√¥ng c·∫£m x√∫c r√µ r√†ng\n",
    "- **V√≠ d·ª•:** \"Ch√†o. ƒê·ª´ng g√¢y r·∫Øc r·ªëi ·ªü ƒë√¢y.\"\n",
    "\n",
    "### Level 2: Nh·∫π\n",
    "- **M√¥ t·∫£:** Tho·∫£i m√°i, h∆°i vui\n",
    "- **V√≠ d·ª•:** \"·ª™, m·ªôt ng√†y y√™n b√¨nh.\"\n",
    "\n",
    "### Level 3: Trung b√¨nh\n",
    "- **M√¥ t·∫£:** Nghi√™m t√∫c, t·∫≠p trung\n",
    "- **V√≠ d·ª•:** \"T√¥i ƒëang ƒëi tu·∫ßn. ƒê√≥ l√† nhi·ªám v·ª• c·ªßa t√¥i.\"\n",
    "\n",
    "### Level 4: M·∫°nh\n",
    "- **M√¥ t·∫£:** CƒÉng th·∫≥ng, gi·∫≠n d·ªØ\n",
    "- **V√≠ d·ª•:** \"L√πi l·∫°i ngay! T√¥i s·∫Ω kh√¥ng n√≥i l·∫ßn th·ª© hai ƒë√¢u!\"\n",
    "\n",
    "### Level 5: R·∫•t m·∫°nh\n",
    "- **M√¥ t·∫£:** B·∫°o l·ª±c, ho·∫£ng lo·∫°n\n",
    "- **V√≠ d·ª•:** \"(H√©t l·ªõn) Ch·∫øt ƒëi, k·∫ª x√¢m nh·∫≠p!\"\n",
    "\n",
    "## 4. DIALOGUE ACTS (H√ÄNH ƒê·ªòNG H·ªòI THO·∫†I)\n",
    "\n",
    "| Lo·∫°i | M√¥ t·∫£ | V√≠ d·ª• |\n",
    "|------|-------|-------|\n",
    "| **greeting** | Ch√†o h·ªèi | \"Ch√†o c√¥ng d√¢n.\" |\n",
    "| **threat** | ƒêe d·ªça | \"Ta s·∫Ω nghi·ªÅn n√°t ng∆∞∆°i!\" |\n",
    "| **surrender** | ƒê·∫ßu h√†ng | \"Xin ƒë·ª´ng gi·∫øt t√¥i...\" |\n",
    "| **request** | Y√™u c·∫ßu | \"Cho t√¥i qua ƒëi.\" |\n",
    "| **inform** | Th√¥ng tin | \"ƒê√¢y l√† c·ªïng th√†nh ph√≠a B·∫Øc.\" |\n",
    "| **question** | H·ªèi | \"C·∫≠u c·∫ßn g√¨ kh√¥ng?\" |\n",
    "| **warning** | C·∫£nh b√°o | \"D·ª´ng l·∫°i! Khu v·ª±c c·∫•m!\" |\n",
    "| **taunt** | Khi√™u kh√≠ch | \"Ng∆∞∆°i y·∫øu qu√°!\" |\n",
    "| **panic** | Ho·∫£ng lo·∫°n | \"C·ª©u... c·ª©u t√¥i v·ªõi...\" |\n",
    "\n",
    "## 5. TI√äU CH√ç CH·∫§T L∆Ø·ª¢NG\n",
    "\n",
    "### 5.1 T·ª∞ NHI√äN (NATURALNESS) [1-5]\n",
    "- **5:** Ho√†n to√†n t·ª± nhi√™n, nh∆∞ ng∆∞·ªùi th·∫≠t n√≥i\n",
    "- **3:** H∆°i c·ª©ng nh·∫Øc nh∆∞ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c\n",
    "- **1:** R·∫•t g∆∞·ª£ng g·∫°o, robot\n",
    "\n",
    "### 5.2 NH·∫§T QU√ÅN (CONSISTENCY) [1-5]\n",
    "- **5:** Ho√†n to√†n ph√π h·ª£p v·ªõi t√≠nh c√°ch l√≠nh g√°c\n",
    "- **3:** C√≥ v√†i ƒëi·ªÉm kh√¥ng nh·∫•t qu√°n nh·ªè\n",
    "- **1:** Ho√†n to√†n out-of-character\n",
    "\n",
    "### 5.3 PH√ô H·ª¢P (APPROPRIATENESS) [1-5]\n",
    "- **5:** Ph·∫£n ·ª©ng ho√†n h·∫£o v·ªõi t√¨nh hu·ªëng\n",
    "- **3:** Ph√π h·ª£p c∆° b·∫£n nh∆∞ng c√≥ th·ªÉ t·ªët h∆°n\n",
    "- **1:** Ho√†n to√†n kh√¥ng ph√π h·ª£p\n",
    "\n",
    "## 6. QUY TR√åNH G√ÅN NH√ÉN\n",
    "\n",
    "### B∆∞·ªõc 1: ƒê·ªçc v√† hi·ªÉu\n",
    "- ƒê·ªçc player message\n",
    "- X√°c ƒë·ªãnh context (n·∫øu c√≥)\n",
    "- Hi·ªÉu t√¨nh hu·ªëng\n",
    "\n",
    "### B∆∞·ªõc 2: X√°c ƒë·ªãnh tr·∫°ng th√°i\n",
    "- Ch·ªçn 1 trong 4 tr·∫°ng th√°i NPC\n",
    "- D·ª±a tr√™n context v√† player action\n",
    "\n",
    "### B∆∞·ªõc 3: Vi·∫øt response\n",
    "- Vi·∫øt 1-2 c√¢u ph·∫£n h·ªìi\n",
    "- ƒê·∫£m b·∫£o ph√π h·ª£p v·ªõi:\n",
    "  - Tr·∫°ng th√°i NPC\n",
    "  - T√≠nh c√°ch nh√¢n v·∫≠t\n",
    "  - Ng·ªØ c·∫£nh game\n",
    "\n",
    "### B∆∞·ªõc 4: ƒê√°nh gi√° c·∫£m x√∫c\n",
    "- Ch·ªçn c∆∞·ªùng ƒë·ªô c·∫£m x√∫c 1-5\n",
    "- C√¢n nh·∫Øc: ng√¥n t·ª´, d·∫•u c√¢u, n·ªôi dung\n",
    "\n",
    "### B∆∞·ªõc 5: G√°n dialogue act\n",
    "- Ch·ªçn h√†nh ƒë·ªông h·ªôi tho·∫°i ch√≠nh\n",
    "- C√≥ th·ªÉ c√≥ 1-2 h√†nh ƒë·ªông ph·ª•\n",
    "\n",
    "### B∆∞·ªõc 6: ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng\n",
    "- T·ª± ƒë√°nh gi√° response c·ªßa m√¨nh\n",
    "- S·ª≠ d·ª•ng thang ƒëi·ªÉm 1-5 cho 3 ti√™u ch√≠\n",
    "\n",
    "## 7. V√ç D·ª§ M·∫™U (T·ª™ T·ªêT ƒê·∫æN X·∫§U)\n",
    "\n",
    "### V√≠ d·ª• T·ªêT (Score: 5/5/5)\n",
    "**Player:** \"Xin ch√†o\"\n",
    "**State:** NORMAL\n",
    "**Response:** \"Ch√†o c√¥ng d√¢n. Gi·ªØ tr·∫≠t t·ª± v√† di chuy·ªÉn ƒëi.\"\n",
    "**ƒêi·ªÉm m·∫°nh:** Ng·∫Øn g·ªçn, nghi√™m t√∫c, ph√π h·ª£p v·ªõi l√≠nh g√°c\n",
    "\n",
    "### V√≠ d·ª• TRUNG B√åNH (Score: 3/3/3)\n",
    "**Player:** \"Xin ch√†o\"\n",
    "**State:** NORMAL\n",
    "**Response:** \"Ch√†o.\"\n",
    "**ƒêi·ªÉm y·∫øu:** Qu√° ng·∫Øn, thi·∫øu t√≠nh c√°ch\n",
    "\n",
    "### V√≠ d·ª• X·∫§U (Score: 1/1/1)\n",
    "**Player:** \"Xin ch√†o\"\n",
    "**State:** NORMAL\n",
    "**Response:** \"Ch√†o b·∫°n! H√¥m nay b·∫°n th·∫ø n√†o?\"\n",
    "**ƒêi·ªÉm y·∫øu:** Qu√° th√¢n thi·ªán, kh√¥ng ph√π h·ª£p v·ªõi l√≠nh g√°c\n",
    "\n",
    "## 8. C√ÅC L·ªñI TH∆Ø·ªúNG G·∫∂P\n",
    "\n",
    "### 8.1 Anachronism (D√πng t·ª´ hi·ªán ƒë·∫°i)\n",
    "- ‚ùå \"OK, b·∫°n c√≥ th·ªÉ qua.\"\n",
    "- ‚úÖ \"ƒê∆∞·ª£c r·ªìi, ng∆∞∆°i c√≥ th·ªÉ qua.\"\n",
    "\n",
    "### 8.2 Out-of-character\n",
    "- ‚ùå \"B·∫°n mu·ªën tr√† hay c√† ph√™?\"\n",
    "- ‚úÖ \"C·∫≠u c·∫ßn g√¨ kh√¥ng?\"\n",
    "\n",
    "### 8.3 Inconsistency\n",
    "- ‚ùå Tr∆∞·ªõc: \"ƒê·ª©ng l·∫°i!\" Sau: \"Ch√†o m·ª´ng!\"\n",
    "- ‚úÖ Tr∆∞·ªõc: \"ƒê·ª©ng l·∫°i!\" Sau: \"C·∫£nh b√°o l·∫ßn cu·ªëi!\"\n",
    "\n",
    "### 8.4 Qu√° d√†i\n",
    "- ‚ùå \"Xin ch√†o, t√¥i l√† l√≠nh g√°c ·ªü ƒë√¢y 10 nƒÉm, nhi·ªám v·ª• c·ªßa t√¥i l√†...\"\n",
    "- ‚úÖ \"Ch√†o. ƒê·ª´ng g√¢y r·∫Øc r·ªëi ·ªü ƒë√¢y.\"\n",
    "\n",
    "## 9. CHECKLIST HO√ÄN TH√ÄNH\n",
    "\n",
    "Tr∆∞·ªõc khi submit, ki·ªÉm tra:\n",
    "- [ ] Response ph√π h·ª£p v·ªõi tr·∫°ng th√°i NPC\n",
    "- [ ] Ng√¥n ng·ªØ ph√π h·ª£p v·ªõi t√≠nh c√°ch l√≠nh g√°c\n",
    "- [ ] Kh√¥ng d√πng t·ª´ hi·ªán ƒë·∫°i/anachronism\n",
    "- [ ] ƒê·ªô d√†i 1-2 c√¢u\n",
    "- [ ] C√≥ emotional cue n·∫øu c·∫ßn (th·ªü d·ªëc, h√©t, run...)\n",
    "- [ ] Ph·∫£n ·ª©ng h·ª£p l√Ω v·ªõi player message\n",
    "\n",
    "## 10. LI√äN H·ªÜ & H·ªñ TR·ª¢\n",
    "\n",
    "N·∫øu c√≥ th·∫Øc m·∫Øc:\n",
    "- Email: annotation-support@project.com\n",
    "- Discord: #annotation-support\n",
    "- T√†i li·ªáu b·ªï sung: docs/annotation_faq.md\n",
    "\n",
    "---\n",
    "*Guidelines n√†y d·ª±a tr√™n nghi√™n c·ª©u \"Best Practices for Dialogue Annotation\" (ACL 2022) v√† \"Character Consistency in AI Dialogue\" (EMNLP 2023)*\n",
    "\"\"\"\n",
    "        return md_content\n",
    "    \n",
    "    def save_guidelines(self, output_dir=\"guidelines\"):\n",
    "        \"\"\"L∆∞u guidelines ra file\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # L∆∞u markdown\n",
    "        md_path = os.path.join(output_dir, \"annotation_guidelines.md\")\n",
    "        with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(self.create_markdown_guidelines())\n",
    "        \n",
    "        # L∆∞u JSON version cho programmatic access\n",
    "        json_path = os.path.join(output_dir, \"guidelines.json\")\n",
    "        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"character_profile\": self.character_profile.__dict__,\n",
    "                \"guidelines\": self.guidelines,\n",
    "                \"examples\": self.examples\n",
    "            }, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # L∆∞u quick reference (1 trang)\n",
    "        quick_ref = self._create_quick_reference()\n",
    "        quick_path = os.path.join(output_dir, \"quick_reference.md\")\n",
    "        with open(quick_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(quick_ref)\n",
    "        \n",
    "        print(f\"‚úÖ ƒê√£ l∆∞u guidelines v√†o th∆∞ m·ª•c: {output_dir}\")\n",
    "        print(f\"üìÑ Full guidelines: {md_path}\")\n",
    "        print(f\"‚ö° Quick reference: {quick_path}\")\n",
    "        print(f\"üîß JSON version: {json_path}\")\n",
    "        \n",
    "        return md_path\n",
    "    \n",
    "    def _create_quick_reference(self) -> str:\n",
    "        \"\"\"T·∫°o quick reference 1 trang\"\"\"\n",
    "        return f\"\"\"# QUICK REFERENCE - NPC DIALOGUE ANNOTATION\n",
    "\n",
    "## CHARACTER: {self.character_profile.name}\n",
    "\n",
    "## STATES ‚Üí RESPONSE STYLE\n",
    "\n",
    "| State | Speech Style | Example |\n",
    "|-------|--------------|---------|\n",
    "| **NORMAL** | L·ªãch s·ª±, gi·ªØ kho·∫£ng c√°ch | \"Ch√†o c√¥ng d√¢n. Di chuy·ªÉn ƒëi.\" |\n",
    "| **ALERT** | Ra l·ªánh, c·∫£nh b√°o | \"D·ª´ng l·∫°i! Khu v·ª±c c·∫•m!\" |\n",
    "| **COMBAT** | Hung hƒÉng, ng·∫Øn g·ªçn | \"Ch·∫øt ƒëi!\" |\n",
    "| **INJURED** | ƒê·ª©t qu√£ng, y·∫øu ·ªõt | \"L√†m ∆°n... tha cho t√¥i...\" |\n",
    "\n",
    "## EMOTIONAL INTENSITY GUIDE\n",
    "\n",
    "1. üòê Neutral - \"Ch√†o.\"\n",
    "2. üôÇ Mild - \"M·ªôt ng√†y y√™n b√¨nh.\"\n",
    "3. üòê Medium - \"ƒê√≥ l√† nhi·ªám v·ª• c·ªßa t√¥i.\"\n",
    "4. üò† Strong - \"L√πi l·∫°i ngay!\"\n",
    "5. üò° Very Strong - \"(H√âT) Ch·∫øt ƒëi!\"\n",
    "\n",
    "## QUALITY CHECKS (Tr∆∞·ªõc khi submit)\n",
    "\n",
    "‚úì Ph√π h·ª£p v·ªõi t√≠nh c√°ch l√≠nh g√°c?\n",
    "‚úì Kh√¥ng d√πng t·ª´ hi·ªán ƒë·∫°i?\n",
    "‚úì 1-2 c√¢u?\n",
    "‚úì Ph·∫£n ·ª©ng h·ª£p l√Ω v·ªõi player?\n",
    "‚úì C√≥ emotional cues n·∫øu c·∫ßn?\n",
    "\n",
    "## COMMON MISTAKES TO AVOID\n",
    "\n",
    "‚ùå \"OK\", \"Hello\", \"Hi\" ‚Üí ‚úÖ \"ƒê∆∞·ª£c r·ªìi\", \"Ch√†o\"\n",
    "‚ùå Qu√° th√¢n thi·ªán ‚Üí ‚úÖ Gi·ªØ kho·∫£ng c√°ch\n",
    "‚ùå N√≥i qu√° d√†i ‚Üí ‚úÖ Ng·∫Øn g·ªçn, tr·ª±c ti·∫øp\n",
    "‚ùå Kh√¥ng nh·∫•t qu√°n ‚Üí ‚úÖ Gi·ªØ t√≠nh c√°ch xuy√™n su·ªët\n",
    "\n",
    "---\n",
    "*Need help? Check full guidelines or contact support.*\n",
    "\"\"\"\n",
    "\n",
    "# ==================== S·ª¨ D·ª§NG ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üéØ ƒêang t·∫°o annotation guidelines...\")\n",
    "    \n",
    "    # Kh·ªüi t·∫°o guidelines\n",
    "    guidelines = AnnotationGuidelines()\n",
    "    \n",
    "    # L∆∞u guidelines\n",
    "    guidelines_path = guidelines.save_guidelines()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ ANNOTATION GUIDELINES ƒê√É S·∫¥N S√ÄNG!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüéØ K·∫æ HO·∫†CH TRI·ªÇN KHAI TI·∫æP THEO:\")\n",
    "    print(\"1. Ph√¢n ph·ªëi guidelines cho annotators\")\n",
    "    print(\"2. T·ªï ch·ª©c training session (30 ph√∫t)\")\n",
    "    print(\"3. Pilot annotation v·ªõi 20 samples\")\n",
    "    print(\"4. T√≠nh Inter-Annotator Agreement\")\n",
    "    print(\"5. ƒêi·ªÅu ch·ªânh guidelines n·∫øu c·∫ßn\")\n",
    "    print(\"6. Tri·ªÉn khai annotation to√†n b·ªô\")\n",
    "    \n",
    "    # Hi·ªÉn th·ªã character profile\n",
    "    print(\"\\nüë§ CHARACTER PROFILE:\")\n",
    "    profile = guidelines.character_profile\n",
    "    print(f\"Name: {profile.name}\")\n",
    "    print(f\"Age: {profile.age}\")\n",
    "    print(f\"Background: {profile.background}\")\n",
    "    print(f\"Personality: {', '.join(profile.personality_traits[:3])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ed6b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Kh·ªüi ƒë·ªông NPC Dialogue Annotation Tool...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "unrecognized token: \"#\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1045\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müöÄ Kh·ªüi ƒë·ªông NPC Dialogue Annotation Tool...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1044\u001b[39m \u001b[38;5;66;03m# T·∫°o database\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1045\u001b[39m db = \u001b[43mAnnotationDatabase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[38;5;66;03m# T·∫°o HTML template\u001b[39;00m\n\u001b[32m   1048\u001b[39m create_html_template()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mAnnotationDatabase.__init__\u001b[39m\u001b[34m(self, db_path)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, db_path=\u001b[33m\"\u001b[39m\u001b[33mannotations.db\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m.db_path = db_path\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_database\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 58\u001b[39m, in \u001b[36mAnnotationDatabase._init_database\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m cursor.execute(\u001b[33m'''\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[33m    CREATE TABLE IF NOT EXISTS tasks (\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[33m        id INTEGER PRIMARY KEY AUTOINCREMENT,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33m    )\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m\u001b[39m\u001b[33m'''\u001b[39m)\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# B·∫£ng annotations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'''\u001b[39;49m\n\u001b[32m     59\u001b[39m \u001b[33;43m    CREATE TABLE IF NOT EXISTS annotations (\u001b[39;49m\n\u001b[32m     60\u001b[39m \u001b[33;43m        id INTEGER PRIMARY KEY AUTOINCREMENT,\u001b[39;49m\n\u001b[32m     61\u001b[39m \u001b[33;43m        task_id INTEGER NOT NULL,\u001b[39;49m\n\u001b[32m     62\u001b[39m \u001b[33;43m        annotator_id INTEGER NOT NULL,\u001b[39;49m\n\u001b[32m     63\u001b[39m \u001b[33;43m        npc_response TEXT NOT NULL,\u001b[39;49m\n\u001b[32m     64\u001b[39m \u001b[33;43m        npc_state TEXT NOT NULL,\u001b[39;49m\n\u001b[32m     65\u001b[39m \u001b[33;43m        emotional_intensity INTEGER CHECK(emotional_intensity BETWEEN 1 AND 5),\u001b[39;49m\n\u001b[32m     66\u001b[39m \u001b[33;43m        dialogue_acts TEXT,  # JSON array\u001b[39;49m\n\u001b[32m     67\u001b[39m \u001b[33;43m        quality_naturalness INTEGER CHECK(quality_naturalness BETWEEN 1 AND 5),\u001b[39;49m\n\u001b[32m     68\u001b[39m \u001b[33;43m        quality_consistency INTEGER CHECK(quality_consistency BETWEEN 1 AND 5),\u001b[39;49m\n\u001b[32m     69\u001b[39m \u001b[33;43m        quality_appropriateness INTEGER CHECK(quality_appropriateness BETWEEN 1 AND 5),\u001b[39;49m\n\u001b[32m     70\u001b[39m \u001b[33;43m        confidence_score INTEGER CHECK(confidence_score BETWEEN 1 AND 5),\u001b[39;49m\n\u001b[32m     71\u001b[39m \u001b[33;43m        annotation_time_seconds INTEGER,\u001b[39;49m\n\u001b[32m     72\u001b[39m \u001b[33;43m        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\u001b[39;49m\n\u001b[32m     73\u001b[39m \u001b[33;43m        FOREIGN KEY (task_id) REFERENCES tasks (id),\u001b[39;49m\n\u001b[32m     74\u001b[39m \u001b[33;43m        FOREIGN KEY (annotator_id) REFERENCES annotators (id)\u001b[39;49m\n\u001b[32m     75\u001b[39m \u001b[33;43m    )\u001b[39;49m\n\u001b[32m     76\u001b[39m \u001b[33;43m\u001b[39;49m\u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# B·∫£ng gold standards (cho t√≠nh IAA)\u001b[39;00m\n\u001b[32m     79\u001b[39m cursor.execute(\u001b[33m'''\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[33m    CREATE TABLE IF NOT EXISTS gold_standards (\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[33m        task_id INTEGER PRIMARY KEY,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     87\u001b[39m \u001b[33m    )\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[33m\u001b[39m\u001b[33m'''\u001b[39m)\n",
      "\u001b[31mOperationalError\u001b[39m: unrecognized token: \"#\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "annotation_tool.py\n",
    "\n",
    "D·ª±a tr√™n nghi√™n c·ª©u \"Prodigy: A New Annotation Tool for Efficient Data Collection\" (2022)\n",
    "v√† \"Best Practices for Annotation Interface Design\" (HCI 2023)\n",
    "\"\"\"\n",
    "\n",
    "from flask import Flask, render_template, request, jsonify, session\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "import random\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'npcdialogue_annotation_secure_key'\n",
    "\n",
    "class AnnotationDatabase:\n",
    "    \"\"\"Database management d·ª±a tr√™n SQLite\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path=\"annotations.db\"):\n",
    "        self.db_path = db_path\n",
    "        self._init_database()\n",
    "    \n",
    "    def _init_database(self):\n",
    "        \"\"\"Kh·ªüi t·∫°o database schema\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # B·∫£ng annotators\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS annotators (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                username TEXT UNIQUE NOT NULL,\n",
    "                experience_level TEXT CHECK(experience_level IN ('beginner', 'intermediate', 'expert')),\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                total_annotations INTEGER DEFAULT 0,\n",
    "                avg_quality_score REAL DEFAULT 0.0\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # B·∫£ng annotation tasks\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS tasks (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                player_message TEXT NOT NULL,\n",
    "                context TEXT,\n",
    "                npc_state TEXT CHECK(npc_state IN ('normal', 'alert', 'combat', 'injured')),\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                assigned_to INTEGER,\n",
    "                completed BOOLEAN DEFAULT FALSE,\n",
    "                FOREIGN KEY (assigned_to) REFERENCES annotators (id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # B·∫£ng annotations\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS annotations (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                task_id INTEGER NOT NULL,\n",
    "                annotator_id INTEGER NOT NULL,\n",
    "                npc_response TEXT NOT NULL,\n",
    "                npc_state TEXT NOT NULL,\n",
    "                emotional_intensity INTEGER CHECK(emotional_intensity BETWEEN 1 AND 5),\n",
    "                dialogue_acts TEXT,  # JSON array\n",
    "                quality_naturalness INTEGER CHECK(quality_naturalness BETWEEN 1 AND 5),\n",
    "                quality_consistency INTEGER CHECK(quality_consistency BETWEEN 1 AND 5),\n",
    "                quality_appropriateness INTEGER CHECK(quality_appropriateness BETWEEN 1 AND 5),\n",
    "                confidence_score INTEGER CHECK(confidence_score BETWEEN 1 AND 5),\n",
    "                annotation_time_seconds INTEGER,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (task_id) REFERENCES tasks (id),\n",
    "                FOREIGN KEY (annotator_id) REFERENCES annotators (id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        # B·∫£ng gold standards (cho t√≠nh IAA)\n",
    "        cursor.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS gold_standards (\n",
    "                task_id INTEGER PRIMARY KEY,\n",
    "                expert_response TEXT NOT NULL,\n",
    "                expert_state TEXT NOT NULL,\n",
    "                created_by TEXT,\n",
    "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (task_id) REFERENCES tasks (id)\n",
    "            )\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    \n",
    "    def create_annotator(self, username: str, experience_level: str = \"beginner\") -> int:\n",
    "        \"\"\"T·∫°o annotator m·ªõi\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO annotators (username, experience_level)\n",
    "                VALUES (?, ?)\n",
    "            ''', (username, experience_level))\n",
    "            \n",
    "            annotator_id = cursor.lastrowid\n",
    "            conn.commit()\n",
    "            return annotator_id\n",
    "            \n",
    "        except sqlite3.IntegrityError:\n",
    "            # Username ƒë√£ t·ªìn t·∫°i\n",
    "            cursor.execute('SELECT id FROM annotators WHERE username = ?', (username,))\n",
    "            result = cursor.fetchone()\n",
    "            return result[0] if result else None\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def add_task(self, player_message: str, context: str = None, \n",
    "                 npc_state: str = None, assign_to: int = None) -> int:\n",
    "        \"\"\"Th√™m task m·ªõi\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('''\n",
    "            INSERT INTO tasks (player_message, context, npc_state, assigned_to)\n",
    "            VALUES (?, ?, ?, ?)\n",
    "        ''', (player_message, context, npc_state, assign_to))\n",
    "        \n",
    "        task_id = cursor.lastrowid\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        \n",
    "        return task_id\n",
    "    \n",
    "    def get_next_task(self, annotator_id: int) -> Dict:\n",
    "        \"\"\"L·∫•y task ti·∫øp theo cho annotator\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        conn.row_factory = sqlite3.Row\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # L·∫•y task ch∆∞a ho√†n th√†nh, ∆∞u ti√™n task ƒë∆∞·ª£c assign\n",
    "        cursor.execute('''\n",
    "            SELECT t.id, t.player_message, t.context, t.npc_state\n",
    "            FROM tasks t\n",
    "            LEFT JOIN annotations a ON t.id = a.task_id AND a.annotator_id = ?\n",
    "            WHERE a.id IS NULL \n",
    "            AND (t.assigned_to IS NULL OR t.assigned_to = ?)\n",
    "            AND t.completed = FALSE\n",
    "            ORDER BY t.assigned_to DESC, RANDOM()\n",
    "            LIMIT 1\n",
    "        ''', (annotator_id, annotator_id))\n",
    "        \n",
    "        task = cursor.fetchone()\n",
    "        conn.close()\n",
    "        \n",
    "        return dict(task) if task else None\n",
    "    \n",
    "    def save_annotation(self, annotator_id: int, task_id: int, \n",
    "                       annotation_data: Dict) -> bool:\n",
    "        \"\"\"L∆∞u annotation\"\"\"\n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        try:\n",
    "            cursor.execute('''\n",
    "                INSERT INTO annotations (\n",
    "                    task_id, annotator_id, npc_response, npc_state,\n",
    "                    emotional_intensity, dialogue_acts,\n",
    "                    quality_naturalness, quality_consistency, quality_appropriateness,\n",
    "                    confidence_score, annotation_time_seconds\n",
    "                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                task_id,\n",
    "                annotator_id,\n",
    "                annotation_data['npc_response'],\n",
    "                annotation_data['npc_state'],\n",
    "                annotation_data['emotional_intensity'],\n",
    "                json.dumps(annotation_data['dialogue_acts']),\n",
    "                annotation_data['quality_naturalness'],\n",
    "                annotation_data['quality_consistency'],\n",
    "                annotation_data['quality_appropriateness'],\n",
    "                annotation_data['confidence_score'],\n",
    "                annotation_data.get('annotation_time_seconds', 0)\n",
    "            ))\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t task l√† completed\n",
    "            cursor.execute('''\n",
    "                UPDATE tasks SET completed = TRUE WHERE id = ?\n",
    "            ''', (task_id,))\n",
    "            \n",
    "            # C·∫≠p nh·∫≠t annotator stats\n",
    "            cursor.execute('''\n",
    "                UPDATE annotators \n",
    "                SET total_annotations = total_annotations + 1\n",
    "                WHERE id = ?\n",
    "            ''', (annotator_id,))\n",
    "            \n",
    "            conn.commit()\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving annotation: {e}\")\n",
    "            return False\n",
    "        finally:\n",
    "            conn.close()\n",
    "\n",
    "class AnnotationTaskGenerator:\n",
    "    \"\"\"T·∫°o annotation tasks t·ª´ base data v√† templates\"\"\"\n",
    "    \n",
    "    def __init__(self, db: AnnotationDatabase):\n",
    "        self.db = db\n",
    "        self.templates = self._load_templates()\n",
    "    \n",
    "    def _load_templates(self) -> Dict:\n",
    "        \"\"\"Load templates t·ª´ research on dialogue generation\"\"\"\n",
    "        return {\n",
    "            \"player_messages\": [\n",
    "                # Normal state\n",
    "                \"Xin ch√†o\",\n",
    "                \"Hello\",\n",
    "                \"Anh ƒëang l√†m g√¨ th·∫ø?\",\n",
    "                \"H√¥m nay tr·ªùi ƒë·∫πp nh·ªâ\",\n",
    "                \"Cho t√¥i qua c·ªïng ƒë∆∞·ª£c kh√¥ng?\",\n",
    "                \"C√≥ g√¨ vui kh√¥ng?\",\n",
    "                \"(ƒê·ª©ng im nh√¨n)\",\n",
    "                \"T√¥i mu·ªën g·∫∑p ch·ªâ huy\",\n",
    "                \"Ch·ªó n√†y l√† ƒë√¢u?\",\n",
    "                \"Tr√¥ng anh c√≥ v·∫ª m·ªát\",\n",
    "                \n",
    "                # Alert state\n",
    "                \"T√¥i ch·ªâ mu·ªën ƒëi qua th√¥i\",\n",
    "                \"C√≥ chuy·ªán g√¨ th·∫ø?\",\n",
    "                \"(Ti·∫øp t·ª•c ƒëi t·ªõi)\",\n",
    "                \"Anh l√†m g√¨ cƒÉng th·∫ø?\",\n",
    "                \"T√¥i kh√¥ng s·ª£ ƒë√¢u\",\n",
    "                \"Cho t√¥i v√†o ƒëi m√†\",\n",
    "                \"(R√∫t s√∫ng ra)\",\n",
    "                \"Tr√°nh ƒë∆∞·ªùng ra!\",\n",
    "                \n",
    "                # Combat state\n",
    "                \"Ta s·∫Ω gi·∫øt ng∆∞∆°i!\",\n",
    "                \"(T·∫•n c√¥ng)\",\n",
    "                \"Tha cho t√¥i!\",\n",
    "                \"D·ª´ng l·∫°i ƒëi!\",\n",
    "                \"Ng∆∞∆°i y·∫øu qu√°\",\n",
    "                \"√Å!!!\",\n",
    "                \"Ta ƒë·∫ßu h√†ng\",\n",
    "                \"(B·ªè ch·∫°y)\",\n",
    "                \n",
    "                # Injured state\n",
    "                \"Ng∆∞∆°i thua r·ªìi\",\n",
    "                \"(Chƒ©a s√∫ng v√†o)\",\n",
    "                \"C√∫t ƒëi\",\n",
    "                \"ƒê·ª©ng d·∫≠y chi·∫øn ƒë·∫•u ƒëi!\",\n",
    "                \"C√≥ c·∫ßn gi√∫p kh√¥ng?\",\n",
    "                \"Ta s·∫Ω tha cho ng∆∞∆°i\",\n",
    "                \"(Nh√¨n ch·∫±m ch·∫±m)\",\n",
    "                \"T·∫°i sao ng∆∞∆°i t·∫•n c√¥ng ta?\"\n",
    "            ],\n",
    "            \n",
    "            \"contexts\": [\n",
    "                \"\",\n",
    "                \"Th·ªùi gian: ban ng√†y, ƒë·ªãa ƒëi·ªÉm: c·ªïng th√†nh ph√≠a B·∫Øc\",\n",
    "                \"Th·ªùi gian: ban ƒë√™m, tr·ªùi m∆∞a\",\n",
    "                \"NPC v·ª´a ho√†n th√†nh nhi·ªám v·ª• tu·∫ßn tra\",\n",
    "                \"NPC ph√°t hi·ªán k·∫ª ƒë√°ng ng·ªù t·ª´ xa\",\n",
    "                \"NPC ƒëang ki·ªÉm tra v≈© kh√≠\",\n",
    "                \"Tr·∫≠n chi·∫øn v·ª´a b·∫Øt ƒë·∫ßu\",\n",
    "                \"NPC b·ªã th∆∞∆°ng n·∫∑ng, m√°u ch·∫£y nhi·ªÅu\"\n",
    "            ],\n",
    "            \n",
    "            \"state_hints\": {\n",
    "                \"normal\": [\"ƒëi tu·∫ßn\", \"b√¨nh th∆∞·ªùng\", \"y√™n tƒ©nh\"],\n",
    "                \"alert\": [\"c·∫£nh gi√°c\", \"nghi ng·ªù\", \"c·∫£nh b√°o\"],\n",
    "                \"combat\": [\"chi·∫øn ƒë·∫•u\", \"t·∫•n c√¥ng\", \"hung hƒÉng\"],\n",
    "                \"injured\": [\"b·ªã th∆∞∆°ng\", \"y·∫øu\", \"ƒëau ƒë·ªõn\"]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def generate_pilot_tasks(self, num_tasks=20) -> List[int]:\n",
    "        \"\"\"T·∫°o pilot tasks cho inter-annotator agreement\"\"\"\n",
    "        task_ids = []\n",
    "        \n",
    "        # T·∫°o gold standard tasks (m·ªói state 2 tasks)\n",
    "        gold_tasks = [\n",
    "            # Normal - gold\n",
    "            (\"Xin ch√†o\", \"\", \"normal\"),\n",
    "            (\"Tr·ªùi h√¥m nay ƒë·∫πp nh·ªâ\", \"Th·ªùi gian: ban ng√†y\", \"normal\"),\n",
    "            \n",
    "            # Alert - gold  \n",
    "            (\"Cho t√¥i qua ƒëi\", \"\", \"alert\"),\n",
    "            (\"(Ti·∫øp t·ª•c ƒëi t·ªõi)\", \"Player b·ªã c·∫£nh b√°o r·ªìi\", \"alert\"),\n",
    "            \n",
    "            # Combat - gold\n",
    "            (\"Ta s·∫Ω gi·∫øt ng∆∞∆°i!\", \"\", \"combat\"),\n",
    "            (\"(T·∫•n c√¥ng)\", \"Tr·∫≠n chi·∫øn b·∫Øt ƒë·∫ßu\", \"combat\"),\n",
    "            \n",
    "            # Injured - gold\n",
    "            (\"Ng∆∞∆°i thua r·ªìi\", \"\", \"injured\"),\n",
    "            (\"C√≥ c·∫ßn gi√∫p kh√¥ng?\", \"NPC b·ªã th∆∞∆°ng n·∫∑ng\", \"injured\"),\n",
    "        ]\n",
    "        \n",
    "        # Th√™m gold tasks\n",
    "        for player_msg, context, state in gold_tasks:\n",
    "            task_id = self.db.add_task(player_msg, context, state)\n",
    "            task_ids.append(task_id)\n",
    "        \n",
    "        # Th√™m random tasks\n",
    "        for _ in range(num_tasks - len(gold_tasks)):\n",
    "            player_msg = random.choice(self.templates[\"player_messages\"])\n",
    "            context = random.choice(self.templates[\"contexts\"])\n",
    "            state = random.choice([\"normal\", \"alert\", \"combat\", \"injured\"])\n",
    "            \n",
    "            task_id = self.db.add_task(player_msg, context, state)\n",
    "            task_ids.append(task_id)\n",
    "        \n",
    "        return task_ids\n",
    "\n",
    "# ==================== FLASK ROUTES ====================\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Trang ch·ªß\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/login', methods=['POST'])\n",
    "def login():\n",
    "    \"\"\"ƒêƒÉng nh·∫≠p annotator\"\"\"\n",
    "    username = request.json.get('username')\n",
    "    \n",
    "    if not username:\n",
    "        return jsonify({'error': 'Username required'}), 400\n",
    "    \n",
    "    db = AnnotationDatabase()\n",
    "    annotator_id = db.create_annotator(username)\n",
    "    \n",
    "    session['annotator_id'] = annotator_id\n",
    "    session['username'] = username\n",
    "    \n",
    "    return jsonify({\n",
    "        'annotator_id': annotator_id,\n",
    "        'username': username,\n",
    "        'message': 'Login successful'\n",
    "    })\n",
    "\n",
    "@app.route('/task')\n",
    "def get_task():\n",
    "    \"\"\"L·∫•y task ti·∫øp theo\"\"\"\n",
    "    if 'annotator_id' not in session:\n",
    "        return jsonify({'error': 'Not logged in'}), 401\n",
    "    \n",
    "    annotator_id = session['annotator_id']\n",
    "    db = AnnotationDatabase()\n",
    "    \n",
    "    task = db.get_next_task(annotator_id)\n",
    "    \n",
    "    if not task:\n",
    "        return jsonify({'message': 'No more tasks available'}), 404\n",
    "    \n",
    "    return jsonify({\n",
    "        'task': task,\n",
    "        'guidelines': {\n",
    "            'states': ['normal', 'alert', 'combat', 'injured'],\n",
    "            'emotional_intensity': list(range(1, 6)),\n",
    "            'quality_scale': list(range(1, 6))\n",
    "        }\n",
    "    })\n",
    "\n",
    "@app.route('/submit', methods=['POST'])\n",
    "def submit_annotation():\n",
    "    \"\"\"Submit annotation\"\"\"\n",
    "    if 'annotator_id' not in session:\n",
    "        return jsonify({'error': 'Not logged in'}), 401\n",
    "    \n",
    "    data = request.json\n",
    "    annotator_id = session['annotator_id']\n",
    "    \n",
    "    # Validate required fields\n",
    "    required_fields = ['task_id', 'npc_response', 'npc_state', \n",
    "                      'emotional_intensity', 'dialogue_acts',\n",
    "                      'quality_naturalness', 'quality_consistency', \n",
    "                      'quality_appropriateness', 'confidence_score']\n",
    "    \n",
    "    for field in required_fields:\n",
    "        if field not in data:\n",
    "            return jsonify({'error': f'Missing field: {field}'}), 400\n",
    "    \n",
    "    # Save to database\n",
    "    db = AnnotationDatabase()\n",
    "    success = db.save_annotation(annotator_id, data['task_id'], data)\n",
    "    \n",
    "    if success:\n",
    "        # Get annotator stats\n",
    "        conn = sqlite3.connect('annotations.db')\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute('SELECT total_annotations FROM annotators WHERE id = ?', (annotator_id,))\n",
    "        total = cursor.fetchone()[0]\n",
    "        conn.close()\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'total_annotations': total,\n",
    "            'message': 'Annotation saved successfully'\n",
    "        })\n",
    "    else:\n",
    "        return jsonify({'error': 'Failed to save annotation'}), 500\n",
    "\n",
    "@app.route('/stats')\n",
    "def get_stats():\n",
    "    \"\"\"L·∫•y statistics\"\"\"\n",
    "    if 'annotator_id' not in session:\n",
    "        return jsonify({'error': 'Not logged in'}), 401\n",
    "    \n",
    "    annotator_id = session['annotator_id']\n",
    "    \n",
    "    conn = sqlite3.connect('annotations.db')\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Annotator stats\n",
    "    cursor.execute('''\n",
    "        SELECT username, experience_level, total_annotations, avg_quality_score\n",
    "        FROM annotators WHERE id = ?\n",
    "    ''', (annotator_id,))\n",
    "    annotator_stats = dict(cursor.fetchone())\n",
    "    \n",
    "    # Daily progress\n",
    "    cursor.execute('''\n",
    "        SELECT DATE(created_at) as date, COUNT(*) as count\n",
    "        FROM annotations \n",
    "        WHERE annotator_id = ?\n",
    "        GROUP BY DATE(created_at)\n",
    "        ORDER BY date DESC\n",
    "        LIMIT 7\n",
    "    ''', (annotator_id,))\n",
    "    daily_progress = [dict(row) for row in cursor.fetchall()]\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return jsonify({\n",
    "        'annotator': annotator_stats,\n",
    "        'daily_progress': daily_progress\n",
    "    })\n",
    "\n",
    "# ==================== HTML TEMPLATES ====================\n",
    "\n",
    "INDEX_TEMPLATE = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"vi\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>NPC Dialogue Annotation Tool</title>\n",
    "    <style>\n",
    "        :root {\n",
    "            --primary: #2c3e50;\n",
    "            --secondary: #3498db;\n",
    "            --success: #27ae60;\n",
    "            --warning: #f39c12;\n",
    "            --danger: #e74c3c;\n",
    "            --light: #ecf0f1;\n",
    "            --dark: #2c3e50;\n",
    "        }\n",
    "        \n",
    "        body {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "            min-height: 100vh;\n",
    "            margin: 0;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        \n",
    "        .container {\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            background: white;\n",
    "            border-radius: 15px;\n",
    "            box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        \n",
    "        .header {\n",
    "            background: var(--primary);\n",
    "            color: white;\n",
    "            padding: 30px;\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .header h1 {\n",
    "            margin: 0;\n",
    "            font-size: 2.5em;\n",
    "        }\n",
    "        \n",
    "        .header p {\n",
    "            margin: 10px 0 0;\n",
    "            opacity: 0.8;\n",
    "        }\n",
    "        \n",
    "        .main-content {\n",
    "            padding: 30px;\n",
    "            display: flex;\n",
    "            gap: 30px;\n",
    "        }\n",
    "        \n",
    "        .left-panel {\n",
    "            flex: 1;\n",
    "            background: var(--light);\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "        }\n",
    "        \n",
    "        .right-panel {\n",
    "            flex: 2;\n",
    "        }\n",
    "        \n",
    "        .login-form {\n",
    "            text-align: center;\n",
    "        }\n",
    "        \n",
    "        .login-form input {\n",
    "            width: 80%;\n",
    "            padding: 12px;\n",
    "            margin: 10px 0;\n",
    "            border: 2px solid #ddd;\n",
    "            border-radius: 8px;\n",
    "            font-size: 16px;\n",
    "            transition: border-color 0.3s;\n",
    "        }\n",
    "        \n",
    "        .login-form input:focus {\n",
    "            outline: none;\n",
    "            border-color: var(--secondary);\n",
    "        }\n",
    "        \n",
    "        .btn {\n",
    "            background: var(--secondary);\n",
    "            color: white;\n",
    "            border: none;\n",
    "            padding: 12px 30px;\n",
    "            border-radius: 8px;\n",
    "            font-size: 16px;\n",
    "            cursor: pointer;\n",
    "            transition: all 0.3s;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        \n",
    "        .btn:hover {\n",
    "            background: #2980b9;\n",
    "            transform: translateY(-2px);\n",
    "        }\n",
    "        \n",
    "        .btn-success {\n",
    "            background: var(--success);\n",
    "        }\n",
    "        \n",
    "        .btn-success:hover {\n",
    "            background: #219653;\n",
    "        }\n",
    "        \n",
    "        .task-container {\n",
    "            background: white;\n",
    "            border: 2px solid var(--light);\n",
    "            border-radius: 10px;\n",
    "            padding: 25px;\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        \n",
    "        .player-message {\n",
    "            background: #e8f4fc;\n",
    "            padding: 20px;\n",
    "            border-radius: 8px;\n",
    "            margin-bottom: 20px;\n",
    "            border-left: 4px solid var(--secondary);\n",
    "        }\n",
    "        \n",
    "        .player-message h3 {\n",
    "            margin: 0 0 10px 0;\n",
    "            color: var(--primary);\n",
    "        }\n",
    "        \n",
    "        .context-box {\n",
    "            background: #fff8e1;\n",
    "            padding: 15px;\n",
    "            border-radius: 8px;\n",
    "            margin-bottom: 20px;\n",
    "            font-style: italic;\n",
    "            color: #666;\n",
    "        }\n",
    "        \n",
    "        .form-group {\n",
    "            margin-bottom: 20px;\n",
    "        }\n",
    "        \n",
    "        label {\n",
    "            display: block;\n",
    "            margin-bottom: 8px;\n",
    "            font-weight: bold;\n",
    "            color: var(--dark);\n",
    "        }\n",
    "        \n",
    "        textarea {\n",
    "            width: 100%;\n",
    "            padding: 12px;\n",
    "            border: 2px solid #ddd;\n",
    "            border-radius: 8px;\n",
    "            font-size: 16px;\n",
    "            font-family: inherit;\n",
    "            resize: vertical;\n",
    "            min-height: 100px;\n",
    "        }\n",
    "        \n",
    "        textarea:focus {\n",
    "            outline: none;\n",
    "            border-color: var(--secondary);\n",
    "        }\n",
    "        \n",
    "        .radio-group {\n",
    "            display: flex;\n",
    "            gap: 20px;\n",
    "            flex-wrap: wrap;\n",
    "        }\n",
    "        \n",
    "        .radio-item {\n",
    "            flex: 1;\n",
    "            min-width: 120px;\n",
    "        }\n",
    "        \n",
    "        .radio-item input {\n",
    "            margin-right: 8px;\n",
    "        }\n",
    "        \n",
    "        .quality-slider {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            gap: 10px;\n",
    "        }\n",
    "        \n",
    "        .slider-value {\n",
    "            font-weight: bold;\n",
    "            color: var(--secondary);\n",
    "            min-width: 30px;\n",
    "        }\n",
    "        \n",
    "        input[type=\"range\"] {\n",
    "            flex: 1;\n",
    "        }\n",
    "        \n",
    "        .stats-panel {\n",
    "            background: var(--light);\n",
    "            padding: 20px;\n",
    "            border-radius: 10px;\n",
    "            margin-top: 20px;\n",
    "        }\n",
    "        \n",
    "        .stat-item {\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            padding: 8px 0;\n",
    "            border-bottom: 1px solid #ddd;\n",
    "        }\n",
    "        \n",
    "        .stat-value {\n",
    "            font-weight: bold;\n",
    "            color: var(--secondary);\n",
    "        }\n",
    "        \n",
    "        .state-indicator {\n",
    "            display: inline-block;\n",
    "            padding: 4px 12px;\n",
    "            border-radius: 20px;\n",
    "            font-size: 12px;\n",
    "            font-weight: bold;\n",
    "            text-transform: uppercase;\n",
    "        }\n",
    "        \n",
    "        .state-normal { background: #d4edda; color: #155724; }\n",
    "        .state-alert { background: #fff3cd; color: #856404; }\n",
    "        .state-combat { background: #f8d7da; color: #721c24; }\n",
    "        .state-injured { background: #d1ecf1; color: #0c5460; }\n",
    "        \n",
    "        .emotion-scale {\n",
    "            display: flex;\n",
    "            justify-content: space-between;\n",
    "            margin-top: 5px;\n",
    "        }\n",
    "        \n",
    "        .emotion-level {\n",
    "            text-align: center;\n",
    "            font-size: 12px;\n",
    "            color: #666;\n",
    "        }\n",
    "        \n",
    "        .progress-bar {\n",
    "            width: 100%;\n",
    "            height: 10px;\n",
    "            background: #ddd;\n",
    "            border-radius: 5px;\n",
    "            margin: 20px 0;\n",
    "            overflow: hidden;\n",
    "        }\n",
    "        \n",
    "        .progress-fill {\n",
    "            height: 100%;\n",
    "            background: var(--success);\n",
    "            transition: width 0.3s;\n",
    "        }\n",
    "        \n",
    "        @media (max-width: 768px) {\n",
    "            .main-content {\n",
    "                flex-direction: column;\n",
    "            }\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container\">\n",
    "        <div class=\"header\">\n",
    "            <h1>üè∞ NPC Dialogue Annotation</h1>\n",
    "            <p>H·ªó tr·ª£ nghi√™n c·ª©u AI cho Game NPC - Phi√™n b·∫£n Beta</p>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"main-content\">\n",
    "            <div class=\"left-panel\">\n",
    "                <div id=\"login-section\">\n",
    "                    <div class=\"login-form\">\n",
    "                        <h3>üîê ƒêƒÉng nh·∫≠p</h3>\n",
    "                        <input type=\"text\" id=\"username\" placeholder=\"T√™n annotator c·ªßa b·∫°n\">\n",
    "                        <button class=\"btn\" onclick=\"login()\">B·∫Øt ƒë·∫ßu annotation</button>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \n",
    "                <div id=\"stats-section\" style=\"display: none;\">\n",
    "                    <div class=\"stats-panel\">\n",
    "                        <h3>üìä Th·ªëng k√™ c·ªßa b·∫°n</h3>\n",
    "                        <div class=\"stat-item\">\n",
    "                            <span>T·ªïng annotations:</span>\n",
    "                            <span class=\"stat-value\" id=\"total-annotations\">0</span>\n",
    "                        </div>\n",
    "                        <div class=\"stat-item\">\n",
    "                            <span>H√¥m nay:</span>\n",
    "                            <span class=\"stat-value\" id=\"today-annotations\">0</span>\n",
    "                        </div>\n",
    "                        <div class=\"stat-item\">\n",
    "                            <span>Ch·∫•t l∆∞·ª£ng trung b√¨nh:</span>\n",
    "                            <span class=\"stat-value\" id=\"avg-quality\">0.0</span>\n",
    "                        </div>\n",
    "                        <div class=\"progress-bar\">\n",
    "                            <div class=\"progress-fill\" id=\"progress-fill\" style=\"width: 0%\"></div>\n",
    "                        </div>\n",
    "                        <p style=\"text-align: center; font-size: 14px; color: #666;\">\n",
    "                            M·ª•c ti√™u: 20 annotations/ng√†y\n",
    "                        </p>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \n",
    "            <div class=\"right-panel\">\n",
    "                <div id=\"task-section\" style=\"display: none;\">\n",
    "                    <div class=\"task-container\">\n",
    "                        <div class=\"player-message\">\n",
    "                            <h3>üí¨ Player Message:</h3>\n",
    "                            <p id=\"player-message-text\">...</p>\n",
    "                        </div>\n",
    "                        \n",
    "                        <div class=\"context-box\" id=\"context-box\" style=\"display: none;\">\n",
    "                            <strong>üìå Context:</strong> \n",
    "                            <span id=\"context-text\">...</span>\n",
    "                        </div>\n",
    "                        \n",
    "                        <form id=\"annotation-form\">\n",
    "                            <div class=\"form-group\">\n",
    "                                <label for=\"npc-response\">‚úçÔ∏è NPC Response (1-2 c√¢u):</label>\n",
    "                                <textarea id=\"npc-response\" placeholder=\"Nh·∫≠p c√¢u tr·∫£ l·ªùi c·ªßa NPC...\"></textarea>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üé≠ NPC State:</label>\n",
    "                                <div class=\"radio-group\">\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"radio\" id=\"state-normal\" name=\"npc-state\" value=\"normal\">\n",
    "                                        <label for=\"state-normal\" class=\"state-indicator state-normal\">Normal</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"radio\" id=\"state-alert\" name=\"npc-state\" value=\"alert\">\n",
    "                                        <label for=\"state-alert\" class=\"state-indicator state-alert\">Alert</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"radio\" id=\"state-combat\" name=\"npc-state\" value=\"combat\">\n",
    "                                        <label for=\"state-combat\" class=\"state-indicator state-combat\">Combat</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"radio\" id=\"state-injured\" name=\"npc-state\" value=\"injured\">\n",
    "                                        <label for=\"state-injured\" class=\"state-indicator state-injured\">Injured</label>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üò† Emotional Intensity:</label>\n",
    "                                <div class=\"quality-slider\">\n",
    "                                    <span class=\"slider-value\" id=\"emotion-value\">3</span>\n",
    "                                    <input type=\"range\" id=\"emotional-intensity\" min=\"1\" max=\"5\" value=\"3\" \n",
    "                                           oninput=\"document.getElementById('emotion-value').textContent = this.value\">\n",
    "                                </div>\n",
    "                                <div class=\"emotion-scale\">\n",
    "                                    <div class=\"emotion-level\">1: Neutral</div>\n",
    "                                    <div class=\"emotion-level\">2: Mild</div>\n",
    "                                    <div class=\"emotion-level\">3: Medium</div>\n",
    "                                    <div class=\"emotion-level\">4: Strong</div>\n",
    "                                    <div class=\"emotion-level\">5: Very Strong</div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üó£Ô∏è Dialogue Acts (ch·ªçn t·∫•t c·∫£ ph√π h·ª£p):</label>\n",
    "                                <div class=\"radio-group\">\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"checkbox\" id=\"act-greeting\" value=\"greeting\">\n",
    "                                        <label for=\"act-greeting\">Greeting</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"checkbox\" id=\"act-threat\" value=\"threat\">\n",
    "                                        <label for=\"act-threat\">Threat</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"checkbox\" id=\"act-surrender\" value=\"surrender\">\n",
    "                                        <label for=\"act-surrender\">Surrender</label>\n",
    "                                    </div>\n",
    "                                    <div class=\"radio-item\">\n",
    "                                        <input type=\"checkbox\" id=\"act-request\" value=\"request\">\n",
    "                                        <label for=\"act-request\">Request</label>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <h3>üìù Quality Assessment:</h3>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üéØ Naturalness:</label>\n",
    "                                <div class=\"quality-slider\">\n",
    "                                    <span class=\"slider-value\" id=\"naturalness-value\">3</span>\n",
    "                                    <input type=\"range\" id=\"quality-naturalness\" min=\"1\" max=\"5\" value=\"3\"\n",
    "                                           oninput=\"document.getElementById('naturalness-value').textContent = this.value\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üë§ Character Consistency:</label>\n",
    "                                <div class=\"quality-slider\">\n",
    "                                    <span class=\"slider-value\" id=\"consistency-value\">3</span>\n",
    "                                    <input type=\"range\" id=\"quality-consistency\" min=\"1\" max=\"5\" value=\"3\"\n",
    "                                           oninput=\"document.getElementById('consistency-value').textContent = this.value\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>‚úÖ Appropriateness:</label>\n",
    "                                <div class=\"quality-slider\">\n",
    "                                    <span class=\"slider-value\" id=\"appropriateness-value\">3</span>\n",
    "                                    <input type=\"range\" id=\"quality-appropriateness\" min=\"1\" max=\"5\" value=\"3\"\n",
    "                                           oninput=\"document.getElementById('appropriateness-value').textContent = this.value\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div class=\"form-group\">\n",
    "                                <label>üí™ Confidence in your annotation:</label>\n",
    "                                <div class=\"quality-slider\">\n",
    "                                    <span class=\"slider-value\" id=\"confidence-value\">3</span>\n",
    "                                    <input type=\"range\" id=\"confidence-score\" min=\"1\" max=\"5\" value=\"3\"\n",
    "                                           oninput=\"document.getElementById('confidence-value').textContent = this.value\">\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            \n",
    "                            <div style=\"text-align: center; margin-top: 30px;\">\n",
    "                                <button type=\"button\" class=\"btn btn-success\" onclick=\"submitAnnotation()\">\n",
    "                                    ‚úÖ Submit Annotation\n",
    "                                </button>\n",
    "                                <button type=\"button\" class=\"btn\" onclick=\"skipTask()\" style=\"margin-left: 10px;\">\n",
    "                                    ‚è≠Ô∏è Skip Task\n",
    "                                </button>\n",
    "                            </div>\n",
    "                        </form>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \n",
    "                <div id=\"completed-section\" style=\"display: none; text-align: center; padding: 50px;\">\n",
    "                    <h2>üéâ Ho√†n th√†nh!</h2>\n",
    "                    <p>B·∫°n ƒë√£ ho√†n th√†nh t·∫•t c·∫£ tasks hi·ªán c√≥.</p>\n",
    "                    <p>C·∫£m ∆°n b·∫°n ƒë√£ ƒë√≥ng g√≥p cho nghi√™n c·ª©u!</p>\n",
    "                    <button class=\"btn\" onclick=\"loadStats()\">Xem th·ªëng k√™</button>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        let currentTask = null;\n",
    "        let startTime = null;\n",
    "        \n",
    "        async function login() {\n",
    "            const username = document.getElementById('username').value;\n",
    "            if (!username) {\n",
    "                alert('Vui l√≤ng nh·∫≠p t√™n annotator');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            const response = await fetch('/login', {\n",
    "                method: 'POST',\n",
    "                headers: {'Content-Type': 'application/json'},\n",
    "                body: JSON.stringify({username})\n",
    "            });\n",
    "            \n",
    "            if (response.ok) {\n",
    "                document.getElementById('login-section').style.display = 'none';\n",
    "                document.getElementById('stats-section').style.display = 'block';\n",
    "                document.getElementById('task-section').style.display = 'block';\n",
    "                await loadStats();\n",
    "                await getNextTask();\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        async function getNextTask() {\n",
    "            startTime = Date.now();\n",
    "            const response = await fetch('/task');\n",
    "            \n",
    "            if (response.status === 404) {\n",
    "                document.getElementById('task-section').style.display = 'none';\n",
    "                document.getElementById('completed-section').style.display = 'block';\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            if (!response.ok) {\n",
    "                alert('L·ªói khi l·∫•y task');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            const data = await response.json();\n",
    "            currentTask = data.task;\n",
    "            \n",
    "            document.getElementById('player-message-text').textContent = currentTask.player_message;\n",
    "            \n",
    "            if (currentTask.context) {\n",
    "                document.getElementById('context-box').style.display = 'block';\n",
    "                document.getElementById('context-text').textContent = currentTask.context;\n",
    "            } else {\n",
    "                document.getElementById('context-box').style.display = 'none';\n",
    "            }\n",
    "            \n",
    "            // Reset form\n",
    "            document.getElementById('annotation-form').reset();\n",
    "            document.getElementById('emotion-value').textContent = '3';\n",
    "            document.getElementById('naturalness-value').textContent = '3';\n",
    "            document.getElementById('consistency-value').textContent = '3';\n",
    "            document.getElementById('appropriateness-value').textContent = '3';\n",
    "            document.getElementById('confidence-value').textContent = '3';\n",
    "        }\n",
    "        \n",
    "        async function submitAnnotation() {\n",
    "            const annotationTime = Math.floor((Date.now() - startTime) / 1000);\n",
    "            \n",
    "            const dialogueActs = [];\n",
    "            ['greeting', 'threat', 'surrender', 'request'].forEach(act => {\n",
    "                if (document.getElementById(`act-${act}`).checked) {\n",
    "                    dialogueActs.push(act);\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            const annotationData = {\n",
    "                task_id: currentTask.id,\n",
    "                npc_response: document.getElementById('npc-response').value,\n",
    "                npc_state: document.querySelector('input[name=\"npc-state\"]:checked')?.value,\n",
    "                emotional_intensity: parseInt(document.getElementById('emotional-intensity').value),\n",
    "                dialogue_acts: dialogueActs,\n",
    "                quality_naturalness: parseInt(document.getElementById('quality-naturalness').value),\n",
    "                quality_consistency: parseInt(document.getElementById('quality-consistency').value),\n",
    "                quality_appropriateness: parseInt(document.getElementById('quality-appropriateness').value),\n",
    "                confidence_score: parseInt(document.getElementById('confidence-score').value),\n",
    "                annotation_time_seconds: annotationTime\n",
    "            };\n",
    "            \n",
    "            // Validation\n",
    "            if (!annotationData.npc_response.trim()) {\n",
    "                alert('Vui l√≤ng nh·∫≠p NPC response');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            if (!annotationData.npc_state) {\n",
    "                alert('Vui l√≤ng ch·ªçn NPC state');\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            const response = await fetch('/submit', {\n",
    "                method: 'POST',\n",
    "                headers: {'Content-Type': 'application/json'},\n",
    "                body: JSON.stringify(annotationData)\n",
    "            });\n",
    "            \n",
    "            if (response.ok) {\n",
    "                const result = await response.json();\n",
    "                alert('‚úÖ Annotation saved! Total: ' + result.total_annotations);\n",
    "                await loadStats();\n",
    "                await getNextTask();\n",
    "            } else {\n",
    "                alert('‚ùå Error saving annotation');\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        async function skipTask() {\n",
    "            await getNextTask();\n",
    "        }\n",
    "        \n",
    "        async function loadStats() {\n",
    "            const response = await fetch('/stats');\n",
    "            if (response.ok) {\n",
    "                const data = await response.json();\n",
    "                document.getElementById('total-annotations').textContent = data.annotator.total_annotations;\n",
    "                document.getElementById('avg-quality').textContent = data.annotator.avg_quality_score.toFixed(1);\n",
    "                \n",
    "                // Calculate today's annotations\n",
    "                const today = new Date().toISOString().split('T')[0];\n",
    "                const todayCount = data.daily_progress.find(d => d.date === today)?.count || 0;\n",
    "                document.getElementById('today-annotations').textContent = todayCount;\n",
    "                \n",
    "                // Update progress bar\n",
    "                const progress = (todayCount / 20) * 100;\n",
    "                document.getElementById('progress-fill').style.width = Math.min(progress, 100) + '%';\n",
    "            }\n",
    "        }\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# T·∫°o HTML template n·∫øu ch∆∞a t·ªìn t·∫°i\n",
    "def create_html_template():\n",
    "    \"\"\"T·∫°o HTML template cho annotation tool\"\"\"\n",
    "    os.makedirs(\"templates\", exist_ok=True)\n",
    "    \n",
    "    with open(\"templates/index.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(INDEX_TEMPLATE)\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Kh·ªüi ƒë·ªông NPC Dialogue Annotation Tool...\")\n",
    "    \n",
    "    # T·∫°o database\n",
    "    db = AnnotationDatabase()\n",
    "    \n",
    "    # T·∫°o HTML template\n",
    "    create_html_template()\n",
    "    \n",
    "    # T·∫°o pilot tasks\n",
    "    generator = AnnotationTaskGenerator(db)\n",
    "    task_ids = generator.generate_pilot_tasks(20)\n",
    "    print(f\"‚úÖ ƒê√£ t·∫°o {len(task_ids)} pilot tasks\")\n",
    "    \n",
    "    print(\"\\nüîß Database schema ƒë√£ s·∫µn s√†ng!\")\n",
    "    print(\"üìä Tables created:\")\n",
    "    print(\"  - annotators (l∆∞u th√¥ng tin annotator)\")\n",
    "    print(\"  - tasks (l∆∞u c√°c task c·∫ßn annotation)\")\n",
    "    print(\"  - annotations (l∆∞u k·∫øt qu·∫£ annotation)\")\n",
    "    print(\"  - gold_standards (l∆∞u gold standards cho IAA)\")\n",
    "    \n",
    "    print(\"\\nüåê Kh·ªüi ƒë·ªông web server...\")\n",
    "    print(\"üëâ Truy c·∫≠p: http://localhost:5000\")\n",
    "    print(\"üëâ Username test: annotator1, annotator2, annotator3\")\n",
    "    \n",
    "    # Kh·ªüi ƒë·ªông Flask app\n",
    "    app.run(debug=True, port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd22d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "quality_control.py\n",
    "\n",
    "D·ª±a tr√™n nghi√™n c·ª©u:\n",
    "1. \"Measuring Inter-Annotator Agreement for Dialogue Annotation\" (ACL 2022)\n",
    "2. \"Quality Control in Crowdsourced Annotation\" (EMNLP 2023)\n",
    "3. \"Fleiss' Kappa and Krippendorff's Alpha for Dialogue\" (2021)\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import itertools\n",
    "\n",
    "class InterAnnotatorAgreement:\n",
    "    \"\"\"T√≠nh to√°n Inter-Annotator Agreement d·ª±a tr√™n best practices\"\"\"\n",
    "    \n",
    "    def __init__(self, annotation_db_path=\"annotations.db\"):\n",
    "        self.db_path = annotation_db_path\n",
    "        self.results = {}\n",
    "        \n",
    "    def load_annotations(self) -> pd.DataFrame:\n",
    "        \"\"\"Load annotations t·ª´ database\"\"\"\n",
    "        import sqlite3\n",
    "        \n",
    "        conn = sqlite3.connect(self.db_path)\n",
    "        query = '''\n",
    "        SELECT \n",
    "            a.task_id,\n",
    "            a.annotator_id,\n",
    "            a.npc_response,\n",
    "            a.npc_state,\n",
    "            a.emotional_intensity,\n",
    "            a.dialogue_acts,\n",
    "            a.quality_naturalness,\n",
    "            a.quality_consistency,\n",
    "            a.quality_appropriateness,\n",
    "            t.player_message,\n",
    "            t.context\n",
    "        FROM annotations a\n",
    "        JOIN tasks t ON a.task_id = t.id\n",
    "        '''\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_fleiss_kappa(self, annotations_df: pd.DataFrame, \n",
    "                               task_ids: List[int] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        T√≠nh Fleiss' Kappa cho categorical variables\n",
    "        D·ª±a tr√™n \"The Measurement of Observer Agreement for Categorical Data\" (Fleiss, 1971)\n",
    "        \"\"\"\n",
    "        \n",
    "        if task_ids is None:\n",
    "            # L·∫•y c√°c tasks c√≥ √≠t nh·∫•t 3 annotations (cho pilot study)\n",
    "            task_counts = annotations_df['task_id'].value_counts()\n",
    "            task_ids = task_counts[task_counts >= 3].index.tolist()\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # 1. T√≠nh cho NPC State\n",
    "        state_kappa = self._calculate_fleiss_for_category(\n",
    "            annotations_df, task_ids, 'npc_state'\n",
    "        )\n",
    "        results['npc_state'] = {\n",
    "            'fleiss_kappa': state_kappa,\n",
    "            'interpretation': self._interpret_kappa(state_kappa)\n",
    "        }\n",
    "        \n",
    "        # 2. T√≠nh cho Emotional Intensity\n",
    "        emotion_kappa = self._calculate_fleiss_for_category(\n",
    "            annotations_df, task_ids, 'emotional_intensity'\n",
    "        )\n",
    "        results['emotional_intensity'] = {\n",
    "            'fleiss_kappa': emotion_kappa,\n",
    "            'interpretation': self._interpret_kappa(emotion_kappa)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _calculate_fleiss_for_category(self, df: pd.DataFrame, \n",
    "                                       task_ids: List[int], \n",
    "                                       category: str) -> float:\n",
    "        \"\"\"T√≠nh Fleiss' Kappa cho m·ªôt category c·ª• th·ªÉ\"\"\"\n",
    "        \n",
    "        # T·∫°o rating matrix\n",
    "        categories = sorted(df[category].unique())\n",
    "        n_categories = len(categories)\n",
    "        \n",
    "        # L·ªçc tasks c√≥ multiple annotations\n",
    "        multi_annot_tasks = []\n",
    "        for task_id in task_ids:\n",
    "            task_df = df[df['task_id'] == task_id]\n",
    "            if len(task_df) >= 2:  # √çt nh·∫•t 2 annotations\n",
    "                multi_annot_tasks.append(task_id)\n",
    "        \n",
    "        n_items = len(multi_annot_tasks)\n",
    "        if n_items == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # Kh·ªüi t·∫°o rating matrix\n",
    "        rating_matrix = np.zeros((n_items, n_categories))\n",
    "        \n",
    "        # ƒêi·ªÅn matrix\n",
    "        for i, task_id in enumerate(multi_annot_tasks):\n",
    "            task_df = df[df['task_id'] == task_id]\n",
    "            for annot_idx, row in task_df.iterrows():\n",
    "                cat_value = row[category]\n",
    "                cat_index = categories.index(cat_value)\n",
    "                rating_matrix[i, cat_index] += 1\n",
    "        \n",
    "        # T√≠nh Fleiss' Kappa\n",
    "        n_annotators = rating_matrix.sum(axis=1).mean()\n",
    "        \n",
    "        # T√≠nh Pj (proportion of assignments to category j)\n",
    "        Pj = rating_matrix.sum(axis=0) / (n_items * n_annotators)\n",
    "        \n",
    "        # T√≠nh Pi (proportion of agreeing pairs for item i)\n",
    "        Pi = ((rating_matrix ** 2).sum(axis=1) - n_annotators) / (n_annotators * (n_annotators - 1))\n",
    "        \n",
    "        # T√≠nh Pbar (mean of Pi)\n",
    "        Pbar = Pi.mean()\n",
    "        \n",
    "        # T√≠nh Pbar_e (expected agreement by chance)\n",
    "        Pbar_e = (Pj ** 2).sum()\n",
    "        \n",
    "        # T√≠nh Kappa\n",
    "        if Pbar_e == 1:\n",
    "            kappa = 1.0\n",
    "        else:\n",
    "            kappa = (Pbar - Pbar_e) / (1 - Pbar_e)\n",
    "        \n",
    "        return kappa\n",
    "    \n",
    "    def calculate_krippendorff_alpha(self, annotations_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        T√≠nh Krippendorff's Alpha - robust h∆°n cho small samples\n",
    "        D·ª±a tr√™n \"Content Analysis: An Introduction to Its Methodology\" (Krippendorff, 2018)\n",
    "        \"\"\"\n",
    "        \n",
    "        # ƒê∆°n gi·∫£n h√≥a: s·ª≠ d·ª•ng scipy's kendall tau cho ordinal data\n",
    "        results = {}\n",
    "        \n",
    "        # T√≠nh cho c√°c c·∫∑p annotators\n",
    "        annotator_pairs = self._get_annotator_pairs(annotations_df)\n",
    "        \n",
    "        alpha_scores = []\n",
    "        for ann1, ann2 in annotator_pairs:\n",
    "            # L·∫•y c√°c tasks m√† c·∫£ 2 c√πng annotate\n",
    "            common_tasks = self._get_common_tasks(annotations_df, ann1, ann2)\n",
    "            \n",
    "            if len(common_tasks) >= 2:\n",
    "                # T√≠nh agreement cho t·ª´ng category\n",
    "                for category in ['npc_state', 'emotional_intensity']:\n",
    "                    values1 = []\n",
    "                    values2 = []\n",
    "                    \n",
    "                    for task_id in common_tasks:\n",
    "                        val1 = annotations_df[\n",
    "                            (annotations_df['task_id'] == task_id) & \n",
    "                            (annotations_df['annotator_id'] == ann1)\n",
    "                        ][category].iloc[0]\n",
    "                        \n",
    "                        val2 = annotations_df[\n",
    "                            (annotations_df['task_id'] == task_id) & \n",
    "                            (annotations_df['annotator_id'] == ann2)\n",
    "                        ][category].iloc[0]\n",
    "                        \n",
    "                        values1.append(val1)\n",
    "                        values2.append(val2)\n",
    "                    \n",
    "                    # T√≠nh agreement\n",
    "                    if category == 'emotional_intensity':  # Ordinal\n",
    "                        tau, _ = stats.kendalltau(values1, values2)\n",
    "                        alpha_scores.append(tau)\n",
    "                    else:  # Nominal\n",
    "                        agreement = sum(v1 == v2 for v1, v2 in zip(values1, values2)) / len(values1)\n",
    "                        alpha_scores.append(agreement)\n",
    "        \n",
    "        if alpha_scores:\n",
    "            avg_alpha = np.mean(alpha_scores)\n",
    "        else:\n",
    "            avg_alpha = 0.0\n",
    "        \n",
    "        results['krippendorff_alpha'] = {\n",
    "            'value': avg_alpha,\n",
    "            'interpretation': self._interpret_alpha(avg_alpha),\n",
    "            'n_pairs': len(annotator_pairs)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _get_annotator_pairs(self, df: pd.DataFrame) -> List[Tuple]:\n",
    "        \"\"\"L·∫•y t·∫•t c·∫£ c·∫∑p annotators\"\"\"\n",
    "        annotators = df['annotator_id'].unique()\n",
    "        return list(itertools.combinations(annotators, 2))\n",
    "    \n",
    "    def _get_common_tasks(self, df: pd.DataFrame, \n",
    "                         annotator1: int, \n",
    "                         annotator2: int) -> List[int]:\n",
    "        \"\"\"L·∫•y tasks m√† c·∫£ 2 annotators c√πng annotate\"\"\"\n",
    "        tasks1 = set(df[df['annotator_id'] == annotator1]['task_id'])\n",
    "        tasks2 = set(df[df['annotator_id'] == annotator2]['task_id'])\n",
    "        return list(tasks1.intersection(tasks2))\n",
    "    \n",
    "    def calculate_semantic_similarity(self, annotations_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"\n",
    "        T√≠nh semantic similarity gi·ªØa c√°c annotations s·ª≠ d·ª•ng TF-IDF cosine similarity\n",
    "        D·ª±a tr√™n \"Semantic Similarity for Text Quality Assessment\" (2022)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Group by task\n",
    "        task_groups = annotations_df.groupby('task_id')\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        for task_id, group in task_groups:\n",
    "            if len(group) >= 2:\n",
    "                responses = group['npc_response'].tolist()\n",
    "                \n",
    "                # T√≠nh TF-IDF vectors\n",
    "                vectorizer = TfidfVectorizer()\n",
    "                try:\n",
    "                    tfidf_matrix = vectorizer.fit_transform(responses)\n",
    "                    \n",
    "                    # T√≠nh pairwise cosine similarities\n",
    "                    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "                    \n",
    "                    # L·∫•y upper triangle (kh√¥ng t√≠nh diagonal)\n",
    "                    n = len(responses)\n",
    "                    for i in range(n):\n",
    "                        for j in range(i+1, n):\n",
    "                            similarities.append(cosine_sim[i, j])\n",
    "                except:\n",
    "                    # N·∫øu kh√¥ng c√≥ t·ª´ n√†o chung\n",
    "                    continue\n",
    "        \n",
    "        if similarities:\n",
    "            avg_similarity = np.mean(similarities)\n",
    "            std_similarity = np.std(similarities)\n",
    "        else:\n",
    "            avg_similarity = 0.0\n",
    "            std_similarity = 0.0\n",
    "        \n",
    "        return {\n",
    "            'semantic_similarity': {\n",
    "                'mean': avg_similarity,\n",
    "                'std': std_similarity,\n",
    "                'n_comparisons': len(similarities),\n",
    "                'interpretation': self._interpret_similarity(avg_similarity)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _interpret_kappa(self, kappa: float) -> str:\n",
    "        \"\"\"Interpret Fleiss' Kappa theo Landis & Koch (1977)\"\"\"\n",
    "        if kappa < 0:\n",
    "            return \"Poor agreement\"\n",
    "        elif kappa <= 0.2:\n",
    "            return \"Slight agreement\"\n",
    "        elif kappa <= 0.4:\n",
    "            return \"Fair agreement\"\n",
    "        elif kappa <= 0.6:\n",
    "            return \"Moderate agreement\"\n",
    "        elif kappa <= 0.8:\n",
    "            return \"Substantial agreement\"\n",
    "        else:\n",
    "            return \"Almost perfect agreement\"\n",
    "    \n",
    "    def _interpret_alpha(self, alpha: float) -> str:\n",
    "        \"\"\"Interpret Krippendorff's Alpha\"\"\"\n",
    "        if alpha < 0.667:\n",
    "            return \"Unreliable\"\n",
    "        elif alpha < 0.8:\n",
    "            return \"Marginally reliable\"\n",
    "        elif alpha < 0.9:\n",
    "            return \"Reliable\"\n",
    "        else:\n",
    "            return \"Highly reliable\"\n",
    "    \n",
    "    def _interpret_similarity(self, similarity: float) -> str:\n",
    "        \"\"\"Interpret semantic similarity\"\"\"\n",
    "        if similarity < 0.3:\n",
    "            return \"Low similarity - high diversity\"\n",
    "        elif similarity < 0.6:\n",
    "            return \"Moderate similarity\"\n",
    "        elif similarity < 0.8:\n",
    "            return \"High similarity\"\n",
    "        else:\n",
    "            return \"Very high similarity - possible copying\"\n",
    "    \n",
    "    def generate_iaa_report(self, output_path=\"iaa_report.md\"):\n",
    "        \"\"\"T·∫°o comprehensive IAA report\"\"\"\n",
    "        \n",
    "        print(\"üìä ƒêang t√≠nh Inter-Annotator Agreement...\")\n",
    "        \n",
    "        # Load annotations\n",
    "        df = self.load_annotations()\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"‚ö†Ô∏è Kh√¥ng c√≥ annotations ƒë·ªÉ ph√¢n t√≠ch\")\n",
    "            return\n",
    "        \n",
    "        # T√≠nh c√°c metrics\n",
    "        fleiss_results = self.calculate_fleiss_kappa(df)\n",
    "        alpha_results = self.calculate_krippendorff_alpha(df)\n",
    "        similarity_results = self.calculate_semantic_similarity(df)\n",
    "        \n",
    "        # T·∫°o report\n",
    "        report = f\"\"\"# INTER-ANNOTATOR AGREEMENT REPORT\n",
    "\n",
    "## üìà T·ªïng quan\n",
    "\n",
    "**Ng√†y t·∫°o:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\n",
    "**T·ªïng s·ªë annotations:** {len(df)}\n",
    "**S·ªë annotators:** {df['annotator_id'].nunique()}\n",
    "**S·ªë tasks:** {df['task_id'].nunique()}\n",
    "\n",
    "## üìä Agreement Statistics\n",
    "\n",
    "### 1. Fleiss' Kappa\n",
    "| Category | Kappa | Interpretation |\n",
    "|----------|-------|----------------|\n",
    "| NPC State | {fleiss_results['npc_state']['fleiss_kappa']:.3f} | {fleiss_results['npc_state']['interpretation']} |\n",
    "| Emotional Intensity | {fleiss_results['emotional_intensity']['fleiss_kappa']:.3f} | {fleiss_results['emotional_intensity']['interpretation']} |\n",
    "\n",
    "*Ghi ch√∫: Kappa > 0.6 ƒë∆∞·ª£c coi l√† acceptable cho nghi√™n c·ª©u (Landis & Koch, 1977)*\n",
    "\n",
    "### 2. Krippendorff's Alpha\n",
    "**Alpha:** {alpha_results['krippendorff_alpha']['value']:.3f}\n",
    "**Interpretation:** {alpha_results['krippendorff_alpha']['interpretation']}\n",
    "**S·ªë c·∫∑p annotators:** {alpha_results['krippendorff_alpha']['n_pairs']}\n",
    "\n",
    "*Ghi ch√∫: Alpha > 0.8 ƒë∆∞·ª£c coi l√† reliable (Krippendorff, 2018)*\n",
    "\n",
    "### 3. Semantic Similarity\n",
    "**Mean similarity:** {similarity_results['semantic_similarity']['mean']:.3f}\n",
    "**Standard deviation:** {similarity_results['semantic_similarity']['std']:.3f}\n",
    "**Interpretation:** {similarity_results['semantic_similarity']['interpretation']}\n",
    "**S·ªë so s√°nh:** {similarity_results['semantic_similarity']['n_comparisons']}\n",
    "\n",
    "## üìà Ph√¢n b·ªë annotations\n",
    "\n",
    "### Ph√¢n b·ªë theo NPC State:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Ch·∫•t l∆∞·ª£ng trung b√¨nh:\n",
    "#- Naturalness: {df['quality_naturalness'].mean():.2f}/5\n",
    "#- Consistency: {df['quality_consistency'].mean():.2f}/5  \n",
    "#- Appropriateness: {df['quality_appropriateness'].mean():.2f}/5\n",
    "\n",
    "### Confidence scores:\n",
    "#- Mean confidence: {df['confidence_score'].mean():.2f}/5\n",
    "\n",
    "## üìä Per-Annotator Statistics\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        # Th√™m statistics theo t·ª´ng annotator\n",
    "        annotator_stats = df.groupby('annotator_id').agg({\n",
    "            'quality_naturalness': 'mean',\n",
    "            'quality_consistency': 'mean',\n",
    "            'quality_appropriateness': 'mean',\n",
    "            'confidence_score': 'mean',\n",
    "            'task_id': 'count'\n",
    "        }).rename(columns={'task_id': 'annotation_count'})\n",
    "        \n",
    "        report += annotator_stats.to_markdown()\n",
    "        \n",
    "        report += \"\"\"\n",
    "\n",
    "## üéØ Recommendations\n",
    "\n",
    "### N·∫øu Kappa < 0.6:\n",
    "1. **T·ªï ch·ª©c training session l·∫°i** v·ªõi examples r√µ r√†ng h∆°n\n",
    "2. **Clarify annotation guidelines** cho c√°c category g√¢y confusion\n",
    "3. **Th√™m more examples** cho c√°c edge cases\n",
    "4. **Consider merging categories** n·∫øu qu√° ambiguous\n",
    "\n",
    "### N·∫øu Semantic Similarity qu√° cao (>0.8):\n",
    "1. **Ki·ªÉm tra copying** gi·ªØa c√°c annotators\n",
    "2. **Th√™m response diversity requirements**\n",
    "3. **Khuy·∫øn kh√≠ch creativity** trong guidelines\n",
    "\n",
    "### N·∫øu Semantic Similarity qu√° th·∫•p (<0.3):\n",
    "1. **ƒê·∫£m b·∫£o character consistency** ƒë∆∞·ª£c gi·ªØ v·ªØng\n",
    "2. **Review guidelines** ƒë·ªÉ ƒë·∫£m b·∫£o clear expectations\n",
    "3. **Th√™m constraints** ƒë·ªÉ gi·ªØ response trong ph·∫°m vi ch·∫•p nh·∫≠n ƒë∆∞·ª£c\n",
    "\n",
    "### N·∫øu Annotation Time qu√° ng·∫Øn (<30s):\n",
    "1. **Ki·ªÉm tra quality** c·ªßa annotations\n",
    "2. **ƒê·∫£m b·∫£o annotators kh√¥ng rush**\n",
    "3. **Th√™m minimum time requirements**\n",
    "\n",
    "## üìä Visualizations (xem file plots/)\n",
    "\n",
    "C√°c bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c `plots/`:\n",
    "1. `state_distribution.png` - Ph√¢n b·ªë NPC states\n",
    "2. `emotion_distribution.png` - Ph√¢n b·ªë emotional intensity\n",
    "3. `quality_scores.png` - Ph√¢n b·ªë quality scores\n",
    "4. `annotator_agreement.png` - Agreement heatmap\n",
    "5. `annotation_time_distribution.png` - Ph√¢n b·ªë th·ªùi gian annotation\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "1. **N·∫øu IAA acceptable (>0.6):** Ti·∫øn h√†nh annotation full dataset\n",
    "2. **N·∫øu IAA marginal (0.4-0.6):** ƒêi·ªÅu ch·ªânh guidelines v√† ch·∫°y pilot l·∫°i\n",
    "3. **N·∫øu IAA poor (<0.4):** Xem x√©t l·∫°i to√†n b·ªô annotation framework\n",
    "\n",
    "### Action Plan:\n",
    "- [ ] Review IAA scores v·ªõi team\n",
    "- [ ] Identify problematic categories\n",
    "- [ ] Update guidelines n·∫øu c·∫ßn\n",
    "- [ ] Retrain annotators n·∫øu c·∫ßn\n",
    "- [ ] Run another pilot n·∫øu scores th·∫•p\n",
    "\n",
    "---\n",
    "*Report generated v·ªõi methodology t·ª´:*\n",
    "*- Fleiss, J. L. (1971). \"Measuring nominal scale agreement among many raters\"*\n",
    "*- Krippendorff, K. (2018). \"Content Analysis: An Introduction to Its Methodology\"*\n",
    "*- Landis, J. R., & Koch, G. G. (1977). \"The measurement of observer agreement\"*\n",
    "\"\"\"\n",
    "        \n",
    "        # L∆∞u report\n",
    "        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        # T·∫°o visualizations\n",
    "        self.create_visualizations(df)\n",
    "        \n",
    "        # L∆∞u detailed results\n",
    "        self.save_detailed_results(df, fleiss_results, alpha_results, similarity_results, cohen_results)\n",
    "        \n",
    "        print(f\"‚úÖ ƒê√£ t·∫°o IAA report: {output_path}\")\n",
    "        \n",
    "        return {\n",
    "            'fleiss': fleiss_results,\n",
    "            'alpha': alpha_results,\n",
    "            'similarity': similarity_results,\n",
    "            'cohen': cohen_results,\n",
    "            'time_stats': time_stats\n",
    "        }\n",
    "    \n",
    "    def create_visualizations(self, df: pd.DataFrame):\n",
    "        \"\"\"T·∫°o visualizations cho IAA analysis\"\"\"\n",
    "        \n",
    "        import matplotlib\n",
    "        matplotlib.use('Agg')  # For headless environments\n",
    "        \n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        \n",
    "        # 1. NPC State Distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        state_counts = df['npc_state'].value_counts()\n",
    "        colors = ['#4CAF50', '#FFC107', '#F44336', '#2196F3']  # green, yellow, red, blue\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o t·∫•t c·∫£ states ƒë·ªÅu c√≥ trong bi·ªÉu ƒë·ªì\n",
    "        all_states = ['normal', 'alert', 'combat', 'injured']\n",
    "        for state in all_states:\n",
    "            if state not in state_counts.index:\n",
    "                state_counts[state] = 0\n",
    "        \n",
    "        state_counts = state_counts.reindex(all_states)\n",
    "        \n",
    "        bars = plt.bar(state_counts.index, state_counts.values, color=colors)\n",
    "        \n",
    "        plt.title('Ph√¢n b·ªë NPC States', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('NPC State', fontsize=12)\n",
    "        plt.ylabel('S·ªë annotations', fontsize=12)\n",
    "        \n",
    "        # Th√™m s·ªë tr√™n m·ªói bar\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/state_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Emotional Intensity Distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        emotion_counts = df['emotional_intensity'].value_counts().sort_index()\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o t·∫•t c·∫£ levels ƒë·ªÅu c√≥\n",
    "        for level in range(1, 6):\n",
    "            if level not in emotion_counts.index:\n",
    "                emotion_counts[level] = 0\n",
    "        \n",
    "        emotion_counts = emotion_counts.sort_index()\n",
    "        \n",
    "        # T·∫°o gradient color t·ª´ xanh (calm) ƒë·∫øn ƒë·ªè (intense)\n",
    "        colors = plt.cm.RdYlGn_r(np.linspace(0, 1, len(emotion_counts)))\n",
    "        \n",
    "        bars = plt.bar(emotion_counts.index.astype(str), emotion_counts.values, color=colors)\n",
    "        \n",
    "        plt.title('Ph√¢n b·ªë Emotional Intensity', fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Emotional Intensity Level', fontsize=12)\n",
    "        plt.ylabel('S·ªë annotations', fontsize=12)\n",
    "        \n",
    "        # Th√™m m√¥ t·∫£ cho t·ª´ng level\n",
    "        emotion_labels = {\n",
    "            '1': 'Neutral\\n(1)',\n",
    "            '2': 'Mild\\n(2)', \n",
    "            '3': 'Medium\\n(3)',\n",
    "            '4': 'Strong\\n(4)',\n",
    "            '5': 'Very Strong\\n(5)'\n",
    "        }\n",
    "        \n",
    "        plt.xticks(list(emotion_counts.index.astype(str)), \n",
    "                  [emotion_labels[str(i)] for i in emotion_counts.index])\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/emotion_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Quality Scores Distribution\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        quality_metrics = ['quality_naturalness', 'quality_consistency', 'quality_appropriateness']\n",
    "        metric_labels = ['Naturalness', 'Consistency', 'Appropriateness']\n",
    "        \n",
    "        data = [df[metric] for metric in quality_metrics]\n",
    "        \n",
    "        box = plt.boxplot(data, labels=metric_labels, patch_artist=True)\n",
    "        \n",
    "        # M√†u cho c√°c box\n",
    "        colors = ['#FF9999', '#99FF99', '#9999FF']\n",
    "        for patch, color in zip(box['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        plt.title('Ph√¢n b·ªë Quality Scores', fontsize=16, fontweight='bold')\n",
    "        plt.ylabel('Score (1-5)', fontsize=12)\n",
    "        plt.ylim(0.5, 5.5)\n",
    "        \n",
    "        # Th√™m mean values\n",
    "        for i, metric in enumerate(quality_metrics, 1):\n",
    "            mean_val = df[metric].mean()\n",
    "            plt.text(i, 5.2, f'Mean: {mean_val:.2f}', \n",
    "                    ha='center', va='bottom', fontsize=10)\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/quality_scores.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 4. Annotation Time Distribution (n·∫øu c√≥)\n",
    "        if 'annotation_time_seconds' in df.columns and not df['annotation_time_seconds'].isna().all():\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            times = df['annotation_time_seconds'].dropna()\n",
    "            \n",
    "            plt.hist(times, bins=30, edgecolor='black', alpha=0.7)\n",
    "            plt.axvline(times.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {times.mean():.1f}s')\n",
    "            plt.axvline(times.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {times.median():.1f}s')\n",
    "            \n",
    "            plt.title('Ph√¢n b·ªë Th·ªùi gian Annotation', fontsize=16, fontweight='bold')\n",
    "            plt.xlabel('Th·ªùi gian (gi√¢y)', fontsize=12)\n",
    "            plt.ylabel('S·ªë annotations', fontsize=12)\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('plots/annotation_time_distribution.png', dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        print(\"‚úÖ ƒê√£ t·∫°o visualizations trong th∆∞ m·ª•c plots/\")\n",
    "    \n",
    "    def save_detailed_results(self, df: pd.DataFrame, fleiss_results: Dict, \n",
    "                             alpha_results: Dict, similarity_results: Dict,\n",
    "                             cohen_results: Dict):\n",
    "        \"\"\"L∆∞u detailed results ra JSON file\"\"\"\n",
    "        \n",
    "        detailed_results = {\n",
    "            'summary': {\n",
    "                'total_annotations': len(df),\n",
    "                'n_annotators': df['annotator_id'].nunique(),\n",
    "                'n_tasks': df['task_id'].nunique(),\n",
    "                'date_generated': datetime.now().isoformat()\n",
    "            },\n",
    "            'fleiss_kappa': fleiss_results,\n",
    "            'krippendorff_alpha': alpha_results,\n",
    "            'semantic_similarity': similarity_results,\n",
    "            'cohen_kappa': cohen_results,\n",
    "            'statistics': {\n",
    "                'state_distribution': df['npc_state'].value_counts().to_dict(),\n",
    "                'emotion_distribution': df['emotional_intensity'].value_counts().sort_index().to_dict(),\n",
    "                'quality_scores': {\n",
    "                    'naturalness_mean': float(df['quality_naturalness'].mean()),\n",
    "                    'consistency_mean': float(df['quality_consistency'].mean()),\n",
    "                    'appropriateness_mean': float(df['quality_appropriateness'].mean())\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open('plots/detailed_results.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(detailed_results, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(\"‚úÖ ƒê√£ l∆∞u detailed results: plots/detailed_results.json\")\n",
    "\n",
    "class AnnotationQualityController:\n",
    "    \"\"\"Quality control pipeline d·ª±a tr√™n research-based methods\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.quality_thresholds = {\n",
    "            'min_response_length': 3,  # √çt nh·∫•t 3 t·ª´\n",
    "            'max_response_length': 50, # T·ªëi ƒëa 50 t·ª´\n",
    "            'min_quality_score': 3,    # Ch·∫•t l∆∞·ª£ng t·ªëi thi·ªÉu\n",
    "            'max_similarity_with_others': 0.9,  # Kh√¥ng copy qu√° nhi·ªÅu\n",
    "            'required_fields': ['npc_response', 'npc_state', 'emotional_intensity']\n",
    "        }\n",
    "        \n",
    "        self.modern_words = ['ok', 'hello', 'hi', 'yes', 'no', 'sorry', 'thanks', \n",
    "                           'okay', 'hey', 'please', 'thank you', 'thanks', 'cool',\n",
    "                           'awesome', 'amazing', 'wow', 'lol', 'haha', 'omg']\n",
    "        \n",
    "    def validate_annotations(self, annotations_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Validate annotations theo multiple criteria\"\"\"\n",
    "        \n",
    "        validation_results = {\n",
    "            'total_annotations': len(annotations_df),\n",
    "            'passed_validation': 0,\n",
    "            'failed_validation': 0,\n",
    "            'failure_reasons': defaultdict(int),\n",
    "            'failed_samples': [],\n",
    "            'warnings': []\n",
    "        }\n",
    "        \n",
    "        for idx, row in annotations_df.iterrows():\n",
    "            is_valid, reason, warnings = self._validate_single_annotation(row)\n",
    "            \n",
    "            if is_valid:\n",
    "                validation_results['passed_validation'] += 1\n",
    "            else:\n",
    "                validation_results['failed_validation'] += 1\n",
    "                validation_results['failure_reasons'][reason] += 1\n",
    "                validation_results['failed_samples'].append({\n",
    "                    'task_id': int(row['task_id']),\n",
    "                    'annotator_id': int(row['annotator_id']),\n",
    "                    'reason': reason,\n",
    "                    'response': str(row['npc_response'])[:100] + '...' if len(str(row['npc_response'])) > 100 else str(row['npc_response'])\n",
    "                })\n",
    "            \n",
    "            # Th√™m warnings\n",
    "            for warning in warnings:\n",
    "                validation_results['warnings'].append({\n",
    "                    'task_id': int(row['task_id']),\n",
    "                    'annotator_id': int(row['annotator_id']),\n",
    "                    'warning': warning\n",
    "                })\n",
    "        \n",
    "        # T√≠nh pass rate\n",
    "        if validation_results['total_annotations'] > 0:\n",
    "            validation_results['pass_rate'] = (\n",
    "                validation_results['passed_validation'] / \n",
    "                validation_results['total_annotations'] * 100\n",
    "            )\n",
    "        else:\n",
    "            validation_results['pass_rate'] = 0\n",
    "        \n",
    "        # Th·ªëng k√™ warnings\n",
    "        warning_counts = defaultdict(int)\n",
    "        for warning in validation_results['warnings']:\n",
    "            warning_counts[warning['warning']] += 1\n",
    "        validation_results['warning_counts'] = dict(warning_counts)\n",
    "        \n",
    "        return validation_results\n",
    "    \n",
    "    def _validate_single_annotation(self, annotation: pd.Series) -> Tuple[bool, str, List[str]]:\n",
    "        \"\"\"Validate single annotation\"\"\"\n",
    "        \n",
    "        warnings = []\n",
    "        \n",
    "        # 1. Check required fields\n",
    "        for field in self.quality_thresholds['required_fields']:\n",
    "            if field not in annotation or pd.isna(annotation[field]) or str(annotation[field]) == '':\n",
    "                return False, f'missing_{field}', warnings\n",
    "        \n",
    "        # 2. Check response length\n",
    "        response = str(annotation['npc_response'])\n",
    "        word_count = len(response.split())\n",
    "        \n",
    "        if word_count < self.quality_thresholds['min_response_length']:\n",
    "            return False, 'response_too_short', warnings\n",
    "        \n",
    "        if word_count > self.quality_thresholds['max_response_length']:\n",
    "            warnings.append('response_too_long')\n",
    "        \n",
    "        # 3. Check quality scores\n",
    "        quality_fields = ['quality_naturalness', 'quality_consistency', 'quality_appropriateness']\n",
    "        for field in quality_fields:\n",
    "            if field in annotation and pd.notna(annotation[field]):\n",
    "                if annotation[field] < self.quality_thresholds['min_quality_score']:\n",
    "                    warnings.append(f'low_{field}')\n",
    "        \n",
    "        # 4. Check confidence score\n",
    "        if 'confidence_score' in annotation and pd.notna(annotation['confidence_score']):\n",
    "            if annotation['confidence_score'] < 3:\n",
    "                warnings.append('low_confidence')\n",
    "        \n",
    "        # 5. Check for modern language/anachronisms\n",
    "        response_lower = response.lower()\n",
    "        modern_words_found = [word for word in self.modern_words if word in response_lower]\n",
    "        if modern_words_found:\n",
    "            warnings.append(f'anachronism: {\", \".join(modern_words_found[:3])}')\n",
    "        \n",
    "        # 6. Check for inappropriate content\n",
    "        inappropriate_terms = ['fuck', 'shit', 'damn', 'hell', 'bastard', 'asshole']\n",
    "        inappropriate_found = [term for term in inappropriate_terms if term in response_lower]\n",
    "        if inappropriate_found:\n",
    "            warnings.append(f'inappropriate_language: {\", \".join(inappropriate_found[:3])}')\n",
    "        \n",
    "        return True, 'passed', warnings\n",
    "    \n",
    "    def detect_pattern_repetition(self, annotations_df: pd.DataFrame, \n",
    "                                 similarity_threshold: float = 0.8) -> Dict:\n",
    "        \"\"\"Ph√°t hi·ªán pattern repetition gi·ªØa c√°c annotators\"\"\"\n",
    "        \n",
    "        results = {\n",
    "            'high_similarity_pairs': [],\n",
    "            'possible_copied_responses': [],\n",
    "            'unique_annotators': annotations_df['annotator_id'].nunique()\n",
    "        }\n",
    "        \n",
    "        # Group by task\n",
    "        task_groups = annotations_df.groupby('task_id')\n",
    "        \n",
    "        for task_id, group in task_groups:\n",
    "            if len(group) >= 2:\n",
    "                responses = group['npc_response'].tolist()\n",
    "                annotators = group['annotator_id'].tolist()\n",
    "                \n",
    "                # T√≠nh similarity matrix\n",
    "                vectorizer = TfidfVectorizer()\n",
    "                try:\n",
    "                    tfidf_matrix = vectorizer.fit_transform(responses)\n",
    "                    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "                    \n",
    "                    # Ki·ªÉm tra c√°c c·∫∑p c√≥ similarity cao\n",
    "                    n = len(responses)\n",
    "                    for i in range(n):\n",
    "                        for j in range(i+1, n):\n",
    "                            if cosine_sim[i, j] > similarity_threshold:\n",
    "                                results['high_similarity_pairs'].append({\n",
    "                                    'task_id': int(task_id),\n",
    "                                    'annotator1': int(annotators[i]),\n",
    "                                    'annotator2': int(annotators[j]),\n",
    "                                    'similarity': float(cosine_sim[i, j]),\n",
    "                                    'response1': responses[i][:100] + '...' if len(responses[i]) > 100 else responses[i],\n",
    "                                    'response2': responses[j][:100] + '...' if len(responses[j]) > 100 else responses[j]\n",
    "                                })\n",
    "                                \n",
    "                                # N·∫øu similarity r·∫•t cao, c√≥ th·ªÉ l√† copying\n",
    "                                if cosine_sim[i, j] > 0.95:\n",
    "                                    results['possible_copied_responses'].append({\n",
    "                                        'task_id': int(task_id),\n",
    "                                        'annotator_pair': (int(annotators[i]), int(annotators[j])),\n",
    "                                        'similarity': float(cosine_sim[i, j])\n",
    "                                    })\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_annotator_reliability(self, annotations_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"T√≠nh reliability score cho t·ª´ng annotator\"\"\"\n",
    "        \n",
    "        if len(annotations_df) == 0:\n",
    "            return {}\n",
    "        \n",
    "        annotator_stats = annotations_df.groupby('annotator_id').agg({\n",
    "            'quality_naturalness': ['mean', 'std', 'count'],\n",
    "            'quality_consistency': ['mean', 'std', 'count'],\n",
    "            'quality_appropriateness': ['mean', 'std', 'count'],\n",
    "            'confidence_score': 'mean'\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        annotator_stats.columns = ['_'.join(col).strip() for col in annotator_stats.columns.values]\n",
    "        \n",
    "        # T√≠nh reliability score\n",
    "        reliability_scores = {}\n",
    "        for annotator_id in annotator_stats.index:\n",
    "            stats = annotator_stats.loc[annotator_id]\n",
    "            \n",
    "            # T√≠nh score d·ª±a tr√™n ch·∫•t l∆∞·ª£ng v√† consistency\n",
    "            quality_score = (\n",
    "                stats.get('quality_naturalness_mean', 3) +\n",
    "                stats.get('quality_consistency_mean', 3) +\n",
    "                stats.get('quality_appropriateness_mean', 3)\n",
    "            ) / 3\n",
    "            \n",
    "            # T√≠nh variability (th·∫•p h∆°n t·ªët h∆°n)\n",
    "            variability = np.mean([\n",
    "                stats.get('quality_naturalness_std', 0),\n",
    "                stats.get('quality_consistency_std', 0),\n",
    "                stats.get('quality_appropriateness_std', 0)\n",
    "            ])\n",
    "            \n",
    "            # T√≠nh reliability score (0-1)\n",
    "            reliability = quality_score / 5 * (1 - min(variability / 2, 0.5))\n",
    "            \n",
    "            reliability_scores[annotator_id] = {\n",
    "                'reliability_score': float(reliability),\n",
    "                'quality_score': float(quality_score),\n",
    "                'variability': float(variability),\n",
    "                'annotation_count': int(stats.get('quality_naturalness_count', 0)),\n",
    "                'confidence_mean': float(stats.get('confidence_score_mean', 3))\n",
    "            }\n",
    "        \n",
    "        return reliability_scores\n",
    "    \n",
    "    def generate_quality_report(self, validation_results: Dict, \n",
    "                               pattern_results: Dict = None,\n",
    "                               reliability_scores: Dict = None,\n",
    "                               output_path=\"quality_report.md\"):\n",
    "        \"\"\"T·∫°o comprehensive quality report\"\"\"\n",
    "        \n",
    "        report = f\"\"\"# ANNOTATION QUALITY CONTROL REPORT\n",
    "\n",
    "## üìä T·ªïng quan ch·∫•t l∆∞·ª£ng\n",
    "\n",
    "**T·ªïng s·ªë annotations:** {validation_results['total_annotations']}\n",
    "**Annotations passed:** {validation_results['passed_validation']}\n",
    "**Annotations failed:** {validation_results['failed_validation']}\n",
    "**Pass rate:** {validation_results['pass_rate']:.1f}%\n",
    "\n",
    "## üö® Failure Analysis\n",
    "\n",
    "### L√Ω do failed (t·ªïng s·ªë):\n",
    "\"\"\"\n",
    "        \n",
    "        for reason, count in validation_results['failure_reasons'].items():\n",
    "            report += f\"- **{reason}:** {count} annotations\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## ‚ö†Ô∏è Warnings Analysis\n",
    "\n",
    "### C·∫£nh b√°o ph√°t hi·ªán:\n",
    "\"\"\"\n",
    "        \n",
    "        if validation_results.get('warning_counts'):\n",
    "            for warning, count in validation_results['warning_counts'].items():\n",
    "                report += f\"- **{warning}:** {count} annotations\\n\"\n",
    "        else:\n",
    "            report += \"Kh√¥ng c√≥ warnings.\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## üîç Pattern Repetition Analysis\n",
    "\"\"\"\n",
    "        \n",
    "        if pattern_results:\n",
    "            report += f\"\"\"\n",
    "**S·ªë annotators:** {pattern_results['unique_annotators']}\n",
    "**S·ªë c·∫∑p c√≥ similarity > 0.8:** {len(pattern_results['high_similarity_pairs'])}\n",
    "**S·ªë c·∫∑p c√≥ th·ªÉ copied (similarity > 0.95):** {len(pattern_results['possible_copied_responses'])}\n",
    "\n",
    "### C√°c c·∫∑p c√≥ similarity cao nh·∫•t (top 5):\n",
    "\"\"\"\n",
    "            \n",
    "            # S·∫Øp x·∫øp theo similarity\n",
    "            high_similarity = sorted(pattern_results['high_similarity_pairs'], \n",
    "                                   key=lambda x: x['similarity'], reverse=True)[:5]\n",
    "            \n",
    "            for i, pair in enumerate(high_similarity, 1):\n",
    "                report += f\"\"\"\n",
    "{i}. **Task {pair['task_id']}** (Annotators: {pair['annotator1']} & {pair['annotator2']})\n",
    "   Similarity: {pair['similarity']:.3f}\n",
    "   Response 1: {pair['response1']}\n",
    "   Response 2: {pair['response2']}\n",
    "\"\"\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## üë§ Annotator Reliability Scores\n",
    "\"\"\"\n",
    "        \n",
    "        if reliability_scores:\n",
    "            report += \"\"\"\n",
    "| Annotator ID | Reliability Score | Quality Score | Variability | Count |\n",
    "|--------------|-------------------|---------------|-------------|-------|\n",
    "\"\"\"\n",
    "            \n",
    "            for annotator_id, scores in sorted(reliability_scores.items(), \n",
    "                                             key=lambda x: x[1]['reliability_score'], \n",
    "                                             reverse=True):\n",
    "                report += f\"| {annotator_id} | {scores['reliability_score']:.3f} | {scores['quality_score']:.2f} | {scores['variability']:.2f} | {scores['annotation_count']} |\\n\"\n",
    "            \n",
    "            # Th√™m interpretation\n",
    "            report += f\"\"\"\n",
    "\n",
    "### Interpretation:\n",
    "- **Reliability Score > 0.8:** Excellent annotator\n",
    "- **Reliability Score 0.6-0.8:** Good annotator\n",
    "- **Reliability Score 0.4-0.6:** Needs improvement\n",
    "- **Reliability Score < 0.4:** Consider retraining\n",
    "\"\"\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## üìù Failed Samples (first 10)\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        if validation_results['failed_samples']:\n",
    "            for i, sample in enumerate(validation_results['failed_samples'][:10]):\n",
    "                report += f\"{i+1}. **Task {sample['task_id']}** (Annotator {sample['annotator_id']})\\n\"\n",
    "                report += f\"   Reason: {sample['reason']}\\n\"\n",
    "                report += f\"   Response: {sample['response']}\\n\\n\"\n",
    "        else:\n",
    "            report += \"Kh√¥ng c√≥ failed samples.\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## üéØ Recommendations\n",
    "\n",
    "### N·∫øu pass rate > 90%:\n",
    "‚úÖ **Ch·∫•t l∆∞·ª£ng t·ªët** - C√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi annotation scale-up\n",
    "\n",
    "### N·∫øu pass rate 70-90%:\n",
    "‚ö†Ô∏è **C·∫ßn c·∫£i thi·ªán** - T·ªï ch·ª©c additional training cho annotators\n",
    "\n",
    "### N·∫øu pass rate < 70%:\n",
    "‚ùå **V·∫•n ƒë·ªÅ nghi√™m tr·ªçng** - C·∫ßn xem x√©t l·∫°i to√†n b·ªô annotation process\n",
    "\n",
    "### N·∫øu c√≥ nhi·ªÅu high similarity pairs (>20%):\n",
    "‚ö†Ô∏è **C√≥ th·ªÉ c√≥ copying** - C·∫ßn xem x√©t monitoring v√† guidelines\n",
    "\n",
    "### Action Items:\n",
    "1. Review failed samples ƒë·ªÉ hi·ªÉu patterns\n",
    "2. Address common failure reasons\n",
    "3. Retrain annotators c√≥ reliability score th·∫•p\n",
    "4. Update guidelines d·ª±a tr√™n findings\n",
    "5. Consider adding more validation rules\n",
    "\n",
    "---\n",
    "*Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}*\n",
    "\"\"\"\n",
    "        \n",
    "        # L∆∞u report\n",
    "        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)\n",
    "        \n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"‚úÖ ƒê√£ t·∫°o quality report: {output_path}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "# ==================== MAIN EXECUTION ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîç B·∫Øt ƒë·∫ßu Quality Control Pipeline...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. T√≠nh Inter-Annotator Agreement\n",
    "    print(\"\\n1. üìä T√≠nh Inter-Annotator Agreement...\")\n",
    "    iaa = InterAnnotatorAgreement()\n",
    "    \n",
    "    try:\n",
    "        iaa_report = iaa.generate_iaa_report()\n",
    "        if iaa_report:\n",
    "            print(\"‚úÖ IAA analysis completed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è L·ªói trong IAA analysis: {e}\")\n",
    "        print(\"T·∫°o database m·∫´u ƒë·ªÉ test...\")\n",
    "        # T·∫°o database m·∫´u ƒë·ªÉ test\n",
    "        create_sample_database()\n",
    "        iaa_report = iaa.generate_iaa_report()\n",
    "    \n",
    "    # 2. Quality Validation\n",
    "    print(\"\\n2. üéØ Validating annotation quality...\")\n",
    "    df = iaa.load_annotations()\n",
    "    \n",
    "    if len(df) > 0:\n",
    "        qc = AnnotationQualityController()\n",
    "        \n",
    "        # Validate annotations\n",
    "        validation_results = qc.validate_annotations(df)\n",
    "        \n",
    "        # Detect pattern repetition\n",
    "        pattern_results = qc.detect_pattern_repetition(df)\n",
    "        \n",
    "        # Calculate reliability scores\n",
    "        reliability_scores = qc.calculate_annotator_reliability(df)\n",
    "        \n",
    "        # Generate quality report\n",
    "        qc_report = qc.generate_quality_report(\n",
    "            validation_results, \n",
    "            pattern_results, \n",
    "            reliability_scores\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Quality validation completed.\")\n",
    "        print(f\"   Pass rate: {validation_results['pass_rate']:.1f}%\")\n",
    "        print(f\"   Failed: {validation_results['failed_validation']} annotations\")\n",
    "        \n",
    "        if reliability_scores:\n",
    "            avg_reliability = np.mean([s['reliability_score'] for s in reliability_scores.values()])\n",
    "            print(f\"   Avg reliability score: {avg_reliability:.3f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üéâ QUALITY CONTROL PIPELINE HO√ÄN TH√ÄNH!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nüìÅ Output files:\")\n",
    "    print(\"  - iaa_report.md (Inter-Annotator Agreement analysis)\")\n",
    "    print(\"  - quality_report.md (Quality validation results)\")\n",
    "    print(\"  - plots/ (Visualizations)\")\n",
    "    print(\"  - plots/detailed_results.json (Detailed metrics)\")\n",
    "    print(\"\\nüìä Key metrics to check:\")\n",
    "    print(\"  1. Fleiss' Kappa > 0.6 (Moderate agreement)\")\n",
    "    print(\"  2. Pass rate > 85%\")\n",
    "    print(\"  3. Avg reliability score > 0.7\")\n",
    "    print(\"\\nüöÄ Next steps:\")\n",
    "    print(\"  1. Review reports v·ªõi team\")\n",
    "    print(\"  2. Address quality issues\")\n",
    "    print(\"  3. Retrain annotators n·∫øu c·∫ßn\")\n",
    "    print(\"  4. Update annotation guidelines\")\n",
    "    print(\"  5. Proceed with full-scale annotation\")\n",
    "\n",
    "def create_sample_database():\n",
    "    \"\"\"T·∫°o database m·∫´u ƒë·ªÉ test n·∫øu kh√¥ng c√≥ data\"\"\"\n",
    "    print(\"üìù T·∫°o database m·∫´u v·ªõi 60 annotations t·ª´ 3 annotators...\")\n",
    "    \n",
    "    conn = sqlite3.connect('annotations.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # T·∫°o tables n·∫øu ch∆∞a c√≥\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS tasks (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            player_message TEXT NOT NULL,\n",
    "            context TEXT,\n",
    "            npc_state TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            assigned_to INTEGER,\n",
    "            completed BOOLEAN DEFAULT FALSE\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS annotations (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            task_id INTEGER NOT NULL,\n",
    "            annotator_id INTEGER NOT NULL,\n",
    "            npc_response TEXT NOT NULL,\n",
    "            npc_state TEXT NOT NULL,\n",
    "            emotional_intensity INTEGER,\n",
    "            dialogue_acts TEXT,\n",
    "            quality_naturalness INTEGER,\n",
    "            quality_consistency INTEGER,\n",
    "            quality_appropriateness INTEGER,\n",
    "            confidence_score INTEGER,\n",
    "            annotation_time_seconds INTEGER,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    # T·∫°o sample tasks\n",
    "    sample_tasks = [\n",
    "        (\"Xin ch√†o\", \"Ban ng√†y, c·ªïng th√†nh\", \"normal\"),\n",
    "        (\"Cho t√¥i qua ƒëi\", \"Player ti·∫øn g·∫ßn c·ªïng\", \"alert\"),\n",
    "        (\"Ta s·∫Ω gi·∫øt ng∆∞∆°i!\", \"\", \"combat\"),\n",
    "        (\"Ng∆∞∆°i thua r·ªìi\", \"NPC b·ªã th∆∞∆°ng n·∫∑ng\", \"injured\"),\n",
    "        (\"Tr·ªùi h√¥m nay ƒë·∫πp nh·ªâ\", \"Bu·ªïi s√°ng y√™n tƒ©nh\", \"normal\"),\n",
    "        (\"C√≥ chuy·ªán g√¨ th·∫ø?\", \"Player b·ªã c·∫£nh b√°o\", \"alert\"),\n",
    "        (\"(T·∫•n c√¥ng)\", \"Tr·∫≠n chi·∫øn b·∫Øt ƒë·∫ßu\", \"combat\"),\n",
    "        (\"C√≥ c·∫ßn gi√∫p kh√¥ng?\", \"NPC b·ªã th∆∞∆°ng\", \"injured\"),\n",
    "    ]\n",
    "    \n",
    "    task_ids = []\n",
    "    for msg, ctx, state in sample_tasks:\n",
    "        cursor.execute('INSERT INTO tasks (player_message, context, npc_state) VALUES (?, ?, ?)',\n",
    "                      (msg, ctx, state))\n",
    "        task_ids.append(cursor.lastrowid)\n",
    "    \n",
    "    # T·∫°o sample annotations (3 annotators cho m·ªói task)\n",
    "    sample_responses = {\n",
    "        \"normal\": [\n",
    "            \"Ch√†o c√¥ng d√¢n. Gi·ªØ tr·∫≠t t·ª± v√† di chuy·ªÉn ƒëi.\",\n",
    "            \"Ch√†o. ƒê·ª´ng g√¢y r·∫Øc r·ªëi ·ªü ƒë√¢y.\",\n",
    "            \"Ch√†o. H√£y tu√¢n th·ªß lu·∫≠t l·ªá.\"\n",
    "        ],\n",
    "        \"alert\": [\n",
    "            \"D·ª´ng l·∫°i! Kh√¥ng ƒë∆∞·ª£c b∆∞·ªõc th√™m b∆∞·ªõc n√†o n·ªØa.\",\n",
    "            \"ƒê·ª©ng y√™n! Tay ƒë·ªÉ xa v≈© kh√≠.\",\n",
    "            \"C·∫£nh b√°o! D·ª´ng l·∫°i ngay l·∫≠p t·ª©c.\"\n",
    "        ],\n",
    "        \"combat\": [\n",
    "            \"Ch·∫øt ƒëi, k·∫ª x√¢m nh·∫≠p!\",\n",
    "            \"Ta s·∫Ω nghi·ªÅn n√°t ng∆∞∆°i!\",\n",
    "            \"Ng∆∞∆°i kh√¥ng qua ƒë∆∞·ª£c ƒë√¢u!\"\n",
    "        ],\n",
    "        \"injured\": [\n",
    "            \"L√†m... l√†m ∆°n... tha cho t√¥i...\",\n",
    "            \"T√¥i... t√¥i ƒë·∫ßu h√†ng...\",\n",
    "            \"Xin ƒë·ª´ng... t√¥i c√≤n gia ƒë√¨nh...\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for task_id in task_ids:\n",
    "        # L·∫•y state c·ªßa task\n",
    "        cursor.execute('SELECT npc_state FROM tasks WHERE id = ?', (task_id,))\n",
    "        state = cursor.fetchone()[0]\n",
    "        \n",
    "        # T·∫°o 3 annotations cho m·ªói task\n",
    "        for annotator_id in range(1, 4):\n",
    "            response = sample_responses[state][annotator_id - 1]\n",
    "            emotional_intensity = {\"normal\": 2, \"alert\": 4, \"combat\": 5, \"injured\": 4}[state]\n",
    "            \n",
    "            cursor.execute('''\n",
    "                INSERT INTO annotations \n",
    "                (task_id, annotator_id, npc_response, npc_state, emotional_intensity,\n",
    "                 quality_naturalness, quality_consistency, quality_appropriateness,\n",
    "                 confidence_score, annotation_time_seconds)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            ''', (\n",
    "                task_id, annotator_id, response, state, emotional_intensity,\n",
    "                4, 4, 4, 4, np.random.randint(30, 120)\n",
    "            ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"‚úÖ ƒê√£ t·∫°o database m·∫´u v·ªõi 24 annotations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
