#!/usr/bin/env python3
"""
BD-NSCA Training Data Generator v2

Generates synthetic training data for NPC dialogue fine-tuning.
Integration: Uses core.prompt_builder to ensure training data matches inference prompts exactly.
"""
from __future__ import annotations
import argparse
import json
import random
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Any
from dataclasses import dataclass
import logging
import os

# Add parent dir to path to import core modules
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from core.prompt_builder import PromptBuilder
except ImportError as e:
    logging.error("Failed to import PromptBuilder: %s", e)
    logging.error("Make sure core/prompt_builder.py exists in the repository")
    logging.error("Current path: %s", Path(__file__).parent.parent / "core" / "prompt_builder.py")
    sys.exit(1)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

DEFAULT_PERSONAS = {
    "merchant": {
        "name": "Elara",
        "persona_vi": "Bạn là Elara, một thương nhân thân thiện, thực tế và lịch sự.",
        "persona_en": "You are Elara, a practical but kind merchant who values fair trade."
    }
}

DEFAULT_SCENARIOS = {
    "village_gate": {
        "location": "Village Gate",
        "plot_vi": "Người chơi vừa đến cổng làng.",
        "plot_en": "The player has just arrived at the village gate."
    }
}

DEFAULT_CONTEXTS = {
    "behavior_states": {"idle": {"vi": "đứng canh", "en": "standing guard"}},
    "health_states": {"healthy": {"vi": "khỏe mạnh", "en": "healthy"}},
    "mood_states": {"neutral": {"vi": "bình tĩnh", "en": "neutral"}},
    "nearby_entities": {"none": {"vi": "không có ai", "en": "no one nearby"}},
    "time_contexts": {"day": {"vi": "ban ngày", "en": "daytime"}}
}

DEFAULT_UTTERANCES = {
    "greeting": {"vi": ["Xin chào."], "en": ["Hello."]},
    "question": {"vi": ["Bạn có thể giúp tôi không?"], "en": ["Can you help me?"]}
}


@dataclass
class TrainingSample:
    """A single training sample in BD-NSCA format."""
    id: str
    npc_id: str
    scenario_id: str
    persona: str
    npc_name: str
    plot: str
    game_state: Dict[str, Any]  # Unpacked game state for PromptBuilder
    player_input: str
    npc_response: str
    language: str
    
    def to_prompt_completion(self) -> Dict[str, str]:
        """Convert to prompt-completion format for fine-tuning using PromptBuilder."""
        
        # Construct NPC Data expected by PromptBuilder
        # Note: We pass the localized persona directly
        npc_data = {
            "name": self.npc_name,
            "persona": self.persona,
            "id": self.npc_id
        }
        
        # Construct Game State expected by PromptBuilder
        # We assume self.game_state already has keys like 'behavior_state', 'mood_state', etc.
        # with localized values.
        # We also need to inject scenario plot into game_state for PromptBuilder
        gs = self.game_state.copy()
        gs['scenario_plot'] = self.plot
        
        pb = PromptBuilder(use_advanced_format=True)
        prompt = pb.build_prompt(
            npc_data=npc_data,
            game_state=gs,
            player_input=self.player_input,
            memory_context="", # No memory in single-turn training samples
            emotional_state=None,
            language=self.language
        )
        
        # Extract the <|user|> part and before as 'prompt', and <|assistant|>... as completion?
        # Actually SFTTrainer usually wants the full text or split.
        # Standard format: prompt includes <|system|>...<|user|>...<|assistant|>
        # Validation checks usually expect 'completion' to be just the response content.
        # The prompt generated by PB generally ends with <|assistant|>\n
        
        return {
            "id": self.id,
            "prompt": prompt,
            "completion": self.npc_response,
            "metadata": {
                "npc_id": self.npc_id,
                "scenario_id": self.scenario_id,
                "language": self.language,
                "context": self.game_state # Store raw context for evaluation
            }
        }


class DataGenerator:
    """Generates training data by combining seed data components."""
    
    def __init__(self, data_dir: Path, language: str = "vi"):
        self.data_dir = data_dir
        self.language = language
        self.personas = self._load_json("personas.json") or DEFAULT_PERSONAS
        self.scenarios = self._load_json("scenarios.json") or DEFAULT_SCENARIOS
        self.contexts = self._load_json("context_templates.json") or DEFAULT_CONTEXTS
        self.utterances = self._load_json("player_utterances.json") or DEFAULT_UTTERANCES
        
    def _load_json(self, filename: str) -> Dict:
        path = self.data_dir / filename
        if not path.exists():
            logger.warning("File not found: %s", path)
            return {}
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def _get_lang_key(self, obj: Dict, key_base: str) -> str:
        """Get language-specific key from object."""
        # Try explicit key (e.g. persona_vi)
        lang_key = "{}_{}".format(key_base, self.language)
        if lang_key in obj:
            return obj[lang_key]
        
        # Try nested dict (obj[key_base][vi])
        if key_base in obj and isinstance(obj[key_base], dict):
            return obj[key_base].get(self.language, obj[key_base].get("vi", ""))
            
        # Fallback to base key
        return obj.get(key_base, "")
    
    def _build_game_state(self, scenario_id: str) -> Dict[str, str]:
        """Build a random dynamic game state dictionary with standard keys and localized values."""
        gs = {}
        
        def pick_val(category: str) -> str:
            # Pick a random key from context_templates category (e.g. 'idle')
            keys = list(self.contexts.get(category, {}).keys())
            if not keys: return "Unknown"
            key = random.choice(keys)
            # Get localized string
            val_data = self.contexts[category][key]
            if isinstance(val_data, dict):
                return val_data.get(self.language, key)
            return key

        # Behavior state
        gs["behavior_state"] = pick_val("behavior_states")
        
        # Health state
        gs["health_state"] = pick_val("health_states")
        
        # Mood state
        gs["mood_state"] = pick_val("mood_states")
        
        # Nearby entities
        gs["nearby_entities"] = pick_val("nearby_entities")
        
        # Time of day
        gs["time_of_day"] = pick_val("time_contexts")
        
        # Location (from scenario)
        scenario = self.scenarios.get(scenario_id, {})
        gs["location"] = scenario.get("location", "Unknown Location") # Location is usually an ID, ideally localized too
        
        # Trust (random int)
        gs["trust_level"] = random.randint(30, 80)
        
        return gs
    
    def _generate_response_template(self, npc_id: str, context: Dict[str, str], player_input: str) -> str:
        """Generate a deterministic response template for offline-safe data generation."""
        style_open = {
            "vi": [
                "Ta hiểu ý ngươi.",
                "Để ta xem xét kỹ hơn.",
                "Nghe có lý đấy.",
            ],
            "en": [
                "I understand your point.",
                "Let me think about that carefully.",
                "That is a reasonable question.",
            ],
        }
        mood = context.get("mood_state", "neutral")
        location = context.get("location", "the village")
        trust_level = context.get("trust_level", 50)

        opening = random.choice(style_open.get(self.language, style_open["en"]))
        if self.language == "vi":
            stance = "Ta tin ngươi." if trust_level >= 60 else "Ta vẫn cần thận trọng."
            return f"{opening} Ở {location}, tâm trạng của ta đang {mood}. {stance} Ta sẽ trả lời về việc: \"{player_input}\"."

        stance = "I trust you." if trust_level >= 60 else "I still need to be careful."
        return f"{opening} Here at {location}, my mood is {mood}. {stance} I will respond about: \"{player_input}\"."
    
    def generate_sample(self, sample_id: int) -> TrainingSample:
        """Generate a single training sample."""
        persona_keys = list(self.personas.keys()) if isinstance(self.personas, dict) else []
        scenario_keys = list(self.scenarios.keys()) if isinstance(self.scenarios, dict) else []
        if not persona_keys:
            self.personas = DEFAULT_PERSONAS
            persona_keys = list(self.personas.keys())
        if not scenario_keys:
            self.scenarios = DEFAULT_SCENARIOS
            scenario_keys = list(self.scenarios.keys())

        npc_id = random.choice(persona_keys)
        scenario_id = random.choice(scenario_keys)
        
        npc = self.personas[npc_id]
        scenario = self.scenarios[scenario_id]
        
        # Get localized persona/name/plot
        persona = self._get_lang_key(npc, "persona")
        npc_name = npc.get("name", "NPC") # Name is universal or mixed
        plot = self._get_lang_key(scenario, "plot")
        
        # Build dynamic state
        game_state = self._build_game_state(scenario_id)
        
        # Player input
        utterance_types = list(self.utterances.keys()) if isinstance(self.utterances, dict) else []
        if not utterance_types:
            self.utterances = DEFAULT_UTTERANCES
            utterance_types = list(self.utterances.keys())

        utterance_type = random.choice(utterance_types)
        utterances_list = self.utterances.get(utterance_type, {}).get(self.language, [])
        if not utterances_list:
            utterances_list = ["Xin chào."] if self.language == "vi" else ["Hello."]
        player_input = random.choice(utterances_list)
        
        npc_response = self._generate_response_template(npc_id, game_state, player_input)
        
        return TrainingSample(
            id="sample_{:05d}".format(sample_id),
            npc_id=npc_id,
            scenario_id=scenario_id,
            persona=persona,
            npc_name=npc_name,
            plot=plot,
            game_state=game_state,
            player_input=player_input,
            npc_response=npc_response,
            language=self.language
        )
    
    def generate_dataset(self, num_samples: int) -> List[TrainingSample]:
        return [self.generate_sample(i) for i in range(num_samples)]


def generate_with_llm(samples: List[TrainingSample], model_id: str = "phi3:mini") -> List[TrainingSample]:
    """
    Optional response enhancement with local Ollama.
    This function is safe-by-default: if Ollama is unavailable, it keeps existing responses.
    Enable by setting NPC_USE_OLLAMA=1.
    """
    if os.getenv("NPC_USE_OLLAMA", "0") != "1":
        return samples

    enhanced = 0
    for sample in samples:
        try:
            prompt = sample.to_prompt_completion()["prompt"]
            result = subprocess.run(
                ["ollama", "run", model_id, prompt],
                capture_output=True,
                text=True,
                timeout=40,
            )
            text = result.stdout.strip()
            if result.returncode == 0 and text:
                sample.npc_response = text
                enhanced += 1
        except Exception:
            # Keep deterministic template response on any failure.
            continue

    logger.info("Enhanced %d/%d samples with Ollama", enhanced, len(samples))
    return samples


def save_jsonl(samples: List[TrainingSample], output_path: Path):
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        for sample in samples:
            data = sample.to_prompt_completion()
            f.write(json.dumps(data, ensure_ascii=False) + "\n")
    logger.info("Saved %d samples to %s", len(samples), output_path)


def main():
    parser = argparse.ArgumentParser(description="BD-NSCA Training Data Generator v2")
    parser.add_argument("--output", "-o", default="data/train.jsonl")
    parser.add_argument("--samples", "-n", type=int, default=100)
    parser.add_argument("--language", "-l", default="vi", choices=["vi", "en"])
    parser.add_argument("--use-llm", action="store_true")
    parser.add_argument("--data-dir", default=None)
    args = parser.parse_args()
    
    # Determine data directory
    script_dir = Path(__file__).parent
    if args.data_dir:
        data_dir = Path(args.data_dir)
    else:
        data_dir = script_dir.parent / "data"
    
    generator = DataGenerator(data_dir, language=args.language)
    samples = generator.generate_dataset(args.samples)
    if args.use_llm:
        samples = generate_with_llm(samples)
    
    output_path = Path(args.output)
    if not output_path.is_absolute():
        output_path = script_dir.parent / output_path
        
    save_jsonl(samples, output_path)
    
    if samples:
        print("Sample Output:")
        print(json.dumps(samples[0].to_prompt_completion(), indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()
