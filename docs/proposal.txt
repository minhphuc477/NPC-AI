BỘ GIÁO DỤC VÀ ĐÀO TẠO
TRƯỜNG ĐẠI HỌC MỞ 
THÀNH PHỐ HỒ CHÍ MINH
CỘNG HOÀ XÃ HỘI CHỦ NGHĨA VIỆT NAM
Độc lập - Tự do - Hạnh phúc


ĐĂNG KÝ ĐỀ TÀI NGHIÊN CỨU KHOA HỌC SINH VIÊN NĂM HỌC 
2025 - 2026  
1a.
TÊN ĐỀ TÀI TIẾNG VIỆT 
Nâng cao tính tự nhiên và tính ngữ cảnh trong tương tác hội thoại với NPC bằng mô hình ngôn ngữ tinh chỉnh được thông tin bởi trạng thái thế giới game động trong game tường thuật


2
LĨNH VỰC 
Theo ngành học| 
 Khoa học Giáo dục| 
 Khởi nghiệp| 
 Khoa học hành vi| 
 Kinh doanh và quản lý|
1b.
TÊN ĐỀ TÀI TIẾNG ANH
Dynamic Game State-Informed Fine-tuned Language Models for Natural and Context-Aware NPC Dialogue in Narrative Games
3.
GIẢNG VIÊN HƯỚNG DẪN 


Họ và tên:
TS. Lê Đăng Giáp


Đơn vị: 
Khoa Công Nghệ Thông Tin




Di động: 0382821902
Email: giap.ld@ou.edu.vn 
4.
CHỦ NHIỆM ĐỀ TÀI


Họ và tên:
Lê Trần Minh Phúc
Mã số sinh viên: 2251010074
Khoa:
Đào tạo đặc biệt
Năm học: 2025-2026


Di động: 0917900452
Email: 2251010074phuc@ou.edu.vn
5.
SINH VIÊN THAM GIA THỰC HIỆN ĐỀ TÀI 


Họ và tên
Mã số sinh viên
Nội dung nghiên cứu dự kiến được giao
Chữ ký










6.
GIỚI THIỆU Ý TƯỞNG NGHIÊN CỨU


Trong lĩnh vực thiết kế và phát triển trò chơi điện tử tương tác, đặc biệt là các game thuộc thể loại tường thuật (narrative games), nhân vật không người chơi (Non-Player Characters - NPCs) giữ một vai trò cấu trúc và chức năng không thể thay thế. Chúng không chỉ là các thực thể vận hành cơ học trong thế giới ảo mà còn là các tác nhân then chốt trong việc kiến tạo không gian tường thuật, dẫn dắt diễn biến cốt truyện, và quan trọng hơn, thiết lập và duy trì mức độ thuyết phục (believability) của môi trường game, qua đó nuôi dưỡng sự gắn kết cảm xúc (emotional engagement) và trải nghiệm đắm chìm (immersion) của người chơi [1], [2]. Một trong những phương thức tương tác nền tảng, định hình mối quan hệ giữa người chơi và NPC, chính là hệ thống hội thoại. Chất lượng của các tương tác hội thoại này hầu như đều thể hiện qua tính tự nhiên của ngôn ngữ (naturalness), sự mạch lạc trong logic đối đáp, khả năng duy trì tính cách nhân vật (persona consistency), và đặc biệt là độ nhạy cảm, phù hợp với bối cảnh động của trò chơi (dynamic context-awareness); các đặc tính đó đã được công nhận là yếu tố có ảnh hưởng quyết định đến hiệu quả trải nghiệm người chơi [2]. Tuy nhiên, các phương pháp luận truyền thống trong việc xây dựng hệ thống hội thoại NPC, vốn chủ yếu dựa trên các cấu trúc cây hội thoại định sẵn (pre-scripted dialogue trees) hoặc các máy trạng thái hữu hạn (Finite State Machines) với các quy tắc chuyển đổi cố định [3], thường xuyên bộc lộ những hạn chế nội tại nghiêm trọng. Các hệ thống này thường dẫn đến các cuộc hội thoại cứng nhắc, dễ đoán, lặp lại, và đặc biệt là thất bại trong việc phản ánh hoặc phản ứng một cách linh hoạt, thông minh trước sự đa dạng trong hành vi của người chơi cũng như các diễn biến không ngừng thay đổi của môi trường game [1], [2].
Sự trỗi dậy mạnh mẽ của các mô hình ngôn ngữ lớn (Large Language Models - LLMs), được xây dựng trên kiến trúc Transformer tiên tiến [4] và tiêu biểu bởi các mô hình nguồn mở mạnh mẽ như Llama 3 [5], Mistral 7B [6], và Microsoft Phi-3 Mini [16], đã mở ra một hướng tiếp cận mới đầy tiềm năng cho lĩnh vực sinh ngôn ngữ tự nhiên. Với khả năng hiểu và sinh ngôn ngữ ở mức độ phức tạp cao, các LLM sở hữu tiềm năng cách mạng hóa cách thức xây dựng hội thoại NPC, hứa hẹn mang lại sự tự nhiên và đa dạng chưa từng có. Mặc dù vậy, việc ứng dụng trực tiếp các LLM tổng quát, vốn được huấn luyện trên các kho dữ liệu khổng lồ nhưng đa dạng và không chuyên biệt, vào bối cảnh đặc thù của một trò chơi điện tử cụ thể lại đặt ra những thách thức đáng kể. 
Thứ nhất, các mô hình này thường thiếu hụt kiến thức chuyên sâu về thế giới game (domain-specific world knowledge). 
Thứ hai, việc đảm bảo một NPC duy trì được một "tính cách" (persona) đảm bảo bao gồm giọng điệu, phong cách ngôn ngữ, hệ thống niềm tin, và kiến thức nền một cách nhất quán và đáng tin cậy qua các phiên tương tác kéo dài vẫn là một bài toán nghiên cứu đang được quan tâm [2], [7].
Tuy nhiên, một thách thức cốt lõi, và là trọng tâm chính của nghiên cứu này, nằm ở sự hạn chế cố hữu về khả năng nhận thức và phản ứng phù hợp của LLM đối với trạng thái thế giới game động (dynamic game world state). Các LLM, trong cấu hình cơ bản, thường hoạt động như những thực thể xử lý ngôn ngữ biệt lập, thiếu các cơ chế nội tại và hiệu quả để "quan sát" hoặc được "thông báo" một cách liên tục về những gì đang diễn ra theo thời gian thực trong môi trường game tương tác mà NPC đang tồn tại. Chúng không tự nhiên nhận biết được các chi tiết ngữ cảnh quan trọng như hành động NPC đang thực hiện (ví dụ, trạng thái hiện tại của một Behavior Tree), vị trí chính xác trong màn chơi, các đối tượng hay nhân vật khác trong phạm vi cảm nhận, trạng thái của các nhiệm vụ người chơi đang thực thi, hay các sự kiện môi trường vừa xảy ra. Sự thiếu hụt kênh thông tin ngữ cảnh động, liên tục cập nhật từ chính môi trường game này tạo ra một rào cản nghiêm trọng, dẫn đến nguy cơ NPC, dù có thể sinh ra văn bản rất lưu loát về mặt ngôn ngữ, lại phát ngôn những câu hoàn toàn không liên quan, lạc lõng (out-of-context), hoặc thậm chí mâu thuẫn với tình huống thực tế [8]. Tình trạng này không chỉ làm suy giảm nghiêm trọng tính thuyết phục của NPC mà còn có thể phá vỡ logic tường thuật và trải nghiệm nhập vai. Mặc dù các công trình tiên phong như "Generative Agents" [10] đã minh họa tiềm năng ấn tượng của LLM trong việc tạo ra các hành vi và hội thoại phức tạp dựa trên bộ nhớ và cơ chế tự phản ánh trong môi trường mô phỏng 2D, việc tích hợp sâu, điều khiển hiệu quả bởi trạng thái game động, và đánh giá khoa học trong bối cảnh một game engine 3D tiêu chuẩn công nghiệp như Unreal Engine 5 [14], là nền tảng được lựa chọn cho nghiên cứu này nhằm tạo ra một môi trường thử nghiệm phong phú và có độ trung thực cao nhưng vẫn là một lĩnh vực còn nhiều thách thức kỹ thuật và cần các phương pháp tiếp cận hệ thống cụ thể. Các giải pháp ban đầu như chỉ cung cấp mô tả nhân vật tĩnh trong system prompt hoặc dựa vào lịch sử hội thoại ngắn hạn, như được đề cập trong các khảo sát về phương pháp prompting [11], tuy cần thiết nhưng chưa đủ để giải quyết triệt để vấn đề nhận thức bối cảnh động trong môi trường game engine phức tạp.
Để giải quyết bài toán về kiến thức chuyên biệt và tính cách nhân vật, kỹ thuật tinh chỉnh (fine-tuning) các LLM trên các tập dữ liệu nhỏ hơn, đặc thù hơn đã chứng tỏ hiệu quả đáng kể [11], [9]. Đặc biệt, các phương pháp tinh chỉnh hiệu quả tham số (Parameter-Efficient Fine-Tuning - PEFT) như LoRA (Low-Rank Adaptation) [12] và QLoRA (Quantized Low-Rank Adaptation) [13] đã nổi lên như những giải pháp tiên tiến, cho phép chuyên biệt hóa các mô hình ngôn ngữ lớn với chi phí tài nguyên thấp hơn đáng kể. Điều này mở ra khả năng tạo ra các NPC "đúng vai" và sở hữu hệ thống kiến thức phù hợp, ngay cả với nguồn lực hạn chế, thông qua việc huấn luyện trên các nền tảng điện toán đám mây (ví dụ: Google Colab) và sau đó triển khai cục bộ. Tuy nhiên, như đã phân tích, một mô hình dù đã được fine-tune kỹ lưỡng về persona vẫn có thể đưa ra những phản hồi không phù hợp với tình huống nếu thiếu thông tin về bối cảnh tức thời. Do đó, một giải pháp toàn diện và hiệu quả cần phải tích hợp đồng thời cả hai yếu tố then chốt:
(1) Một mô hình ngôn ngữ được fine-tune để nắm bắt chính xác persona và kiến thức nền của NPC. 
(2) Một cơ chế mạnh mẽ để thông tin hóa (inform) mô hình đó bằng dữ liệu ngữ cảnh động được trích xuất trực tiếp và liên tục từ thế giới game.
Xuất phát từ những phân tích trên và nhận diện khoảng trống nghiên cứu hiện hữu, mục tiêu chính của nghiên cứu này là đề xuất, thiết kế, triển khai và đánh giá một kiến trúc hội thoại tiên tiến cho phép các NPC trong game tường thuật sử dụng mô hình ngôn ngữ lớn (dự kiến Microsoft Phi-3 Mini [16] hoặc một mô hình nguồn mở tương đương, phù hợp với khả năng tính toán cục bộ phù hợp với điều kiện kỹ thuật cho phép của sinh viên thực hiện) đã được tinh chỉnh để tạo ra các tương tác hội thoại vừa tự nhiên, vừa duy trì tính cách, vừa phản ứng phù hợp và kịp thời với trạng thái thế giới game động. Ý tưởng khoa học trung tâm là xây dựng một hệ thống tích hợp, trong đó LLM đã được chuyên biệt hóa sẽ được thông tin hóa một cách có hệ thống bởi trạng thái thế giới game động. Các thông tin ngữ cảnh động quan trọng, ví dụ như trạng thái hành vi hiện tại của NPC (trích xuất từ hệ thống điều khiển AI như Behavior Trees), vị trí tương đối, và một số thực thể lân cận, sẽ được thu thập và xử lý bởi một module Context Extractor được thiết kế và tích hợp trực tiếp vào môi trường game Unreal Engine 5 [14]. Thông tin này sau đó sẽ được biểu diễn và cấu trúc hóa một cách hiệu quả để tích hợp vào câu lệnh gợi ý (prompt) thông qua các kỹ thuật Prompt Engineering [11], trước khi được gửi đến mô hình LLM (được triển khai cục bộ cho quá trình inference thông qua các nền tảng như Ollama [15] để đảm bảo khả năng tương tác thời gian thực và giảm thiểu độ trễ) nhằm sinh ra phản hồi hội thoại. Nghiên cứu này sẽ tập trung giải quyết các câu hỏi then chốt sau: 
(1) Làm thế nào để trích xuất và biểu diễn hiệu quả các thông tin trạng thái game động cốt lõi từ Unreal Engine 5 cho một LLM có kích thước phù hợp, có thể chạy cục bộ cho inference? 
(2) Kỹ thuật prompt engineering nào là tối ưu để tích hợp thông tin ngữ cảnh này vào quá trình sinh hội thoại mà vẫn duy trì được tính nhất quán của persona đã fine-tune (nếu có)? 
(3) Mức độ cải thiện về tính tự nhiên, tính nhất quán vai trò, và độ phù hợp ngữ cảnh động của hội thoại NPC là bao nhiêu khi áp dụng kiến trúc đề xuất so với các phương pháp baseline (ví dụ: mô hình gốc không có ngữ cảnh động; mô hình fine-tuned/instruct không có ngữ cảnh động)? 
Việc đánh giá sẽ được thực hiện một cách khoa học, sử dụng kết hợp các phương pháp tự động và phân tích định tính dựa trên tiêu chí bởi nhà nghiên cứu [7].
7.
MỤC TIÊU CỦA ĐỀ TÀI, ĐỐI TƯỢNG, PHẠM VI VÀ THÁCH THỨC


Nghiên cứu này nhằm mục đích giải quyết những thách thức hiện hữu trong việc tạo ra các tương tác hội thoại tự nhiên và có nhận thức ngữ cảnh cho nhân vật không người chơi (NPC) trong môi trường game tường thuật. Sự thiếu linh hoạt và khả năng thích ứng của các hệ thống hội thoại NPC truyền thống, thường dựa trên cây hội thoại định sẵn hoặc máy trạng thái hữu hạn [3], đã hạn chế đáng kể tính thuyết phục (believability) và trải nghiệm đắm chìm của người chơi [1], [2]. Sự trỗi dậy của các mô hình ngôn ngữ lớn (LLM), với khả năng hiểu và sinh ngôn ngữ phức tạp [4], mở ra một hướng đi đầy hứa hẹn để khắc phục những hạn chế này [18], [19]. Do đó, mục tiêu bao trùm của công trình này là đề xuất, thiết kế, triển khai và đánh giá một kiến trúc hệ thống hội thoại tiên tiến. Kiến trúc này sẽ khai thác năng lực của một LLM đã được tinh chỉnh (fine-tuned) cho vai trò NPC cụ thể, đồng thời được thông tin hóa một cách có hệ thống bằng dữ liệu trạng thái thế giới game động, được trích xuất trực tiếp và liên tục từ môi trường game.
7.1. Các mục tiêu nghiên cứu cụ thể
Để hiện thực hóa mục tiêu tổng quát, nghiên cứu này sẽ theo đuổi năm mục tiêu cụ thể (Research Objectives - RO) được trình bày tuần tự như sau.
Đầu tiên, (RO1) một cuộc khảo sát và phân tích phê bình toàn diện các công trình khoa học hiện hành sẽ được tiến hành. Phân tích này sẽ tập trung vào các ứng dụng của LLM trong việc tạo hội thoại cho NPC, nhằm nhận diện các phương pháp tiếp cận, thành tựu đã đạt được, những hạn chế còn tồn tại và các khoảng trống nghiên cứu cần được giải quyết. Đặc biệt, nghiên cứu sẽ chú trọng đến những thách thức liên quan đến việc tích hợp thông tin ngữ cảnh động từ các game engine 3D hiện đại, như Unreal Engine 5 (UE5) [14], vào các LLM có khả năng vận hành cục bộ cho các ứng dụng thời gian thực. Các tổng quan và khảo sát gần đây của Gallotta và cộng sự [18] cũng như của Sweetser [19] sẽ cung cấp một nền tảng quan trọng cho việc định vị nghiên cứu này trong bối cảnh khoa học hiện tại.
Tiếp theo, (RO2) nghiên cứu sẽ tập trung vào việc thiết kế chi tiết một kiến trúc hệ thống tích hợp (system architecture) khả thi và hiệu quả. Kiến trúc này được thiết kế để cho phép giao tiếp hai chiều thông suốt giữa game engine UE5 [14] và một LLM nguồn mở, dự kiến là Meta Llama 3 8B [5] hoặc Microsoft Phi-3 Mini [16]. Các thành phần cốt lõi của kiến trúc bao gồm: 
(a) Một module "Context Extractor" (Bộ trích xuất ngữ cảnh), có nhiệm vụ thu thập, tiền xử lý và cấu trúc hóa thông tin trạng thái game động có liên quan từ môi trường UE5 [14].
(b) Một module "Prompt Formatter" (Bộ định dạng Câu lệnh gợi ý), chịu trách nhiệm tổng hợp thông tin ngữ cảnh động, lịch sử hội thoại và các đặc tả về tính cách (persona) của NPC để tạo ra các câu lệnh đầu vào (prompts) tối ưu cho LLM, dựa trên các nguyên tắc và kỹ thuật của prompt engineering đã được hệ thống hóa bởi Liu và cộng sự [11].
Sau khi hoàn tất thiết kế kiến trúc, (RO3) một hệ thống nguyên mẫu (prototype) hoạt động sẽ được phát triển và triển khai. Hệ thống này sẽ sử dụng một LLM đã được tinh chỉnh (fine-tuned) cho một persona NPC cụ thể. Quá trình tinh chỉnh sẽ ưu tiên các kỹ thuật hiệu quả tham số (Parameter-Efficient Fine-Tuning - PEFT) như QLoRA [13], theo phương pháp của Dettmers và cộng sự [13], thực hiện trên nền tảng điện toán đám mây để tối ưu hóa tài nguyên. Mô hình đã tinh chỉnh sau đó sẽ được triển khai để thực hiện quá trình suy luận (inference) cục bộ thông qua một nền tảng trung gian như Ollama [15], nhằm đảm bảo khả năng tương tác thời gian thực trong game.
Tiếp đến là đóng góp kỹ thuật của nghiên cứu, (RO4) là việc xây dựng và thử nghiệm một phương pháp luận (methodology) cho việc trích xuất, biểu diễn và tích hợp một cách hiệu quả ít nhất ba loại thông tin trạng thái game động cốt lõi. Các thông tin này sẽ được lấy từ môi trường UE5 [14], ví dụ như trạng thái hiện tại của hệ thống Behavior Tree điều khiển hành vi NPC, tọa độ vị trí của NPC trong không gian game, thông tin về các đối tượng hoặc nhân vật quan trọng trong phạm vi nhận biết của NPC, và các sự kiện môi trường nổi bật vừa diễn ra. Phương pháp này sẽ tìm cách ánh xạ các thông tin game đa dạng này thành các chỉ dẫn mà LLM có thể hiểu và tận dụng, một cách tiếp cận có thể tham khảo các ý tưởng từ công trình của Branavan và cộng sự [8] về việc học ánh xạ chỉ dẫn ngôn ngữ sang hành động.
Cuối cùng, (RO5) một quy trình đánh giá khoa học nghiêm ngặt sẽ được thiết kế và thực thi. Mục tiêu của quy trình này là đo lường và so sánh hiệu quả của hệ thống hội thoại đề xuất so với các phương pháp baseline (ví dụ: LLM gốc không được cung cấp ngữ cảnh động; LLM đã được tinh chỉnh persona nhưng không được cập nhật ngữ cảnh động). Việc đánh giá sẽ tập trung vào ba khía cạnh chính của chất lượng hội thoại:
(a) Độ phù hợp và tính liên quan của hội thoại với ngữ cảnh động của game.
(b) Mức độ duy trì tính nhất quán trong vai trò và tính cách (persona consistency) của NPC theo thiết kế [2].
(c) Tính tự nhiên, lưu loát của ngôn ngữ được sinh ra bởi LLM. Các độ đo tự động đã được công nhận trong lĩnh vực đánh giá sinh văn bản, chẳng hạn như BERTScore của Zhang và cộng sự [17] để đo độ tương đồng ngữ nghĩa, và perplexity (nếu phù hợp với kiến trúc mô hình) để đánh giá tính lưu loát, sẽ được sử dụng. 
Song song đó, phân tích định tính chi tiết các trường hợp hội thoại cụ thể sẽ được tiến hành, dựa trên các phương pháp và tiêu chí đánh giá đã được khảo sát và tổng hợp bởi Celikyilmaz và cộng sự [7].
7.2. Đối tượng nghiên cứu
Đối tượng nghiên cứu của đề tài này bao gồm hai khía cạnh chính, được phân tách rõ ràng giữa phương diện lý thuyết và thực nghiệm, nhằm đảm bảo tính toàn diện và chiều sâu của công trình.
Về mặt lý thuyết, đối tượng nghiên cứu tập trung vào việc khảo sát và vận dụng các kỹ thuật mô hình hóa ngôn ngữ lớn, đặc biệt là kiến trúc Transformer [4] vốn là nền tảng của các LLM hiện đại, và các mô hình nguồn mở hiệu năng cao có khả năng tùy biến như Meta Llama 3 [5] và Microsoft Phi-3 Mini [16]. Nghiên cứu sẽ đi sâu vào các phương pháp tinh chỉnh hiệu quả tham số (PEFT), với trọng tâm là kỹ thuật QLoRA [13] được đề xuất bởi Dettmers và cộng sự [13], cho phép chuyên biệt hóa LLM với chi phí tài nguyên thấp. Các kỹ thuật xây dựng câu lệnh gợi ý (Prompt Engineering), như được hệ thống hóa trong khảo sát của Liu và cộng sự [11], cũng là một đối tượng nghiên cứu quan trọng, nhằm tối ưu hóa việc điều hướng hành vi của LLM. Bên cạnh đó, các phương pháp luận trong việc biểu diễn và tích hợp thông tin ngữ cảnh động từ môi trường game 3D phức tạp, cụ thể là Unreal Engine 5 [14], sẽ được nghiên cứu kỹ lưỡng. Cuối cùng, các phương pháp và độ đo (metrics) dùng để đánh giá chất lượng của hệ thống sinh ngôn ngữ tự nhiên trong bối cảnh tương tác, như được trình bày trong khảo sát của Celikyilmaz và cộng sự [7] và việc ứng dụng cụ thể của BERTScore [17], sẽ là một phần không thể thiếu của nền tảng lý thuyết.
Về mặt thực nghiệm, đối tượng nghiên cứu chính là hệ thống phần mềm nguyên mẫu được phát triển trong khuôn khổ đề tài. Hệ thống này là sự tích hợp giữa game engine Unreal Engine 5 [14] và một LLM đã được tinh chỉnh persona và được triển khai để hoạt động cục bộ thông qua nền tảng Ollama [15]. Hiệu năng hoạt động của hệ thống nguyên mẫu này, cụ thể là chất lượng của các đoạn hội thoại được sinh ra trong các kịch bản game có trạng thái thay đổi, sẽ là đối tượng trọng tâm của quá trình đánh giá thực nghiệm. Chất lượng này sẽ được xem xét qua các khía cạnh như độ tự nhiên của ngôn ngữ, tính nhất quán trong việc duy trì vai trò và tính cách của NPC [2], cũng như độ liên quan và phù hợp của phản hồi hội thoại với ngữ cảnh động tức thời của game. Việc phân tích hiệu quả tương đối của hệ thống đề xuất so với các mô hình baseline cũng là một phần quan trọng của đánh giá thực nghiệm, phù hợp với các hướng nghiên cứu thăm dò về ứng dụng LLM trong lĩnh vực trò chơi điện tử được phản ánh trong các bài tổng quan gần đây [18], [19].
7.3. Phạm vi Nghiên cứu
Để đảm bảo tính khả thi và tập trung của nghiên cứu trong khuôn khổ thời gian và nguồn lực hạn chế của một đề tài khoa học sinh viên, phạm vi của công trình này được xác định cụ thể như sau:
Nền tảng phát triển game được lựa chọn là Unreal Engine 5 (UE5) [14]. Quyết định này dựa trên vị thế hàng đầu của UE5 [14] trong ngành công nghiệp game, khả năng cung cấp một môi trường phát triển 3D toàn diện và phong phú, cùng với các công cụ mạnh mẽ cho việc xây dựng và kịch bản hóa trí tuệ nhân tạo (AI) cho NPC, bao gồm hệ thống Behavior Trees. Tài liệu kỹ thuật chi tiết [14] và cộng đồng người dùng lớn mạnh của UE5 [14] cũng là những yếu tố thuận lợi cho việc xây dựng một hệ thống nguyên mẫu phức tạp và thực hiện các thử nghiệm liên quan đến trích xuất và tích hợp ngữ cảnh động.
Về mô hình ngôn ngữ lớn (LLM), đề tài sẽ tập trung vào việc sử dụng và tinh chỉnh một LLM nguồn mở cụ thể. Các ứng viên tiềm năng bao gồm Meta Llama 3 8B [5] hoặc Microsoft Phi-3 Mini [16], do chúng đại diện cho thế hệ LLM nguồn mở tiên tiến, có sự cân bằng tốt giữa hiệu năng sinh ngôn ngữ và yêu cầu tài nguyên tính toán. Quá trình tinh chỉnh sẽ được thực hiện bằng kỹ thuật QLoRA [13] trên nền tảng điện toán đám mây. Sau đó, mô hình đã tinh chỉnh sẽ được triển khai để thực hiện suy luận (inference) cục bộ thông qua nền tảng Ollama [15], nhằm tối ưu hóa cho các tương tác thời gian thực. Việc khảo sát và so sánh hiệu năng chi tiết của nhiều mô hình LLM nền tảng khác nhau nằm ngoài phạm vi của nghiên cứu này.
Đối với thông tin ngữ cảnh game động, nghiên cứu sẽ giới hạn ở việc trích xuất và tích hợp một tập hợp các thông tin cốt lõi và khả thi từ môi trường UE5 [14]. Các loại thông tin dự kiến bao gồm trạng thái hiện tại của Behavior Tree điều khiển NPC, vị trí không gian của NPC, thông tin về một số thực thể (đối tượng hoặc nhân vật khác) lân cận có vai trò quan trọng, và một số sự kiện game đơn giản vừa xảy ra. Nghiên cứu sẽ không cố gắng bao phủ toàn bộ trạng thái phức tạp và chi tiết của thế giới game.
Phương thức tương tác hội thoại trong phạm vi nghiên cứu này sẽ được giới hạn ở dạng văn bản (text-based dialogue). Việc tích hợp các yếu tố phi ngôn ngữ như giọng nói hay biểu cảm khuôn mặt, mặc dù quan trọng cho tính thuyết phục tổng thể [2], sẽ không được triển khai trong giai đoạn này vì không có tính khả thi và tài nguyên để thực hiện.
Quy trình đánh giá sẽ tập trung vào chất lượng nội tại của các đoạn hội thoại được sinh ra. Các phương pháp đánh giá tự động, như BERTScore [17] và perplexity (nếu phù hợp), sẽ được sử dụng để cung cấp các chỉ số định lượng. Song song, một phần quan trọng của đánh giá sẽ là phân tích định tính các trường hợp hội thoại cụ thể (case study analysis) do chính nhà nghiên cứu thực hiện, dựa trên các tiêu chí đã được định trước về độ liên quan ngữ cảnh, tính nhất quán vai trò [2] và tính tự nhiên của ngôn ngữ. Do những hạn chế về thời gian và nguồn lực, nghiên cứu này sẽ không bao gồm việc thực hiện các khảo sát hoặc thu thập đánh giá từ người dùng cuối (user studies) ở quy mô lớn để đo lường các khía cạnh như trải nghiệm người chơi hay mức độ hiện diện (presence), vốn là đối tượng của các nghiên cứu quy mô hơn như của Christiansen và cộng sự [20]. Các khía cạnh này có thể được xem xét cho các giai đoạn nghiên cứu tiếp theo nếu có khả năng thực hiện.
Ngôn ngữ chính được sử dụng trong toàn bộ quá trình phát triển, thử nghiệm và đánh giá là tiếng Anh. Lựa chọn này nhằm tận dụng tối đa các mô hình ngôn ngữ và bộ dữ liệu huấn luyện chất lượng cao đã có sẵn bằng tiếng Anh, cũng như tạo điều kiện thuận lợi cho việc so sánh với các công trình quốc tế.
7.4. Các thách thức tiềm ẩn và giải pháp giảm thiểu
Trong quá trình thực hiện, nghiên cứu có thể đối mặt với một số thách thức tiềm ẩn. Việc nhận diện sớm và xây dựng các giải pháp giảm thiểu là cần thiết để đảm bảo sự thành công của đề tài.
Một thách thức chính là hạn chế về tài nguyên tính toán cho cả quá trình tinh chỉnh (fine-tuning) LLM và quá trình suy luận (inference) cục bộ. Việc fine-tuning các mô hình có kích thước trung bình như Meta Llama 3 8B [5] bằng kỹ thuật QLoRA [13], mặc dù hiệu quả về tham số [13], vẫn có thể đòi hỏi dung lượng VRAM và thời gian tính toán đáng kể, có khả năng vượt quá giới hạn của các nền tảng điện toán đám mây miễn phí hoặc chi phí thấp. Hơn nữa, tốc độ suy luận của LLM khi chạy cục bộ trên phần cứng phổ thông có thể không đáp ứng được yêu cầu tương tác thời gian thực của môi trường game. Để giảm thiểu rủi ro này, nghiên cứu sẽ ưu tiên lựa chọn các mô hình LLM có kích thước nhỏ hơn nhưng vẫn duy trì hiệu năng tốt, như Microsoft Phi-3 Mini [16]. Các kỹ thuật tối ưu hóa như quantization (đã tích hợp trong QLoRA [13]) sẽ được tận dụng triệt để. Trong trường hợp cần thiết và nếu nằm trong khả năng cho phép, việc sử dụng các gói tài nguyên trả phí ở mức độ hạn chế trên nền tảng đám mây sẽ được cân nhắc. Đồng thời, thiết kế câu lệnh gợi ý [11] và lượng thông tin ngữ cảnh được truyền vào LLM sẽ được tối ưu hóa để giảm tải tính toán cho quá trình inference.
Thách thức thứ hai liên quan đến độ phức tạp kỹ thuật trong việc trích xuất, biểu diễn và tích hợp thông tin ngữ cảnh động từ Unreal Engine 5 [14]. Việc truy cập và lấy dữ liệu từ các hệ thống nội bộ của UE5 [14], chẳng hạn như trạng thái của Behavior Trees hoặc thông tin từ scene graph, có thể đòi hỏi kiến thức chuyên sâu về lập trình C++ và/hoặc Blueprints của engine. Hơn nữa, việc chuyển hóa các dữ liệu game đa dạng này thành một định dạng mà LLM có thể hiểu và tận dụng một cách hiệu quả là một bài toán không tầm thường. Để đối phó, nghiên cứu sẽ áp dụng phương pháp tiếp cận tăng dần, bắt đầu với việc trích xuất các loại thông tin ngữ cảnh đơn giản và dễ truy cập nhất. Việc nghiên cứu kỹ lưỡng tài liệu kỹ thuật của Unreal Engine [14] và tham khảo các dự án mã nguồn mở có tính năng tương tự (nếu có) sẽ được ưu tiên. Trọng tâm sẽ được đặt vào việc phát triển các kỹ thuật prompt engineering [11] linh hoạt và sáng tạo để "phiên dịch" thông tin từ game cho LLM, có thể thử nghiệm với các định dạng như JSON hoặc các mô tả bằng ngôn ngữ tự nhiên.
Một rủi ro cố hữu khi làm việc với LLM là khả năng mô hình tạo ra các phản hồi không mong muốn, chẳng hạn như thông tin sai lệch (hallucination), không duy trì được tính cách nhân vật một cách nhất quán qua các lượt hội thoại [2], hoặc đưa ra các câu trả lời lạc đề so với tình huống game hiện tại, ngay cả khi đã được fine-tune và cung cấp thông tin ngữ cảnh. Để giảm thiểu vấn đề này, sự cẩn trọng tối đa sẽ được áp dụng trong quá trình chuẩn bị dữ liệu và thực hiện fine-tuning persona, đảm bảo dữ liệu huấn luyện có chất lượng cao và phản ánh đúng tính cách mong muốn của NPC. Câu lệnh gợi ý (prompt) [11] sẽ được thiết kế một cách chi tiết, bao gồm các chỉ dẫn rõ ràng về vai trò, mục tiêu của cuộc hội thoại, và có thể cả các ràng buộc tiêu cực (negative constraints) để hạn chế các chủ đề hoặc kiểu phản hồi không mong muốn. Các kỹ thuật kiểm soát đầu ra của LLM ở mức độ cơ bản, nếu khả thi và phù hợp với kiến trúc triển khai, cũng sẽ được nghiên cứu và áp dụng. Một cơ chế dự phòng đơn giản, ví dụ như NPC đưa ra một câu trả lời chung chung hoặc yêu cầu người chơi làm rõ khi LLM không tạo được phản hồi phù hợp, sẽ được xây dựng.
Cuối cùng, giới hạn về thời gian thực hiện đề tài là một yếu tố cần được quản lý chặt chẽ. Khối lượng công việc bao gồm việc tìm hiểu các công nghệ mới (LLMs [5], [16], PEFT [12], [13], UE5 [14]), chuẩn bị dữ liệu, thực hiện fine-tuning, lập trình tích hợp hệ thống trong UE5 [14], thiết kế các kịch bản thử nghiệm và tiến hành đánh giá là rất lớn so với khung thời gian hạn hẹp của một đề tài nghiên cứu khoa học sinh viên. Đề tài có thể sẽ không thể thành công thực hiện ứng dụng hết tất cả những RO được đưa ra trong thời gian khung định ít ỏi, cần phải quản lý chặt chẽ và giảm thiểu những rủi ro nhất định để có thể thu hoạch được một đề tài vẫn có giá trị học thuật.
8.
CƠ SỞ LÝ THUYẾT VÀ LỊCH SỬ NGHIÊN CỨU




Nghiên cứu này được định vị tại giao điểm của nhiều lĩnh vực khoa học và công nghệ then chốt, bao gồm trí tuệ nhân tạo trong game (Game AI) [1], xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP), và Học Máy (Machine Learning - ML). Cơ sở lý thuyết của đề tài được xây dựng trên sự tổng hợp các nguyên lý, thành tựu và xu hướng phát triển từ các lĩnh vực này, đồng thời tập trung vào việc nhận diện những thách thức và khoảng trống kiến thức hiện hữu trong nỗ lực tạo ra các tác nhân hội thoại thông minh và có khả năng nhận thức ngữ cảnh sâu sắc trong môi trường game tương tác.
Lịch sử phát triển của nhân vật không người chơi (NPC) trong trò chơi điện tử cho thấy một sự tiến hóa đáng kể, từ các thực thể phản ứng đơn giản, hoạt động theo các kịch bản cứng nhắc và có giới hạn [3], đến mục tiêu tạo ra các tác nhân ngày càng phức tạp hơn nhằm nâng cao tính thuyết phục (believability) và trải nghiệm đắm chìm (immersion) của người chơi [1], [2]. Các phương pháp truyền thống, như việc sử dụng máy trạng thái hữu hạn (Finite State Machines - FSMs) [3] hay các kỹ thuật lập kế hoạch cổ điển để điều khiển hành vi NPC, cùng với các hệ thống hội thoại dựa trên cây lựa chọn định sẵn (pre-scripted dialogue trees) [3], mặc dù hữu dụng trong việc tạo ra các hành vi có cấu trúc cho các nhiệm vụ cụ thể và cung cấp một mức độ tương tác cơ bản, thường xuyên bộc lộ những hạn chế nghiêm trọng trong việc mô hình hóa sự linh hoạt, tính tự nhiên và khả năng ứng biến cần thiết cho các tương tác hội thoại thực sự năng động và các hành vi xã hội phức tạp trong game. Nghiên cứu của Warpefelt [2] đã nhấn mạnh tầm quan trọng của việc NPC hành xử theo cách mà người chơi mong đợi và có thể hiểu được trong bối cảnh tường thuật và cơ chế của trò chơi, trong đó hệ thống hội thoại đóng vai trò cốt yếu.
Một cuộc cách mạng trong lĩnh vực NLP đã diễn ra với sự xuất hiện của kiến trúc Transformer [4], vốn là nền tảng cho sự phát triển và thành công của các mô hình ngôn ngữ lớn (LLMs) được huấn luyện trên dữ liệu quy mô web. Các mô hình LLM tiêu biểu như Meta Llama 3 [5], Mistral 7B [6], và gần đây là Microsoft Phi-3 Mini [16], đã chứng minh khả năng vượt trội trong việc hiểu và sinh ngôn ngữ tự nhiên ở mức độ phức tạp cao. Những khả năng này mở ra tiềm năng ứng dụng rộng rãi, bao gồm cả việc cách mạng hóa cách thức tạo ra hội thoại cho NPC trong trò chơi điện tử [18], [19]. Khả năng học trong ngữ cảnh (in-context learning) và thực hiện các tác vụ với ít hoặc không cần ví dụ huấn luyện cụ thể (zero-shot hoặc few-shot capabilities) [11] của các LLM này là đặc biệt hấp dẫn cho việc tạo ra các tương tác đa dạng và không lường trước. Tuy nhiên, việc áp dụng trực tiếp các LLM tổng quát, vốn được huấn luyện trên các kho dữ liệu khổng lồ nhưng đa dạng và không chuyên biệt, vào vai trò cụ thể của một NPC trong một thế giới game nhất định thường gặp phải các rào cản đáng kể. Các thách thức chính bao gồm sự thiếu hụt kiến thức chuyên biệt về thế giới và các quy tắc của game (domain-specific knowledge) và khó khăn trong việc duy trì một "tính cách" (persona) nhất quán và đáng tin cậy cho NPC qua nhiều lượt tương tác kéo dài [2]. Các khảo sát gần đây của Gallotta và cộng sự [18] và Sweetser [19] đã cung cấp một cái nhìn tổng quan về các cơ hội và thách thức khi tích hợp LLM vào các khía cạnh khác nhau của phát triển game, bao gồm việc tăng cường AI cho NPC và làm phong phú thêm các yếu tố tường thuật.
Để giải quyết các vấn đề về kiến thức chuyên biệt và tính nhất quán của nhân vật, cộng đồng nghiên cứu đã tập trung vào hai hướng tiếp cận chính song song: tinh chỉnh mô hình (fine-tuning) và các kỹ thuật xây dựng câu lệnh gợi ý (prompt engineering) [11]. Quá trình tinh chỉnh, đặc biệt là các phương pháp tinh chỉnh hiệu quả tham số (Parameter-Efficient Fine-Tuning - PEFT) như LoRA (Low-Rank Adaptation) [12] và gần đây hơn là QLoRA (Quantized Low-Rank Adaptation) [13], cho phép điều chỉnh hành vi của các LLM lớn để phù hợp hơn với một miền kiến thức cụ thể hoặc một vai trò nhân vật nhất định mà không cần phải huấn luyện lại toàn bộ mô hình. Điều này giúp tiết kiệm đáng kể tài nguyên tính toán và thời gian, một yếu tố quan trọng cho các nhà phát triển game. Kỹ thuật QLoRA [13] còn tiến một bước xa hơn bằng cách áp dụng các phương pháp lượng tử hóa (quantization) trong quá trình tinh chỉnh, cho phép huấn luyện các mô hình rất lớn ngay cả trên các phần cứng có tài nguyên hạn chế hơn. Song song đó, các kỹ thuật prompt engineering [11], bao gồm cả việc điều chỉnh theo chỉ dẫn (instruction tuning) như được minh họa trong công trình của Peng và cộng sự với GPT-4 [9], lại tập trung vào việc thiết kế một cách cẩn thận các câu lệnh đầu vào (prompts) để hướng dẫn LLM thực hiện tác vụ mong muốn mà không cần phải cập nhật các tham số của mô hình gốc.
Mặc dù những tiến bộ này rất đáng kể trong việc cải thiện khả năng ngôn ngữ và tính cách của NPC, một thách thức nền tảng và cốt lõi vẫn tồn tại: sự thiếu kết nối giữa khả năng ngôn ngữ ưu việt của LLM và nhận thức về môi trường tương tác tức thời và động của thế giới game. Các LLM, trong cấu hình cơ bản, thường hoạt động như những thực thể xử lý ngôn ngữ biệt lập, xử lý thông tin chủ yếu dựa trên prompt đầu vào và bộ nhớ tham số nội tại của chúng, mà không có nhận thức trực tiếp hoặc liên tục về trạng thái động của thế giới bên ngoài. Điều này đặc biệt đúng đối với các môi trường game 3D phức tạp và liên tục thay đổi được quản lý bởi một game engine hiện đại như Unreal Engine 5 [14]. Hệ quả là, NPC dù có thể sinh ra văn bản rất lưu loát và đúng ngữ pháp, vẫn có nguy cơ phát ngôn những câu hoàn toàn không liên quan, lạc lõng (out-of-context), hoặc thậm chí mâu thuẫn với tình huống thực tế đang diễn ra trong game, làm suy giảm nghiêm trọng tính thuyết phục [2] và trải nghiệm nhập vai [1]. Các nghiên cứu về học ngôn ngữ có cơ sở (grounded language learning), ví dụ như công trình của Branavan và cộng sự [8] về việc học ánh xạ các chỉ dẫn ngôn ngữ cao cấp sang các chuỗi hành động trong một môi trường cụ thể, đã chạm đến vấn đề này, nhưng thường trong các bối cảnh đơn giản hơn nhiều so với sự phức tạp của game 3D hiện đại.
Công trình tiên phong "Generative Agents" của Park và cộng sự [10] đã minh họa một cách ấn tượng tiềm năng của LLM trong việc tạo ra các hành vi xã hội phức tạp và các đoạn hội thoại có vẻ hợp lý dựa trên cơ chế bộ nhớ và tự phản ánh (reflection) trong một môi trường mô phỏng 2D. Tuy nhiên, như các khảo sát gần đây [18], [19] cũng đã chỉ ra, việc tích hợp sâu, điều khiển hiệu quả bởi trạng thái game động được trích xuất trực tiếp từ một game engine 3D tiêu chuẩn công nghiệp như UE5 [14], và đánh giá khoa học trong bối cảnh đó vẫn là một lĩnh vực còn nhiều thách thức kỹ thuật và cần các phương pháp tiếp cận hệ thống cụ thể. Đề tài này khác biệt ở chỗ tập trung vào việc thiết kế và đánh giá một kiến trúc cho phép LLM nhận thức và phản ứng với các thông tin ngữ cảnh động được trích xuất trực tiếp và liên tục từ các thành phần nội tại của UE5 [14].
Các nghiên cứu gần đây của Christiansen và cộng sự [20] về trải nghiệm tương tác với NPC điều khiển bởi LLM hay của Song [21] về các hệ thống hội thoại đa nền tảng, tuy cho thấy sự phát triển nhanh chóng của lĩnh vực, nhưng vẫn chưa giải quyết triệt để bài toán tích hợp sâu ngữ cảnh động từ game engine 3D vào quá trình ra quyết định hội thoại của LLM. Do đó, nghiên cứu này đề xuất một kiến trúc tích hợp Unreal Engine 5 [14] với một LLM nguồn mở đã được tinh chỉnh hiệu quả và được triển khai cục bộ. Mục tiêu chính là phát triển và đánh giá một phương pháp luận cụ thể để thông tin hóa LLM bằng trạng thái game động, nhằm tạo ra các NPC có khả năng hội thoại không chỉ tự nhiên và nhất quán về tính cách [2], mà còn thực sự phù hợp và nhạy bén với bối cảnh tức thời của trò chơi. Việc đánh giá hiệu quả của hệ thống sẽ kết hợp các phương pháp định lượng, như sử dụng BERTScore [17] để đo độ tương đồng ngữ nghĩa, với các phân tích định tính chi tiết, dựa trên các hướng dẫn về đánh giá sinh văn bản của Celikyilmaz và cộng sự [7].
9.
PHƯƠNG PHÁP NGHIÊN CỨU




Để hiện thực hóa các mục tiêu nghiên cứu đã xác định (Mục 7.1) và giải quyết các câu hỏi nghiên cứu cốt lõi (Mục 6), đề tài này sẽ triển khai một phương pháp luận nghiên cứu tổng hợp. Phương pháp này kết hợp chặt chẽ giữa nghiên cứu lý thuyết nền tảng, thiết kế và phát triển hệ thống (system design and development), và đánh giá thực nghiệm (experimental evaluation) một cách khoa học. Quy trình nghiên cứu được cấu trúc theo các giai đoạn logic, nhằm đảm bảo tính hệ thống, tính khoa học và tính khả thi trong khuôn khổ thời gian và nguồn lực của một đề tài nghiên cứu khoa học sinh viên.
9.1. Nghiên cứu nền tảng lý thuyết và tổng quan tài liệu chi tiết
Quá trình nghiên cứu được khởi đầu bằng giai đoạn nghiên cứu nền tảng lý thuyết và tổng quan tài liệu một cách hệ thống. Giai đoạn này tập trung vào việc khảo sát sâu rộng và phân tích phê bình các công trình khoa học, tài liệu kỹ thuật và các báo cáo chuyên ngành liên quan đến các lĩnh vực cốt lõi của đề tài. Cụ thể, nghiên cứu sẽ đi sâu vào:
Các Mô hình Ngôn ngữ Lớn (LLMs): Nghiên cứu chi tiết về kiến trúc Transformer [4] làm nền tảng cho các LLM hiện đại; các đặc điểm, ưu nhược điểm của các mô hình nguồn mở tiêu biểu như Meta Llama 3 [5], Mistral 7B [6], và Microsoft Phi-3 Mini [16]; các khái niệm về học trong ngữ cảnh (in-context learning) và các khả năng zero-shot/few-shot [11].
Kỹ thuật tinh chỉnh mô hình (Fine-tuning): Tập trung vào các phương pháp tinh chỉnh hiệu quả tham số (Parameter-Efficient Fine-Tuning - PEFT), đặc biệt là LoRA (Low-Rank Adaptation) [12] và QLoRA (Quantized Low-Rank Adaptation) [13]. Nghiên cứu sẽ bao gồm cả lý thuyết hoạt động, các thư viện mã nguồn mở hỗ trợ, và các hướng dẫn thực hành chi tiết cho việc áp dụng các kỹ thuật này. Quá trình chuẩn bị dữ liệu cho fine-tuning (ví dụ: số lượng mẫu, định dạng) và việc lựa chọn các siêu tham số huấn luyện quan trọng (ví dụ: learning rate, số epochs, batch size) sẽ được tìm hiểu kỹ lưỡng.
Kỹ thuật xây dựng câu lệnh gợi ý (Prompt Engineering): Tổng hợp và phân tích các phương pháp, chiến lược và thực tiễn tốt nhất trong việc thiết kế prompt hiệu quả để điều khiển hành vi của LLM, dựa trên các khảo sát hệ thống như của Liu và cộng sự [11], cũng như các kỹ thuật điều chỉnh theo chỉ dẫn (instruction tuning) như được minh họa bởi Peng và cộng sự với GPT-4 [9]. Các kỹ thuật cụ thể như chain-of-thought prompting hay few-shot prompting [11] sẽ được xem xét về khả năng áp dụng cho bài toán cụ thể của nghiên cứu.
Tích hợp ngữ cảnh động và học ngôn ngữ có cơ sở: Xem xét các công trình nghiên cứu về học ngôn ngữ có cơ sở (grounded language learning) [8], các phương pháp biểu diễn và tích hợp thông tin ngữ cảnh từ môi trường tương tác vào mô hình ngôn ngữ. Nghiên cứu sẽ phân tích các cách tiếp cận hiện có và những thách thức đặc thù khi áp dụng vào môi trường game 3D phức tạp. Các công trình tiên phong như "Generative Agents" của Park và cộng sự [10] sẽ được phân tích để rút ra bài học kinh nghiệm và xác định các điểm cải tiến tiềm năng cho việc tích hợp ngữ cảnh động trong game.
Trí tuệ nhân tạo trong game và hệ thống hội thoại NPC: Nghiên cứu các lý thuyết về thiết kế NPC [1], [2]; các phương pháp truyền thống trong xây dựng hệ thống hội thoại NPC [3], và những hạn chế của chúng.
Đánh giá sinh ngôn ngữ tự nhiên (NLG Evaluation): Rà soát các phương pháp và độ đo (metrics) dùng để đánh giá chất lượng của các hệ thống sinh văn bản, bao gồm cả các độ đo tự động (ví dụ: BLEU, ROUGE, Perplexity, BERTScore [17]) và các phương pháp đánh giá định tính dựa trên tiêu chí bởi con người, như được tổng hợp trong khảo sát của Celikyilmaz và cộng sự [7]. Một rubric (bảng tiêu chí) chi tiết cho việc đánh giá định tính bởi nhà nghiên cứu sẽ được phát triển dựa trên các tiêu chí về độ liên quan ngữ cảnh, tính nhất quán vai trò [2] và tính tự nhiên.
Giai đoạn này nhằm mục đích củng cố cơ sở lý thuyết, xác định rõ hơn các thách thức kỹ thuật và khoa học, từ đó định hình phương pháp tiếp cận cụ thể và các quyết định thiết kế trong các giai đoạn tiếp theo.
9.2. Thiết kế kiến trúc hệ thống và công nghệ
Trên cơ sở lý thuyết đã xây dựng, giai đoạn tiếp theo là thiết kế kiến trúc và công nghệ hệ thống. Nghiên cứu sẽ đề xuất và đặc tả chi tiết một kiến trúc phần mềm tích hợp, cho phép tương tác hai chiều hiệu quả và linh hoạt giữa môi trường phần mềm làm game (game engine) dự kiến được sử dụng (Unreal Engine 5 - UE5) [14] và mô hình LLM (dự kiến Meta Llama 3 [5] hoặc Microsoft Phi-3 Mini [16]). Kiến trúc này sẽ định nghĩa các thành phần chính và luồng dữ liệu giữa chúng:
(1) Module trích xuất ngữ cảnh (Context Extractor): Được nhúng và phát triển trong môi trường game engine, module này sẽ chịu trách nhiệm thu thập, tiền xử lý và cấu trúc hóa các thông tin trạng thái game động có liên quan (ví dụ: trạng thái hiện tại của hệ thống Behavior Tree điều khiển NPC, tọa độ vị trí của NPC, thông tin về các thực thể lân cận có vai trò quan trọng). Việc trích xuất thông tin từ Behavior Tree có thể được thực hiện bằng cách truy cập các biến và trạng thái của Behavior Tree thông qua API C++ hoặc Blueprints của UE5 [14]. Thông tin vị trí và các thực thể lân cận sẽ được lấy thông qua các hàm truy vấn không gian (spatial queries) và thông tin từ scene graph của engine. Dữ liệu trích xuất sẽ được định dạng (ví dụ: JSON hoặc một cấu trúc văn bản mô tả ngắn gọn) để dễ dàng xử lý và tích hợp vào prompt.
(2) Module định dạng câu lệnh gợi ý (Prompt Formatter): Module này sẽ xử lý thông tin ngữ cảnh động đã được trích xuất từ Context Extractor, kết hợp với lịch sử hội thoại (nếu có) và các thông tin đặc tả về vai trò và tính cách (persona) của NPC (được định nghĩa trước hoặc học được qua fine-tuning). Mục tiêu là tạo ra các câu lệnh gợi ý (prompts) hoàn chỉnh và hiệu quả, tuân theo các kỹ thuật đã được nghiên cứu trong lĩnh vực Prompt Engineering [11], để tối ưu hóa khả năng sinh phản hồi của LLM. Các kỹ thuật như chèn thông tin ngữ cảnh dưới dạng cặp khóa-giá trị (key-value pairs) hoặc mô tả tự nhiên ngắn gọn, cũng như việc cung cấp các chỉ dẫn rõ ràng về vai trò và mục tiêu hội thoại, sẽ được thử nghiệm.
(3) Giao diện tương tác LLM (LLM Interface): Thành phần này sẽ quản lý việc gửi các câu lệnh gợi ý đã được định dạng đến mô hình LLM được triển khai cục bộ thông qua nền tảng như Ollama [15], và nhận lại các phản hồi hội thoại do LLM sinh ra. Giao diện này cần đảm bảo giao tiếp hiệu quả (ví dụ, sử dụng HTTP requests) và giảm thiểu độ trễ. Các cơ chế xử lý lỗi (error handling) và quản lý thời gian chờ (timeout) sẽ được tích hợp để đảm bảo tính ổn định của hệ thống.
(4) Module quản lý hội thoại (Dialogue Manager) trong UE5: Tiếp nhận phản hồi từ LLM Interface và chịu trách nhiệm hiển thị hội thoại trong game (ví dụ, qua các widget UI), đồng thời có thể kích hoạt các hành vi hoặc biểu cảm tương ứng của NPC (trong phạm vi giới hạn và khả thi của đề tài).
Thiết kế kiến trúc sẽ ưu tiên tính module hóa, khả năng mở rộng và hiệu quả trong giao tiếp giữa các thành phần. Sơ đồ kiến trúc chi tiết và đặc tả giao diện (API) giữa các module sẽ được hoàn thiện và tài liệu hóa trong giai đoạn này.
9.3. Triển khai thực nghiệm và phát triển hệ thống nguyên mẫu
Giai đoạn triển khai thực nghiệm và phát triển prototype là trọng tâm kỹ thuật của đề tài. Giai đoạn này bao gồm hai luồng công việc chính có thể diễn ra song song hoặc tuần tự tùy thuộc vào tiến độ và tài nguyên:
Thứ nhất, tinh chỉnh (fine-tuning) mô hình ngôn ngữ lớn: Do hạn chế về tài nguyên phần cứng cục bộ cho việc huấn luyện các mô hình lớn, quá trình tinh chỉnh mô hình LLM dự kiến (ví dụ: Meta Llama 3 8B [5] hoặc Microsoft Phi-3 Mini [16]) bằng kỹ thuật QLoRA [13] sẽ được thực hiện trên các nền tảng điện toán đám mây (ví dụ: Google Colab Pro để đảm bảo đủ thời gian runtime và VRAM).
Chuẩn bị dữ liệu tinh chỉnh: Nghiên cứu sẽ xem xét việc tạo dữ liệu fine-tuning tổng hợp do hạn chế về dữ liệu chuyên biệt có sẵn cho NPC. Một phương án khả thi là sử dụng một mô hình LLM lớn hơn, có năng lực cao hơn (ví dụ: GPT-4, như được đề cập trong ngữ cảnh instruction tuning bởi Peng và cộng sự [9], nếu có khả năng truy cập hạn chế qua API với chi phí chấp nhận được) làm "mô hình giáo viên" (teacher model). Mô hình này sẽ được cung cấp các kịch bản game chi tiết và mô tả persona NPC để sinh ra các cặp hội thoại mẫu (prompt-response) chất lượng cao. Số lượng mẫu dữ liệu dự kiến là khoảng 500-1000 cặp hội thoại, được lựa chọn cẩn thận để bao phủ các tình huống và phong cách ngôn ngữ mong muốn. Dữ liệu sẽ được định dạng theo cấu trúc yêu cầu của thư viện fine-tuning (ví dụ: Hugging Face Transformers).
Thực hiện fine-tuning: Quá trình tinh chỉnh sẽ được thực hiện bằng các thư viện mã nguồn mở phổ biến. Các siêu tham số quan trọng như learning rate (ví dụ: trong khoảng 1e-5 đến 5e-5), số epochs (ví dụ: 3-5), batch size, và các tham số đặc thù của LoRA/QLoRA (như rank, alpha) [12], [13] sẽ được lựa chọn dựa trên các khuyến nghị từ tài liệu gốc của các kỹ thuật này và các thử nghiệm ban đầu trên một tập dữ liệu nhỏ. Adapter QLoRA [13] đã được huấn luyện thành công sẽ được lưu lại để sử dụng cho việc triển khai cục bộ.
Thứ hai, phát triển hệ thống nguyên mẫu (prototype) trong Unreal Engine 5: Các module Context Extractor, Prompt Formatter, LLM Interface và Dialogue Manager đã được thiết kế ở mục con 9.2 sẽ được hiện thực hóa trong môi trường UE5 [14]. Ngôn ngữ lập trình C++ sẽ được ưu tiên cho các tác vụ đòi hỏi hiệu năng cao (như trích xuất ngữ cảnh phức tạp hoặc xử lý dữ liệu lớn), trong khi hệ thống kịch bản trực quan Blueprints có thể được sử dụng cho logic game, quản lý UI và các tác vụ tích hợp đơn giản hơn. Môi trường chạy suy luận (inference) LLM cục bộ sẽ được thiết lập bằng nền tảng Ollama [15], cho phép nạp và phục vụ mô hình LLM gốc hoặc mô hình đã được fine-tune (thông qua adapter QLoRA [13]). Việc kiểm thử và đảm bảo luồng giao tiếp thông suốt, ổn định giữa UE5 [14] và LLM cục bộ là một phần quan trọng của giai đoạn này. Độ trễ trong giao tiếp sẽ được theo dõi và cố gắng tối ưu hóa, ví dụ bằng cách sử dụng các kỹ thuật gọi hàm bất đồng bộ (asynchronous calls) khi gửi yêu cầu đến LLM và nhận phản hồi. Một hoặc một vài cảnh game (level) tường thuật đơn giản sẽ được xây dựng trong UE5 [14], bao gồm các NPC và các yếu tố môi trường có thể thay đổi, để tạo môi trường thử nghiệm và đánh giá hệ thống.
9.4. Đánh giá hiệu năng và phân tích khoa học
Cuối cùng, sau khi hệ thống nguyên mẫu được hoàn thiện và hoạt động ổn định, giai đoạn đánh giá hiệu năng và phân tích khoa học sẽ được thực hiện để kiểm chứng các mục tiêu nghiên cứu và trả lời các câu hỏi nghiên cứu đã đặt ra. Phương pháp đánh giá sẽ không bao gồm các khảo sát người dùng cuối (user studies) quy mô lớn ở giai đoạn nghiên cứu khoa học này, do những hạn chế về thời gian và nguồn lực, mặc dù các nghiên cứu như của Christiansen và cộng sự [20] cho thấy tầm quan trọng của việc đánh giá trải nghiệm người dùng. Thay vào đó, đánh giá sẽ tập trung vào các khía cạnh sau:
(1) Đánh giá tự động định lượng: Sử dụng các độ đo tự động phù hợp để đánh giá các khía cạnh khác nhau của chất lượng hội thoại được sinh ra, theo các hướng dẫn từ khảo sát của Celikyilmaz và cộng sự [7]. Cụ thể, BERTScore [17] sẽ được sử dụng để đo độ tương đồng ngữ nghĩa giữa ngữ cảnh được cung cấp (trong prompt) và phản hồi của NPC, đánh giá mức độ liên quan của phản hồi. Perplexity của mô hình (nếu có thể tính toán được một cách có ý nghĩa với kiến trúc triển khai và loại mô hình sử dụng) có thể được sử dụng như một chỉ số phụ để đánh giá tính lưu loát của ngôn ngữ được sinh ra.
(2) Phân tích định tính dựa trên tiêu chí được thiết kế:
Thiết kế kịch bản đánh giá: Thiết kế các kịch bản thử nghiệm cụ thể và có kiểm soát trong môi trường game nguyên mẫu trên UE5 [14]. Các kịch bản này sẽ bao gồm các ngữ cảnh game động được thay đổi một cách có chủ đích (ví dụ: NPC đang thực hiện hành động A, người chơi vừa hoàn thành nhiệm vụ B, có một đối tượng C bất ngờ xuất hiện gần NPC, hoặc một sự kiện môi trường quan trọng vừa xảy ra).
Thu thập và so sánh dữ liệu: Thu thập các mẫu hội thoại được sinh ra từ hệ thống đề xuất trong các kịch bản này. Đồng thời, các mẫu hội thoại từ các mô hình baseline (ví dụ: mô hình LLM gốc không được cung cấp thông tin ngữ cảnh động; mô hình LLM đã được fine-tune về persona nhưng không được cung cấp thông tin ngữ cảnh động) cũng sẽ được thu thập trong cùng các kịch bản để phục vụ việc so sánh.
Phân tích theo rubric: Phân tích sâu các mẫu hội thoại này dựa trên một rubric (bảng tiêu chí) đã được định trước và xây dựng cẩn thận. Rubric này sẽ bao gồm các tiêu chí đánh giá về: (a) độ tự nhiên và lưu loát của ngôn ngữ; (b) tính nhất quán trong vai trò và tính cách (persona consistency) của NPC so với persona đã được fine-tune [2]; và (c) quan trọng nhất là độ liên quan, phù hợp và nhạy bén của hội thoại với ngữ cảnh động được cung cấp bởi Context Extractor.
(3) Phân tích lỗi (Error Analysis): Xác định các dạng lỗi phổ biến mà hệ thống có thể tạo ra trong quá trình sinh hội thoại (ví dụ: hiện tượng "ảo giác" - hallucination, phản hồi không liên quan đến ngữ cảnh, lặp lại từ ngữ hoặc ý tưởng, mâu thuẫn với thông tin đã biết hoặc các phát ngôn trước đó) và tiến hành phân tích các nguyên nhân tiềm ẩn (ví dụ: lỗi trong quá trình trích xuất ngữ cảnh, thiết kế prompt chưa tối ưu [11], hạn chế cố hữu của mô hình LLM được sử dụng, hoặc vấn đề trong dữ liệu fine-tuning).
Kết quả so sánh hiệu năng giữa hệ thống đề xuất và các mô hình baseline sẽ được phân tích một cách cẩn thận (có thể bao gồm các phân tích thống kê mô tả đơn giản nếu dữ liệu thu thập cho phép) và được diễn giải trong mối liên hệ với các cơ sở lý thuyết đã trình bày và các mục tiêu nghiên cứu đã đặt ra. Toàn bộ phương pháp, quy trình thực hiện và kết quả đánh giá sẽ được trình bày một cách khoa học, minh bạch và chi tiết trong báo cáo nghiên cứu cuối cùng.
10.
ĐÓNG GÓP NGHIÊN CỨU


Công trình nghiên cứu này, thông qua việc đề xuất và kiểm nghiệm một kiến trúc hội thoại tiên tiến cho nhân vật không người chơi (NPC) dựa trên Mô hình Ngôn ngữ Lớn (LLM) được thông tin hóa bởi trạng thái thế giới game động, dự kiến sẽ mang lại những đóng góp có ý nghĩa trên các phương diện học thuật, thực nghiệm và ứng dụng.
Về mặt học thuật và phương pháp luận, đóng góp chính yếu của đề tài là đề xuất một khuôn khổ tích hợp cụ thể giữa game engine Unreal Engine 5 (UE5) và một LLM nguồn mở (dự kiến Llama 3 8B hoặc Microsoft Phi-3 Mini), nhằm giải quyết thách thức về nhận thức ngữ cảnh động của LLM trong môi trường game 3D. Nghiên cứu này sẽ phát triển một phương pháp luận cho việc trích xuất, biểu diễn và tích hợp thông tin trạng thái game động, bao gồm dữ liệu từ các hệ thống AI như Behavior Trees, vào quy trình tạo câu lệnh gợi ý (prompt engineering) cho LLM. Cách tiếp cận này mở rộng các nghiên cứu về học ngôn ngữ có cơ sở (grounded language learning) sang bối cảnh game 3D phức tạp, một lĩnh vực ít được explor hơn so với các môi trường mô phỏng 2D như trong "Generative Agents". Bên cạnh đó, nghiên cứu sẽ cung cấp những hiểu biết thực nghiệm ban đầu về hiệu quả của việc kết hợp kỹ thuật tinh chỉnh hiệu quả tham số (cụ thể là QLoRA) để duy trì tính nhất quán vai trò (persona consistency) của NPC với cơ chế thông tin hóa bằng ngữ cảnh động, nhằm đạt được sự cân bằng giữa tính cách và sự phù hợp tình huống.
Về mặt thực nghiệm, việc phát triển thành công một hệ thống nguyên mẫu (prototype) hoạt động, tích hợp UE5 với LLM suy luận cục bộ (qua Ollama với mô hình đã fine-tune bằng QLoRA), sẽ minh họa tính khả thi kỹ thuật của hướng tiếp cận đề xuất. Quan trọng hơn, các kết quả từ quy trình đánh giá khoa học (sử dụng các độ đo tự động như BERTScore và phân tích định tính) sẽ cung cấp dữ liệu cụ thể về mức độ cải thiện chất lượng hội thoại NPC (tính tự nhiên, nhất quán vai trò, độ phù hợp ngữ cảnh động) so với các mô hình baseline. Các phân tích lỗi và nghiên cứu tình huống sẽ làm rõ ưu nhược điểm của phương pháp, cung cấp dữ liệu tham khảo cho các nghiên cứu tương lai.
Về mặt ứng dụng thực tiễn, nghiên cứu này có tiềm năng cung cấp một khuôn khổ kỹ thuật và phương pháp luận tham khảo cho các nhà phát triển game và kỹ sư AI mong muốn khai thác LLM để cải thiện NPC trong game tường thuật,. Những hiểu biết về cách LLM phản ứng với ngữ cảnh game động và các thách thức trong kiểm soát hội thoại sẽ hữu ích cho thực tế phát triển. Việc cân nhắc công bố một phần mã nguồn của prototype có thể thúc đẩy ứng dụng rộng rãi hơn.
Về mặt giáo dục và phát triển năng lực, quá trình thực hiện đề tài giúp người nghiên cứu trau dồi kỹ năng liên ngành trong Game AI, NLP, ML; kinh nghiệm làm việc với các công nghệ tiên tiến (LLMs, fine-tuning, kiến trúc Transformer, UE5, Ollama); và năng lực thực hiện nghiên cứu khoa học từ thiết kế đến báo cáo.
11. 
TÀI LIỆU THAM KHẢO


[1] G. N. Yannakakis and J. Togelius, Artificial Intelligence and Games. Cham: Springer International Publishing, 2018. doi: 10.1007/978-3-319-63519-4. Available: https://link.springer.com/book/10.1007/978-3-319-63519-4     
[2] H. Warpefelt, "The Non-Player Character – Exploring the believability of NPC presentation and behavior," Available: https://www.researchgate.net/publication/303496966_The_Non-Player_Character_Exploring_the_believability_of_NPC_presentation_and_behavior      
[3] D. M. Bourg and G. Seemann, AI for Game Developers. Sebastopol, CA, USA: O’Reilly Media, 2004.
[4] A. Vaswani et al., “Attention Is All You Need,” arXiv.org. Available: https://arxiv.org/abs/1706.03762     
[5] “Introducing Meta Llama 3: The most capable openly available LLM to date.” Available: https://ai.meta.com/blog/meta-llama-3/     
[6] A. Q. Jiang et al., “Mistral 7B,” arXiv.org. Available: https://arxiv.org/abs/2310.06825     
[7] A. Celikyilmaz, E. Clark, and J. Gao, “Evaluation of Text Generation: A Survey,” arXiv.org. Available: https://arxiv.org/abs/2006.14799     
[8] S. R. K. Branavan, L. S. Zettlemoyer, and R. Barzilay, "Reading Between the Lines: Learning to Map High-level Instructions to Commands," in Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, Jul. 2010, pp. 1268–1277. Available: https://aclanthology.org/P10-1129
[9] B. Peng, C. Li, P. He, M. Galley, and J. Gao, “Instruction Tuning with GPT-4,” arXiv.org. Available: https://arxiv.org/abs/2304.03277
[10] J. S. Park, J. C. O’Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein, “Generative Agents: Interactive Simulacra of Human Behavior,” arXiv.org. Available: https://arxiv.org/abs/2304.03442     
[11] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, “Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing,” arXiv.org. Available: https://arxiv.org/abs/2107.13586      
[12] E. J. Hu et al., “LoRA: Low-Rank Adaptation of Large Language Models,” arXiv.org. Available: https://arxiv.org/abs/2106.09685      
[13] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, “QLoRA: Efficient Finetuning of Quantized LLMs,” arXiv.org. Available: https://arxiv.org/abs/2305.14314     
[14] Epic Games, "Unreal Engine Documentation," Unreal Engine. Available: https://docs.unrealengine.com/ 
[15] Ollama, "Ollama.". Available: https://ollama.com/ 
[16] M. Abdin et al., “Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone,” arXiv.org. Available: https://arxiv.org/abs/2404.14219 
[17] T. Zhang, V. Kishore, F. Wu, K. Q. Weinberger, and Y. Artzi, “BERTScore: Evaluating Text Generation with BERT,” arXiv:1904.09675 [cs], Feb. 2020, Available: https://arxiv.org/abs/1904.09675 
[18] R. Gallotta et al., “Large Language Models and Games: A Survey and Roadmap,” NASA ADS, Feb. 01, 2024. https://ui.adsabs.harvard.edu/abs/2024arXiv240218659G/abstract 
[19] P. Sweetser, “Large Language Models and Video Games: A Preliminary Scoping Review,” arXiv.org, 2024. https://arxiv.org/abs/2403.02613 
[20] F. R. Christiansen, Linus Nørgaard Hollensberg, N. B. Jensen, K. Julsgaard, K. N. Jespersen, and I. Nikolov, “Exploring Presence in Interactions with LLM-Driven NPCs: A Comparative Study of Speech Recognition and Dialogue Options,” vol. 56, pp. 1–11, Sep. 2024, doi: https://doi.org/10.1145/3641825.3687716. 
[21] L. Song, “LLM-Driven NPCs: Cross-Platform Dialogue System for Games and Social Platforms,” arXiv.org, 2025. https://arxiv.org/abs/2504.13928  
12.
KẾ HOẠCH NGHIÊN CỨU


Giai đoạn 1 (Tháng 1 - Tháng 2): Nghiên cứu Nền tảng, Thiết kế Chi tiết và Chuẩn bị Môi trường 
Tuần 1-3:
Tổng quan tài liệu chuyên sâu: Tập trung vào LLMs, kỹ thuật fine-tuning hiệu quả (QLoRA), các phương pháp Prompt Engineering tiên tiến, kỹ thuật tích hợp ngữ cảnh động vào LLM, các công trình về NPC và hệ thống hội thoại trong game, phương pháp đánh giá NLG.
Xác định và định nghĩa chi tiết các loại Trạng thái Thế giới Game Động cốt lõi sẽ được trích xuất từ Unreal Engine 5 (ví dụ: trạng thái Behavior Tree, vị trí, đối tượng lân cận, sự kiện gần đây).
Tuần 4-5:
Thiết kế kiến trúc hệ thống chi tiết: Vẽ sơ đồ luồng dữ liệu, đặc tả giao diện giữa các module (UE5 Context Extractor, Prompt Formatter, Local LLM Interface qua Ollama).
Thiết kế phương pháp biểu diễn ngữ cảnh game động để tích hợp vào prompt.
Xác định chiến lược chuẩn bị dữ liệu fine-tuning (ví dụ: quy trình sinh dữ liệu tổng hợp sử dụng "mô hình giáo viên" như GPT-4/Claude 3).
Tuần 6-8:
Thiết lập môi trường phát triển: Cài đặt Unreal Engine 5, thiết lập project. Cài đặt môi trường Python cần thiết.
Thiết lập môi trường chạy LLM cục bộ: Cài đặt và cấu hình, tải về mô hình ngôn ngữ lớn (bản gốc và/hoặc quantized).
Thiết lập môi trường fine-tuning trên Cloud: Làm quen và thiết lập tài khoản/môi trường trên Google Colab (hoặc nền tảng tương tự) cho việc fine-tuning QLoRA.
Bắt đầu thu thập/sinh dữ liệu fine-tuning theo chiến lược đã xác định.
Giai đoạn 2 (Tháng 3 - Tháng 4): Triển khai Kỹ thuật Cốt lõi và Fine-tuning 
Tuần 9-11:
Thực hiện Fine-tuning QLoRA: Chuẩn bị xong dữ liệu, tiến hành fine-tuning mô hình trên Google Colab. Lưu lại adapter đã huấn luyện. Lưu ý: Quá trình này có thể cần nhiều lần thử nghiệm và điều chỉnh.
Bắt đầu triển khai module Context Extractor trong UE5 để lấy các thông tin ngữ cảnh đã xác định.
Tuần 12-14:
Triển khai module LLM Interface trong UE5: Xây dựng logic gửi HTTP request đến API của Ollama đang chạy cục bộ và nhận phản hồi.
Triển khai module Prompt Formatter: Xây dựng logic kết hợp ngữ cảnh động và lịch sử hội thoại thành prompt hoàn chỉnh.
Triển khai module Dialogue Manager cơ bản trong UE5 để xử lý và hiển thị hội thoại.
Tuần 15-16:
Tích hợp ban đầu: Kết nối các module Context Extractor, Prompt Formatter, LLM Interface và Dialogue Manager trong UE5.
Chạy thử nghiệm inference cục bộ với mô hình ngôn ngữ đã fine-tune (qua Ollama) để kiểm tra luồng hoạt động cơ bản. Debug lỗi tích hợp.
Xây dựng cảnh game (level) thử nghiệm đơn giản trong UE5.
Giai đoạn 3 (Tháng 5 - Tháng 6): Tích hợp Hoàn chỉnh, Đánh giá và Viết Báo cáo 
Tuần 17-18:
Hoàn thiện tích hợp hệ thống: Tinh chỉnh luồng dữ liệu, xử lý các trường hợp biên, đảm bảo hệ thống hoạt động ổn định trong cảnh game thử nghiệm.
Thiết kế chi tiết các kịch bản đánh giá (Evaluation Scenarios) với các ngữ cảnh game động cụ thể.
Xây dựng/Lựa chọn các công cụ/script cho việc đánh giá tự động (ví dụ: tính Semantic Similarity, Perplexity).
Xây dựng Rubric (bảng tiêu chí) chi tiết cho việc đánh giá định tính bởi nhà nghiên cứu (Relevance, Consistency, Naturalness...).
Tuần 19-21:
Thực hiện đánh giá: Chạy hệ thống prototype và các baseline trong các kịch bản đã thiết kế. Thu thập dữ liệu hội thoại sinh ra.
Chạy các script đánh giá tự động.
Thực hiện đánh giá định tính các mẫu hội thoại dựa trên Rubric đã xây dựng. Phân tích các trường hợp thành công và thất bại (Error Analysis).
Tuần 22-24:
Phân tích và tổng hợp kết quả: Xử lý số liệu từ đánh giá tự động, tổng hợp kết quả đánh giá định tính. So sánh hiệu quả với baseline. Trực quan hóa kết quả.
Viết Báo cáo Nghiên cứu Khoa học: Hoàn thiện các phần Mở đầu, Tổng quan, Phương pháp, Kết quả, Bàn luận, Kết luận, Tài liệu tham khảo.




